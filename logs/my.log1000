nohup: ignoring input


starting seed  1000 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-189.00 +/- 108.02
Episode length: 138.93 +/- 73.08
New best mean reward!
Eval num_timesteps=10000, episode_reward=-101.55 +/- 77.50
Episode length: 79.77 +/- 19.66
New best mean reward!
Eval num_timesteps=15000, episode_reward=-101.50 +/- 70.44
Episode length: 348.29 +/- 211.90
New best mean reward!
Eval num_timesteps=20000, episode_reward=-225.01 +/- 24.87
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-127.14 +/- 30.97
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=30000, episode_reward=-80.55 +/- 21.49
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=35000, episode_reward=-118.94 +/- 27.67
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-111.63 +/- 23.07
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-43.84 +/- 45.93
Episode length: 990.20 +/- 36.21
New best mean reward!
Eval num_timesteps=50000, episode_reward=-38.50 +/- 78.86
Episode length: 963.41 +/- 78.41
New best mean reward!
Eval num_timesteps=55000, episode_reward=-97.45 +/- 28.49
Episode length: 998.07 +/- 19.20
Eval num_timesteps=60000, episode_reward=-56.32 +/- 136.28
Episode length: 755.87 +/- 127.93
Eval num_timesteps=65000, episode_reward=-82.55 +/- 38.80
Episode length: 960.67 +/- 126.50
Eval num_timesteps=70000, episode_reward=-120.76 +/- 28.39
Episode length: 946.43 +/- 153.49
Eval num_timesteps=75000, episode_reward=-52.78 +/- 106.14
Episode length: 745.73 +/- 247.63
Eval num_timesteps=80000, episode_reward=-23.07 +/- 117.32
Episode length: 633.63 +/- 221.15
New best mean reward!
Eval num_timesteps=85000, episode_reward=-16.84 +/- 124.78
Episode length: 466.63 +/- 235.03
New best mean reward!
Eval num_timesteps=90000, episode_reward=-0.83 +/- 129.17
Episode length: 352.11 +/- 147.79
New best mean reward!
Eval num_timesteps=95000, episode_reward=29.57 +/- 126.96
Episode length: 382.06 +/- 153.34
New best mean reward!
Eval num_timesteps=100000, episode_reward=-31.46 +/- 106.95
Episode length: 391.91 +/- 204.55
Eval num_timesteps=105000, episode_reward=71.42 +/- 117.86
Episode length: 665.20 +/- 217.58
New best mean reward!
Eval num_timesteps=110000, episode_reward=13.64 +/- 117.43
Episode length: 736.03 +/- 252.85
Eval num_timesteps=115000, episode_reward=-68.57 +/- 84.39
Episode length: 507.11 +/- 301.33
Eval num_timesteps=120000, episode_reward=-19.61 +/- 102.46
Episode length: 562.48 +/- 290.37
Eval num_timesteps=125000, episode_reward=-42.44 +/- 99.20
Episode length: 493.47 +/- 265.81
Eval num_timesteps=130000, episode_reward=-7.58 +/- 101.08
Episode length: 609.02 +/- 274.13
Eval num_timesteps=135000, episode_reward=-24.66 +/- 109.32
Episode length: 510.48 +/- 230.22
Eval num_timesteps=140000, episode_reward=-55.61 +/- 89.31
Episode length: 542.40 +/- 302.68
Eval num_timesteps=145000, episode_reward=-60.20 +/- 104.52
Episode length: 540.75 +/- 290.38
Eval num_timesteps=150000, episode_reward=-39.44 +/- 93.90
Episode length: 535.78 +/- 301.60
FINISHED IN 3561.8606857489794 s


starting seed  1001 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-200.31 +/- 36.53
Episode length: 549.62 +/- 175.82
New best mean reward!
Eval num_timesteps=10000, episode_reward=-79.38 +/- 71.51
Episode length: 916.60 +/- 125.73
New best mean reward!
Eval num_timesteps=15000, episode_reward=-4.30 +/- 74.57
Episode length: 942.84 +/- 92.25
New best mean reward!
Eval num_timesteps=20000, episode_reward=-108.09 +/- 49.57
Episode length: 987.90 +/- 48.35
Eval num_timesteps=25000, episode_reward=22.53 +/- 97.47
Episode length: 886.60 +/- 125.36
New best mean reward!
Eval num_timesteps=30000, episode_reward=-89.14 +/- 24.62
Episode length: 985.83 +/- 63.57
Eval num_timesteps=35000, episode_reward=-46.18 +/- 100.72
Episode length: 424.51 +/- 170.90
Eval num_timesteps=40000, episode_reward=142.43 +/- 109.26
Episode length: 486.18 +/- 117.10
New best mean reward!
Eval num_timesteps=45000, episode_reward=141.98 +/- 127.02
Episode length: 415.55 +/- 120.21
Eval num_timesteps=50000, episode_reward=95.78 +/- 134.17
Episode length: 487.69 +/- 117.78
Eval num_timesteps=55000, episode_reward=103.37 +/- 113.03
Episode length: 494.79 +/- 118.33
Eval num_timesteps=60000, episode_reward=56.95 +/- 124.88
Episode length: 408.32 +/- 140.28
Eval num_timesteps=65000, episode_reward=46.95 +/- 139.84
Episode length: 517.30 +/- 168.11
Eval num_timesteps=70000, episode_reward=60.27 +/- 132.20
Episode length: 280.17 +/- 83.89
Eval num_timesteps=75000, episode_reward=57.26 +/- 129.44
Episode length: 364.60 +/- 221.55
Eval num_timesteps=80000, episode_reward=58.25 +/- 121.92
Episode length: 227.07 +/- 122.96
Eval num_timesteps=85000, episode_reward=63.04 +/- 134.61
Episode length: 255.70 +/- 123.62
Eval num_timesteps=90000, episode_reward=76.65 +/- 133.86
Episode length: 302.46 +/- 163.28
Eval num_timesteps=95000, episode_reward=92.02 +/- 137.30
Episode length: 431.61 +/- 209.41
Eval num_timesteps=100000, episode_reward=80.59 +/- 111.25
Episode length: 676.46 +/- 232.14
Eval num_timesteps=105000, episode_reward=51.57 +/- 99.65
Episode length: 754.46 +/- 197.81
Eval num_timesteps=110000, episode_reward=67.91 +/- 135.53
Episode length: 485.87 +/- 163.26
Eval num_timesteps=115000, episode_reward=65.70 +/- 121.72
Episode length: 423.38 +/- 178.89
Eval num_timesteps=120000, episode_reward=77.72 +/- 126.23
Episode length: 395.01 +/- 168.74
Eval num_timesteps=125000, episode_reward=28.00 +/- 126.34
Episode length: 414.87 +/- 187.87
Eval num_timesteps=130000, episode_reward=33.75 +/- 128.67
Episode length: 425.15 +/- 195.80
Eval num_timesteps=135000, episode_reward=9.35 +/- 129.91
Episode length: 488.15 +/- 239.51
Eval num_timesteps=140000, episode_reward=-9.43 +/- 121.66
Episode length: 646.70 +/- 284.12
Eval num_timesteps=145000, episode_reward=25.52 +/- 128.13
Episode length: 554.86 +/- 262.73
Eval num_timesteps=150000, episode_reward=3.82 +/- 126.91
Episode length: 550.01 +/- 248.62
FINISHED IN 2760.9498264328577 s


starting seed  1002 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-635.52 +/- 64.41
Episode length: 99.12 +/- 16.17
New best mean reward!
Eval num_timesteps=10000, episode_reward=-619.98 +/- 74.64
Episode length: 97.14 +/- 18.36
New best mean reward!
Eval num_timesteps=15000, episode_reward=-257.84 +/- 271.61
Episode length: 680.48 +/- 417.63
New best mean reward!
Eval num_timesteps=20000, episode_reward=-380.16 +/- 124.30
Episode length: 316.27 +/- 207.62
Eval num_timesteps=25000, episode_reward=-188.87 +/- 41.27
Episode length: 587.49 +/- 213.79
New best mean reward!
Eval num_timesteps=30000, episode_reward=6.35 +/- 99.20
Episode length: 716.66 +/- 221.90
New best mean reward!
Eval num_timesteps=35000, episode_reward=-145.49 +/- 27.77
Episode length: 450.86 +/- 165.17
Eval num_timesteps=40000, episode_reward=-37.22 +/- 78.35
Episode length: 908.73 +/- 139.88
Eval num_timesteps=45000, episode_reward=14.88 +/- 85.70
Episode length: 945.47 +/- 115.22
New best mean reward!
Eval num_timesteps=50000, episode_reward=-204.39 +/- 57.42
Episode length: 715.16 +/- 178.73
Eval num_timesteps=55000, episode_reward=-66.75 +/- 102.66
Episode length: 943.83 +/- 95.85
Eval num_timesteps=60000, episode_reward=63.61 +/- 104.94
Episode length: 782.96 +/- 117.55
New best mean reward!
Eval num_timesteps=65000, episode_reward=166.22 +/- 95.26
Episode length: 480.29 +/- 155.71
New best mean reward!
Eval num_timesteps=70000, episode_reward=44.59 +/- 115.53
Episode length: 228.70 +/- 63.95
Eval num_timesteps=75000, episode_reward=120.39 +/- 133.52
Episode length: 269.02 +/- 97.09
Eval num_timesteps=80000, episode_reward=10.34 +/- 130.34
Episode length: 311.64 +/- 157.95
Eval num_timesteps=85000, episode_reward=63.54 +/- 108.61
Episode length: 721.73 +/- 184.25
Eval num_timesteps=90000, episode_reward=51.68 +/- 116.72
Episode length: 430.81 +/- 143.26
Eval num_timesteps=95000, episode_reward=31.81 +/- 116.86
Episode length: 484.37 +/- 132.19
Eval num_timesteps=100000, episode_reward=94.74 +/- 136.99
Episode length: 289.44 +/- 113.08
Eval num_timesteps=105000, episode_reward=80.87 +/- 131.26
Episode length: 213.20 +/- 103.47
Eval num_timesteps=110000, episode_reward=111.81 +/- 123.77
Episode length: 348.18 +/- 188.32
Eval num_timesteps=115000, episode_reward=92.30 +/- 131.08
Episode length: 295.89 +/- 130.59
Eval num_timesteps=120000, episode_reward=117.94 +/- 125.09
Episode length: 343.71 +/- 180.28
Eval num_timesteps=125000, episode_reward=118.23 +/- 124.36
Episode length: 369.31 +/- 194.59
Eval num_timesteps=130000, episode_reward=106.08 +/- 129.53
Episode length: 407.93 +/- 245.20
Eval num_timesteps=135000, episode_reward=69.60 +/- 113.72
Episode length: 326.84 +/- 205.02
Eval num_timesteps=140000, episode_reward=84.92 +/- 117.16
Episode length: 324.21 +/- 203.48
Eval num_timesteps=145000, episode_reward=85.38 +/- 122.34
Episode length: 327.67 +/- 212.45
Eval num_timesteps=150000, episode_reward=91.89 +/- 121.49
Episode length: 326.38 +/- 194.01
FINISHED IN 2309.189701487776 s


starting seed  1003 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-31.57 +/- 20.55
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-224.40 +/- 26.01
Episode length: 585.61 +/- 144.74
Eval num_timesteps=15000, episode_reward=-51.58 +/- 42.82
Episode length: 996.86 +/- 12.30
Eval num_timesteps=20000, episode_reward=-79.29 +/- 93.65
Episode length: 928.71 +/- 89.04
Eval num_timesteps=25000, episode_reward=-46.62 +/- 22.49
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=30000, episode_reward=-166.00 +/- 36.03
Episode length: 692.70 +/- 153.55
Eval num_timesteps=35000, episode_reward=-58.44 +/- 20.65
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-30.59 +/- 93.32
Episode length: 945.88 +/- 76.48
New best mean reward!
Eval num_timesteps=45000, episode_reward=-109.60 +/- 72.42
Episode length: 822.64 +/- 228.16
Eval num_timesteps=50000, episode_reward=-42.98 +/- 101.08
Episode length: 462.14 +/- 176.04
Eval num_timesteps=55000, episode_reward=-55.16 +/- 97.36
Episode length: 564.97 +/- 287.17
Eval num_timesteps=60000, episode_reward=-102.95 +/- 71.76
Episode length: 342.32 +/- 210.20
Eval num_timesteps=65000, episode_reward=-147.75 +/- 34.42
Episode length: 328.57 +/- 208.13
Eval num_timesteps=70000, episode_reward=-114.44 +/- 42.63
Episode length: 572.97 +/- 359.52
Eval num_timesteps=75000, episode_reward=-88.34 +/- 67.32
Episode length: 627.80 +/- 328.67
Eval num_timesteps=80000, episode_reward=-93.91 +/- 80.78
Episode length: 595.72 +/- 325.47
Eval num_timesteps=85000, episode_reward=-84.82 +/- 77.64
Episode length: 361.43 +/- 198.55
Eval num_timesteps=90000, episode_reward=-133.83 +/- 36.66
Episode length: 440.94 +/- 289.42
Eval num_timesteps=95000, episode_reward=-113.68 +/- 71.85
Episode length: 428.66 +/- 280.39
Eval num_timesteps=100000, episode_reward=-110.42 +/- 55.70
Episode length: 400.78 +/- 298.72
Eval num_timesteps=105000, episode_reward=-152.56 +/- 50.02
Episode length: 457.38 +/- 319.54
Eval num_timesteps=110000, episode_reward=-123.08 +/- 35.99
Episode length: 348.57 +/- 228.91
Eval num_timesteps=115000, episode_reward=-126.12 +/- 46.62
Episode length: 333.30 +/- 232.12
Eval num_timesteps=120000, episode_reward=-126.27 +/- 50.86
Episode length: 340.41 +/- 237.20
Eval num_timesteps=125000, episode_reward=-130.14 +/- 49.71
Episode length: 392.90 +/- 252.83
Eval num_timesteps=130000, episode_reward=-109.44 +/- 60.43
Episode length: 339.76 +/- 226.51
Eval num_timesteps=135000, episode_reward=-100.27 +/- 71.31
Episode length: 350.44 +/- 248.16
Eval num_timesteps=140000, episode_reward=-70.13 +/- 89.80
Episode length: 361.15 +/- 243.97
Eval num_timesteps=145000, episode_reward=-84.87 +/- 85.01
Episode length: 416.59 +/- 292.16
Eval num_timesteps=150000, episode_reward=-59.93 +/- 111.38
Episode length: 406.08 +/- 232.52
FINISHED IN 2975.5618974668905 s


starting seed  1004 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-793.82 +/- 596.82
Episode length: 114.23 +/- 53.04
New best mean reward!
Eval num_timesteps=10000, episode_reward=-629.28 +/- 73.16
Episode length: 75.47 +/- 7.24
New best mean reward!
Eval num_timesteps=15000, episode_reward=-174.35 +/- 66.83
Episode length: 213.82 +/- 47.62
New best mean reward!
Eval num_timesteps=20000, episode_reward=-415.34 +/- 87.85
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=58.47 +/- 127.30
Episode length: 449.40 +/- 186.24
New best mean reward!
Eval num_timesteps=30000, episode_reward=-215.82 +/- 31.09
Episode length: 402.06 +/- 169.42
Eval num_timesteps=35000, episode_reward=-117.86 +/- 49.19
Episode length: 825.62 +/- 258.21
Eval num_timesteps=40000, episode_reward=-24.95 +/- 93.29
Episode length: 863.24 +/- 198.95
Eval num_timesteps=45000, episode_reward=1.96 +/- 124.53
Episode length: 448.67 +/- 175.40
Eval num_timesteps=50000, episode_reward=-35.81 +/- 79.97
Episode length: 899.54 +/- 225.51
Eval num_timesteps=55000, episode_reward=-61.67 +/- 43.70
Episode length: 739.74 +/- 363.67
Eval num_timesteps=60000, episode_reward=-42.98 +/- 116.37
Episode length: 408.06 +/- 215.25
Eval num_timesteps=65000, episode_reward=-98.10 +/- 76.35
Episode length: 423.25 +/- 285.15
Eval num_timesteps=70000, episode_reward=-26.56 +/- 103.42
Episode length: 506.08 +/- 300.58
Eval num_timesteps=75000, episode_reward=-74.96 +/- 90.84
Episode length: 497.86 +/- 337.71
Eval num_timesteps=80000, episode_reward=-88.87 +/- 41.56
Episode length: 595.80 +/- 397.87
Eval num_timesteps=85000, episode_reward=-161.51 +/- 51.40
Episode length: 501.50 +/- 282.26
Eval num_timesteps=90000, episode_reward=-79.97 +/- 51.74
Episode length: 694.94 +/- 375.09
Eval num_timesteps=95000, episode_reward=-120.36 +/- 39.73
Episode length: 470.39 +/- 325.83
Eval num_timesteps=100000, episode_reward=-136.25 +/- 61.38
Episode length: 552.27 +/- 337.08
Eval num_timesteps=105000, episode_reward=-82.53 +/- 63.36
Episode length: 675.48 +/- 342.90
Eval num_timesteps=110000, episode_reward=-109.34 +/- 37.52
Episode length: 468.27 +/- 328.05
Eval num_timesteps=115000, episode_reward=-95.30 +/- 37.51
Episode length: 608.70 +/- 365.45
Eval num_timesteps=120000, episode_reward=-106.35 +/- 34.86
Episode length: 590.66 +/- 357.79
Eval num_timesteps=125000, episode_reward=-104.30 +/- 62.79
Episode length: 517.70 +/- 348.15
Eval num_timesteps=130000, episode_reward=-112.02 +/- 43.30
Episode length: 459.00 +/- 339.96
Eval num_timesteps=135000, episode_reward=-115.47 +/- 55.08
Episode length: 481.82 +/- 337.35
Eval num_timesteps=140000, episode_reward=-123.86 +/- 50.00
Episode length: 540.86 +/- 355.24
Eval num_timesteps=145000, episode_reward=-120.77 +/- 57.34
Episode length: 518.04 +/- 347.43
Eval num_timesteps=150000, episode_reward=-117.75 +/- 46.55
Episode length: 451.77 +/- 330.00
FINISHED IN 4944.338619228918 s


starting seed  1005 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-197.81 +/- 23.62
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-172.05 +/- 52.31
Episode length: 816.29 +/- 230.51
New best mean reward!
Eval num_timesteps=15000, episode_reward=-232.93 +/- 66.07
Episode length: 804.54 +/- 241.98
Eval num_timesteps=20000, episode_reward=-206.53 +/- 57.74
Episode length: 725.67 +/- 257.83
Eval num_timesteps=25000, episode_reward=-85.95 +/- 41.15
Episode length: 980.05 +/- 79.48
New best mean reward!
Eval num_timesteps=30000, episode_reward=-7.39 +/- 118.35
Episode length: 574.79 +/- 250.21
New best mean reward!
Eval num_timesteps=35000, episode_reward=-117.83 +/- 49.08
Episode length: 886.90 +/- 219.08
Eval num_timesteps=40000, episode_reward=-44.55 +/- 31.98
Episode length: 957.04 +/- 175.47
Eval num_timesteps=45000, episode_reward=-138.69 +/- 18.05
Episode length: 223.90 +/- 62.05
Eval num_timesteps=50000, episode_reward=-144.17 +/- 49.79
Episode length: 797.55 +/- 234.00
Eval num_timesteps=55000, episode_reward=-82.10 +/- 34.50
Episode length: 908.66 +/- 247.65
Eval num_timesteps=60000, episode_reward=-68.25 +/- 21.69
Episode length: 957.71 +/- 169.45
Eval num_timesteps=65000, episode_reward=-22.63 +/- 75.28
Episode length: 886.91 +/- 231.93
Eval num_timesteps=70000, episode_reward=7.55 +/- 120.36
Episode length: 355.06 +/- 188.71
New best mean reward!
Eval num_timesteps=75000, episode_reward=-32.69 +/- 114.78
Episode length: 577.59 +/- 320.32
Eval num_timesteps=80000, episode_reward=5.43 +/- 122.55
Episode length: 354.76 +/- 157.24
Eval num_timesteps=85000, episode_reward=32.05 +/- 126.57
Episode length: 356.39 +/- 153.39
New best mean reward!
Eval num_timesteps=90000, episode_reward=-18.08 +/- 116.47
Episode length: 309.80 +/- 176.82
Eval num_timesteps=95000, episode_reward=8.95 +/- 111.78
Episode length: 543.29 +/- 277.66
Eval num_timesteps=100000, episode_reward=-87.67 +/- 37.56
Episode length: 640.68 +/- 359.73
Eval num_timesteps=105000, episode_reward=-88.65 +/- 42.60
Episode length: 700.75 +/- 360.73
Eval num_timesteps=110000, episode_reward=-107.76 +/- 30.12
Episode length: 637.72 +/- 382.79
Eval num_timesteps=115000, episode_reward=-127.95 +/- 42.36
Episode length: 571.61 +/- 358.25
Eval num_timesteps=120000, episode_reward=-127.99 +/- 39.08
Episode length: 415.80 +/- 307.73
Eval num_timesteps=125000, episode_reward=-114.88 +/- 38.31
Episode length: 456.68 +/- 335.67
Eval num_timesteps=130000, episode_reward=-125.15 +/- 39.41
Episode length: 418.19 +/- 317.49
Eval num_timesteps=135000, episode_reward=-122.34 +/- 42.84
Episode length: 461.90 +/- 328.15
Eval num_timesteps=140000, episode_reward=-123.06 +/- 35.94
Episode length: 453.37 +/- 314.70
Eval num_timesteps=145000, episode_reward=-117.46 +/- 27.38
Episode length: 411.62 +/- 298.79
Eval num_timesteps=150000, episode_reward=-124.19 +/- 35.63
Episode length: 435.07 +/- 329.61
FINISHED IN 2965.605744805187 s


starting seed  1006 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-790.89 +/- 401.84
Episode length: 116.90 +/- 45.24
New best mean reward!
Eval num_timesteps=10000, episode_reward=-565.95 +/- 163.84
Episode length: 66.60 +/- 12.86
New best mean reward!
Eval num_timesteps=15000, episode_reward=-1113.40 +/- 1320.17
Episode length: 141.49 +/- 90.94
Eval num_timesteps=20000, episode_reward=-573.34 +/- 164.05
Episode length: 67.40 +/- 12.10
Eval num_timesteps=25000, episode_reward=-583.69 +/- 181.25
Episode length: 66.22 +/- 11.46
Eval num_timesteps=30000, episode_reward=-577.20 +/- 178.23
Episode length: 66.87 +/- 12.96
Eval num_timesteps=35000, episode_reward=-130.40 +/- 39.41
Episode length: 69.32 +/- 11.90
New best mean reward!
Eval num_timesteps=40000, episode_reward=-131.50 +/- 36.60
Episode length: 66.72 +/- 10.81
Eval num_timesteps=45000, episode_reward=-1857.99 +/- 501.27
Episode length: 458.81 +/- 84.05
Eval num_timesteps=50000, episode_reward=-72.52 +/- 21.67
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=55000, episode_reward=-274.33 +/- 42.86
Episode length: 958.09 +/- 83.24
Eval num_timesteps=60000, episode_reward=32.43 +/- 111.39
Episode length: 743.14 +/- 154.40
New best mean reward!
Eval num_timesteps=65000, episode_reward=-23.79 +/- 116.53
Episode length: 588.51 +/- 166.45
Eval num_timesteps=70000, episode_reward=-108.80 +/- 38.16
Episode length: 346.01 +/- 153.92
Eval num_timesteps=75000, episode_reward=-109.28 +/- 24.83
Episode length: 352.43 +/- 155.21
Eval num_timesteps=80000, episode_reward=49.86 +/- 110.17
Episode length: 488.96 +/- 288.41
New best mean reward!
Eval num_timesteps=85000, episode_reward=-110.65 +/- 65.06
Episode length: 728.30 +/- 305.68
Eval num_timesteps=90000, episode_reward=-85.46 +/- 33.10
Episode length: 951.12 +/- 193.67
Eval num_timesteps=95000, episode_reward=-77.22 +/- 94.44
Episode length: 824.40 +/- 241.13
Eval num_timesteps=100000, episode_reward=-62.88 +/- 82.87
Episode length: 603.56 +/- 296.24
Eval num_timesteps=105000, episode_reward=-44.82 +/- 94.87
Episode length: 716.61 +/- 264.16
Eval num_timesteps=110000, episode_reward=-123.52 +/- 55.83
Episode length: 826.53 +/- 251.20
Eval num_timesteps=115000, episode_reward=-40.59 +/- 96.77
Episode length: 535.34 +/- 244.66
Eval num_timesteps=120000, episode_reward=-25.43 +/- 133.92
Episode length: 434.28 +/- 192.76
Eval num_timesteps=125000, episode_reward=-87.67 +/- 60.71
Episode length: 739.87 +/- 289.94
Eval num_timesteps=130000, episode_reward=-88.90 +/- 57.92
Episode length: 737.43 +/- 304.69
Eval num_timesteps=135000, episode_reward=-55.26 +/- 69.33
Episode length: 657.59 +/- 322.74
Eval num_timesteps=140000, episode_reward=-83.62 +/- 74.41
Episode length: 549.77 +/- 286.99
Eval num_timesteps=145000, episode_reward=-76.16 +/- 94.69
Episode length: 491.59 +/- 257.89
Eval num_timesteps=150000, episode_reward=-58.67 +/- 91.13
Episode length: 483.84 +/- 262.04
FINISHED IN 2516.0159243652597 s


starting seed  1007 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-742.17 +/- 330.91
Episode length: 160.54 +/- 68.75
New best mean reward!
Eval num_timesteps=10000, episode_reward=-38.01 +/- 72.93
Episode length: 118.81 +/- 55.23
New best mean reward!
Eval num_timesteps=15000, episode_reward=-3.46 +/- 129.58
Episode length: 679.31 +/- 153.94
New best mean reward!
Eval num_timesteps=20000, episode_reward=-298.93 +/- 38.91
Episode length: 991.33 +/- 86.27
Eval num_timesteps=25000, episode_reward=-176.36 +/- 57.72
Episode length: 922.17 +/- 86.08
Eval num_timesteps=30000, episode_reward=-154.07 +/- 42.88
Episode length: 987.41 +/- 88.36
Eval num_timesteps=35000, episode_reward=-101.00 +/- 35.58
Episode length: 993.16 +/- 68.06
Eval num_timesteps=40000, episode_reward=-200.47 +/- 58.80
Episode length: 807.40 +/- 179.76
Eval num_timesteps=45000, episode_reward=98.13 +/- 81.92
Episode length: 717.88 +/- 232.44
New best mean reward!
Eval num_timesteps=50000, episode_reward=-48.78 +/- 88.06
Episode length: 977.13 +/- 57.82
Eval num_timesteps=55000, episode_reward=129.88 +/- 118.10
Episode length: 361.38 +/- 95.44
New best mean reward!
Eval num_timesteps=60000, episode_reward=52.54 +/- 118.05
Episode length: 232.39 +/- 85.26
Eval num_timesteps=65000, episode_reward=-7.75 +/- 70.66
Episode length: 170.91 +/- 70.52
Eval num_timesteps=70000, episode_reward=-14.14 +/- 65.05
Episode length: 147.07 +/- 34.73
Eval num_timesteps=75000, episode_reward=-29.17 +/- 88.92
Episode length: 172.11 +/- 69.70
Eval num_timesteps=80000, episode_reward=-116.62 +/- 69.87
Episode length: 307.66 +/- 154.27
Eval num_timesteps=85000, episode_reward=-148.22 +/- 30.35
Episode length: 288.05 +/- 144.17
Eval num_timesteps=90000, episode_reward=-143.02 +/- 40.41
Episode length: 334.61 +/- 185.65
Eval num_timesteps=95000, episode_reward=-170.23 +/- 43.27
Episode length: 301.95 +/- 168.97
Eval num_timesteps=100000, episode_reward=-168.90 +/- 46.55
Episode length: 423.69 +/- 230.28
Eval num_timesteps=105000, episode_reward=-189.24 +/- 55.81
Episode length: 508.22 +/- 255.05
Eval num_timesteps=110000, episode_reward=-147.07 +/- 43.50
Episode length: 876.99 +/- 195.17
Eval num_timesteps=115000, episode_reward=-141.21 +/- 52.16
Episode length: 899.28 +/- 199.17
Eval num_timesteps=120000, episode_reward=-149.16 +/- 32.59
Episode length: 974.21 +/- 128.27
Eval num_timesteps=125000, episode_reward=-114.50 +/- 19.30
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=130000, episode_reward=-119.02 +/- 16.04
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=135000, episode_reward=-134.24 +/- 18.51
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=140000, episode_reward=-135.93 +/- 19.45
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=145000, episode_reward=-120.13 +/- 21.99
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=150000, episode_reward=-120.65 +/- 18.96
Episode length: 1000.00 +/- 0.00
FINISHED IN 3083.090574888047 s


starting seed  1008 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-880.47 +/- 596.29
Episode length: 123.95 +/- 58.48
New best mean reward!
Eval num_timesteps=10000, episode_reward=-844.91 +/- 553.88
Episode length: 118.79 +/- 54.27
New best mean reward!
Eval num_timesteps=15000, episode_reward=-794.66 +/- 475.49
Episode length: 117.23 +/- 52.04
New best mean reward!
Eval num_timesteps=20000, episode_reward=-586.99 +/- 158.77
Episode length: 67.47 +/- 11.88
New best mean reward!
Eval num_timesteps=25000, episode_reward=-565.21 +/- 168.42
Episode length: 66.24 +/- 12.16
New best mean reward!
Eval num_timesteps=30000, episode_reward=-585.40 +/- 160.18
Episode length: 66.96 +/- 10.73
Eval num_timesteps=35000, episode_reward=-586.84 +/- 177.36
Episode length: 66.55 +/- 11.35
Eval num_timesteps=40000, episode_reward=-593.38 +/- 179.80
Episode length: 69.01 +/- 15.74
Eval num_timesteps=45000, episode_reward=-631.88 +/- 190.73
Episode length: 71.86 +/- 14.42
Eval num_timesteps=50000, episode_reward=-559.50 +/- 164.32
Episode length: 66.74 +/- 12.54
New best mean reward!
Eval num_timesteps=55000, episode_reward=-591.22 +/- 177.82
Episode length: 68.06 +/- 13.67
Eval num_timesteps=60000, episode_reward=-609.51 +/- 166.64
Episode length: 68.70 +/- 12.40
Eval num_timesteps=65000, episode_reward=-566.82 +/- 182.42
Episode length: 66.40 +/- 12.42
Eval num_timesteps=70000, episode_reward=-135.99 +/- 54.66
Episode length: 71.84 +/- 13.16
New best mean reward!
Eval num_timesteps=75000, episode_reward=-576.40 +/- 179.99
Episode length: 67.07 +/- 13.01
Eval num_timesteps=80000, episode_reward=-130.51 +/- 43.73
Episode length: 70.13 +/- 13.14
New best mean reward!
Eval num_timesteps=85000, episode_reward=-199.99 +/- 74.61
Episode length: 71.84 +/- 13.80
Eval num_timesteps=90000, episode_reward=-174.53 +/- 99.62
Episode length: 77.31 +/- 15.33
Eval num_timesteps=95000, episode_reward=-611.53 +/- 189.84
Episode length: 223.31 +/- 71.75
Eval num_timesteps=100000, episode_reward=-718.16 +/- 350.12
Episode length: 122.96 +/- 34.79
Eval num_timesteps=105000, episode_reward=-764.03 +/- 236.89
Episode length: 154.05 +/- 44.64
Eval num_timesteps=110000, episode_reward=-620.71 +/- 104.57
Episode length: 111.81 +/- 18.41
Eval num_timesteps=115000, episode_reward=-166.87 +/- 24.67
Episode length: 230.39 +/- 44.96
Eval num_timesteps=120000, episode_reward=-263.40 +/- 27.47
Episode length: 307.83 +/- 53.42
Eval num_timesteps=125000, episode_reward=-208.67 +/- 28.15
Episode length: 226.89 +/- 45.95
Eval num_timesteps=130000, episode_reward=-284.33 +/- 55.61
Episode length: 418.68 +/- 115.68
Eval num_timesteps=135000, episode_reward=-316.45 +/- 58.12
Episode length: 459.01 +/- 111.25
Eval num_timesteps=140000, episode_reward=-255.60 +/- 55.92
Episode length: 485.86 +/- 155.03
Eval num_timesteps=145000, episode_reward=-204.80 +/- 35.60
Episode length: 398.63 +/- 117.54
Eval num_timesteps=150000, episode_reward=-198.64 +/- 38.72
Episode length: 379.28 +/- 118.56
FINISHED IN 833.2695601540618 s


starting seed  1009 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-562.88 +/- 157.13
Episode length: 65.79 +/- 11.24
New best mean reward!
Eval num_timesteps=10000, episode_reward=-124.18 +/- 16.10
Episode length: 70.67 +/- 13.36
New best mean reward!
Eval num_timesteps=15000, episode_reward=-414.27 +/- 69.36
Episode length: 639.77 +/- 158.06
Eval num_timesteps=20000, episode_reward=-71.34 +/- 25.57
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-47.98 +/- 20.31
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=-97.89 +/- 17.79
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=-61.13 +/- 22.65
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-75.26 +/- 37.09
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-75.03 +/- 37.42
Episode length: 986.23 +/- 70.33
Eval num_timesteps=50000, episode_reward=-31.65 +/- 71.98
Episode length: 952.17 +/- 85.19
New best mean reward!
Eval num_timesteps=55000, episode_reward=-84.86 +/- 27.57
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-90.21 +/- 58.77
Episode length: 916.61 +/- 174.44
Eval num_timesteps=65000, episode_reward=87.55 +/- 106.53
Episode length: 699.98 +/- 152.91
New best mean reward!
Eval num_timesteps=70000, episode_reward=11.80 +/- 135.76
Episode length: 449.00 +/- 198.33
Eval num_timesteps=75000, episode_reward=-14.04 +/- 106.62
Episode length: 298.02 +/- 197.13
Eval num_timesteps=80000, episode_reward=-28.99 +/- 97.91
Episode length: 696.06 +/- 268.17
Eval num_timesteps=85000, episode_reward=-76.11 +/- 83.82
Episode length: 647.94 +/- 298.36
Eval num_timesteps=90000, episode_reward=-48.67 +/- 47.10
Episode length: 947.16 +/- 178.08
Eval num_timesteps=95000, episode_reward=-42.55 +/- 29.01
Episode length: 920.95 +/- 231.98
Eval num_timesteps=100000, episode_reward=-44.85 +/- 24.74
Episode length: 944.17 +/- 204.21
Eval num_timesteps=105000, episode_reward=-52.13 +/- 28.80
Episode length: 938.10 +/- 210.36
Eval num_timesteps=110000, episode_reward=-118.68 +/- 54.69
Episode length: 509.81 +/- 280.95
Eval num_timesteps=115000, episode_reward=-99.96 +/- 52.88
Episode length: 543.85 +/- 319.18
Eval num_timesteps=120000, episode_reward=-116.77 +/- 46.27
Episode length: 606.82 +/- 340.80
Eval num_timesteps=125000, episode_reward=-85.19 +/- 61.01
Episode length: 579.97 +/- 339.25
Eval num_timesteps=130000, episode_reward=-66.77 +/- 89.37
Episode length: 579.56 +/- 334.10
Eval num_timesteps=135000, episode_reward=-65.73 +/- 58.15
Episode length: 629.82 +/- 357.24
Eval num_timesteps=140000, episode_reward=-74.50 +/- 56.35
Episode length: 602.51 +/- 353.82
Eval num_timesteps=145000, episode_reward=-81.96 +/- 52.66
Episode length: 596.42 +/- 351.12
Eval num_timesteps=150000, episode_reward=-71.64 +/- 75.70
Episode length: 595.72 +/- 352.08
FINISHED IN 3546.101395216305 s


starting seed  1010 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-806.24 +/- 519.32
Episode length: 120.17 +/- 54.39
New best mean reward!
Eval num_timesteps=10000, episode_reward=-939.73 +/- 564.57
Episode length: 130.98 +/- 58.29
Eval num_timesteps=15000, episode_reward=-638.21 +/- 59.46
Episode length: 88.80 +/- 15.41
New best mean reward!
Eval num_timesteps=20000, episode_reward=-964.05 +/- 391.12
Episode length: 205.34 +/- 41.35
Eval num_timesteps=25000, episode_reward=-219.19 +/- 36.17
Episode length: 553.29 +/- 174.24
New best mean reward!
Eval num_timesteps=30000, episode_reward=-217.29 +/- 36.36
Episode length: 527.79 +/- 144.43
New best mean reward!
Eval num_timesteps=35000, episode_reward=-91.07 +/- 23.80
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=40000, episode_reward=-66.94 +/- 19.25
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=45000, episode_reward=-154.21 +/- 40.86
Episode length: 553.01 +/- 198.57
Eval num_timesteps=50000, episode_reward=-47.16 +/- 101.94
Episode length: 680.91 +/- 279.02
New best mean reward!
Eval num_timesteps=55000, episode_reward=-101.06 +/- 66.79
Episode length: 341.96 +/- 87.26
Eval num_timesteps=60000, episode_reward=-100.10 +/- 31.83
Episode length: 977.97 +/- 101.91
Eval num_timesteps=65000, episode_reward=-88.85 +/- 23.91
Episode length: 997.93 +/- 15.74
Eval num_timesteps=70000, episode_reward=-97.07 +/- 81.45
Episode length: 222.61 +/- 102.10
Eval num_timesteps=75000, episode_reward=-112.27 +/- 52.47
Episode length: 762.81 +/- 258.36
Eval num_timesteps=80000, episode_reward=-36.15 +/- 61.73
Episode length: 971.78 +/- 75.36
New best mean reward!
Eval num_timesteps=85000, episode_reward=-39.33 +/- 29.25
Episode length: 996.67 +/- 25.88
Eval num_timesteps=90000, episode_reward=-46.17 +/- 32.24
Episode length: 999.04 +/- 9.55
Eval num_timesteps=95000, episode_reward=36.21 +/- 93.95
Episode length: 940.43 +/- 87.85
New best mean reward!
Eval num_timesteps=100000, episode_reward=-45.64 +/- 35.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=105000, episode_reward=-32.11 +/- 22.98
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=110000, episode_reward=-63.77 +/- 24.93
Episode length: 992.80 +/- 71.64
Eval num_timesteps=115000, episode_reward=-3.53 +/- 54.01
Episode length: 985.42 +/- 64.59
Eval num_timesteps=120000, episode_reward=-7.46 +/- 70.25
Episode length: 967.35 +/- 103.09
Eval num_timesteps=125000, episode_reward=-12.23 +/- 46.55
Episode length: 987.65 +/- 70.89
Eval num_timesteps=130000, episode_reward=51.85 +/- 61.71
Episode length: 973.64 +/- 51.32
New best mean reward!
Eval num_timesteps=135000, episode_reward=64.42 +/- 79.49
Episode length: 929.99 +/- 103.51
New best mean reward!
Eval num_timesteps=140000, episode_reward=75.69 +/- 103.67
Episode length: 870.58 +/- 136.47
New best mean reward!
Eval num_timesteps=145000, episode_reward=117.48 +/- 87.90
Episode length: 776.37 +/- 136.03
New best mean reward!
Eval num_timesteps=150000, episode_reward=111.94 +/- 96.11
Episode length: 756.90 +/- 124.58
FINISHED IN 3704.5533475270495 s


starting seed  1011 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-459.00 +/- 141.01
Episode length: 432.60 +/- 88.80
New best mean reward!
Eval num_timesteps=10000, episode_reward=-138.41 +/- 46.99
Episode length: 633.20 +/- 234.60
New best mean reward!
Eval num_timesteps=15000, episode_reward=-88.94 +/- 85.90
Episode length: 541.62 +/- 244.68
New best mean reward!
Eval num_timesteps=20000, episode_reward=-143.97 +/- 52.63
Episode length: 547.56 +/- 272.19
Eval num_timesteps=25000, episode_reward=-56.84 +/- 80.94
Episode length: 773.09 +/- 268.18
New best mean reward!
Eval num_timesteps=30000, episode_reward=-223.89 +/- 59.74
Episode length: 668.48 +/- 205.13
Eval num_timesteps=35000, episode_reward=-28.13 +/- 90.40
Episode length: 853.88 +/- 175.93
New best mean reward!
Eval num_timesteps=40000, episode_reward=1.94 +/- 121.91
Episode length: 467.44 +/- 184.24
New best mean reward!
Eval num_timesteps=45000, episode_reward=-0.32 +/- 125.78
Episode length: 196.78 +/- 80.88
Eval num_timesteps=50000, episode_reward=-5.97 +/- 128.55
Episode length: 337.59 +/- 223.02
Eval num_timesteps=55000, episode_reward=-84.91 +/- 90.47
Episode length: 550.89 +/- 288.64
Eval num_timesteps=60000, episode_reward=-71.10 +/- 59.01
Episode length: 681.41 +/- 320.89
Eval num_timesteps=65000, episode_reward=-45.93 +/- 32.16
Episode length: 940.61 +/- 202.33
Eval num_timesteps=70000, episode_reward=-101.07 +/- 64.88
Episode length: 475.94 +/- 311.11
Eval num_timesteps=75000, episode_reward=-93.17 +/- 73.47
Episode length: 364.37 +/- 249.04
Eval num_timesteps=80000, episode_reward=-101.29 +/- 56.46
Episode length: 490.70 +/- 332.74
Eval num_timesteps=85000, episode_reward=-10.78 +/- 115.98
Episode length: 348.34 +/- 194.15
Eval num_timesteps=90000, episode_reward=-0.24 +/- 126.25
Episode length: 284.62 +/- 154.71
Eval num_timesteps=95000, episode_reward=29.31 +/- 136.82
Episode length: 350.64 +/- 176.34
New best mean reward!
Eval num_timesteps=100000, episode_reward=68.80 +/- 120.84
Episode length: 387.86 +/- 204.07
New best mean reward!
Eval num_timesteps=105000, episode_reward=69.42 +/- 131.66
Episode length: 450.73 +/- 226.28
New best mean reward!
Eval num_timesteps=110000, episode_reward=23.85 +/- 117.71
Episode length: 662.80 +/- 258.95
Eval num_timesteps=115000, episode_reward=-23.34 +/- 61.82
Episode length: 821.82 +/- 308.06
Eval num_timesteps=120000, episode_reward=-9.36 +/- 109.63
Episode length: 740.83 +/- 304.63
Eval num_timesteps=125000, episode_reward=-48.66 +/- 63.21
Episode length: 710.54 +/- 345.45
Eval num_timesteps=130000, episode_reward=-23.97 +/- 120.57
Episode length: 435.01 +/- 240.25
Eval num_timesteps=135000, episode_reward=5.55 +/- 122.14
Episode length: 351.43 +/- 184.77
Eval num_timesteps=140000, episode_reward=-5.48 +/- 123.74
Episode length: 336.89 +/- 205.19
Eval num_timesteps=145000, episode_reward=-13.61 +/- 120.87
Episode length: 332.22 +/- 205.65
Eval num_timesteps=150000, episode_reward=-25.74 +/- 114.07
Episode length: 334.20 +/- 205.61
FINISHED IN 2481.727424513083 s


starting seed  1012 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-1057.44 +/- 170.21
Episode length: 220.92 +/- 32.79
New best mean reward!
Eval num_timesteps=10000, episode_reward=-211.75 +/- 55.16
Episode length: 930.73 +/- 101.50
New best mean reward!
Eval num_timesteps=15000, episode_reward=-192.78 +/- 68.75
Episode length: 888.68 +/- 140.15
New best mean reward!
Eval num_timesteps=20000, episode_reward=-94.62 +/- 21.23
Episode length: 996.83 +/- 30.46
New best mean reward!
Eval num_timesteps=25000, episode_reward=-60.71 +/- 20.32
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=-47.42 +/- 54.52
Episode length: 979.07 +/- 54.21
New best mean reward!
Eval num_timesteps=35000, episode_reward=-88.42 +/- 80.22
Episode length: 848.49 +/- 199.94
Eval num_timesteps=40000, episode_reward=-1.00 +/- 116.13
Episode length: 625.26 +/- 205.15
New best mean reward!
Eval num_timesteps=45000, episode_reward=-93.18 +/- 58.83
Episode length: 799.79 +/- 280.60
Eval num_timesteps=50000, episode_reward=-72.31 +/- 69.28
Episode length: 794.60 +/- 282.31
Eval num_timesteps=55000, episode_reward=-113.30 +/- 65.02
Episode length: 610.56 +/- 339.48
Eval num_timesteps=60000, episode_reward=-133.43 +/- 41.97
Episode length: 486.23 +/- 315.26
Eval num_timesteps=65000, episode_reward=-143.59 +/- 45.64
Episode length: 485.83 +/- 314.62
Eval num_timesteps=70000, episode_reward=-143.23 +/- 56.39
Episode length: 512.15 +/- 339.04
Eval num_timesteps=75000, episode_reward=-157.32 +/- 43.12
Episode length: 537.48 +/- 330.08
Eval num_timesteps=80000, episode_reward=-75.78 +/- 27.68
Episode length: 788.90 +/- 350.01
Eval num_timesteps=85000, episode_reward=-73.60 +/- 113.62
Episode length: 537.21 +/- 276.83
Eval num_timesteps=90000, episode_reward=-145.93 +/- 56.93
Episode length: 464.70 +/- 309.15
Eval num_timesteps=95000, episode_reward=-108.22 +/- 32.82
Episode length: 651.43 +/- 385.43
Eval num_timesteps=100000, episode_reward=-111.75 +/- 30.62
Episode length: 715.15 +/- 369.05
Eval num_timesteps=105000, episode_reward=-123.51 +/- 40.41
Episode length: 617.41 +/- 374.90
Eval num_timesteps=110000, episode_reward=-119.20 +/- 31.35
Episode length: 551.32 +/- 367.98
Eval num_timesteps=115000, episode_reward=-149.32 +/- 41.80
Episode length: 518.16 +/- 312.68
Eval num_timesteps=120000, episode_reward=-132.73 +/- 35.88
Episode length: 403.15 +/- 276.55
Eval num_timesteps=125000, episode_reward=-139.37 +/- 29.77
Episode length: 399.52 +/- 291.48
Eval num_timesteps=130000, episode_reward=-149.35 +/- 37.82
Episode length: 354.92 +/- 264.89
Eval num_timesteps=135000, episode_reward=-150.90 +/- 31.54
Episode length: 383.34 +/- 267.21
Eval num_timesteps=140000, episode_reward=-149.41 +/- 40.93
Episode length: 370.77 +/- 291.28
Eval num_timesteps=145000, episode_reward=-153.45 +/- 40.88
Episode length: 436.74 +/- 323.07
Eval num_timesteps=150000, episode_reward=-152.73 +/- 36.46
Episode length: 435.70 +/- 323.47
FINISHED IN 3026.4083358310163 s


starting seed  1013 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-292.91 +/- 185.83
Episode length: 605.57 +/- 328.48
New best mean reward!
Eval num_timesteps=10000, episode_reward=-330.75 +/- 22.07
Episode length: 436.55 +/- 62.28
Eval num_timesteps=15000, episode_reward=-236.66 +/- 49.25
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-90.58 +/- 25.14
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-82.89 +/- 21.89
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=-93.19 +/- 25.59
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=-46.49 +/- 20.41
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=40000, episode_reward=-88.89 +/- 20.76
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-57.44 +/- 34.32
Episode length: 998.88 +/- 7.20
Eval num_timesteps=50000, episode_reward=-20.11 +/- 43.05
Episode length: 996.09 +/- 17.56
New best mean reward!
Eval num_timesteps=55000, episode_reward=26.86 +/- 119.80
Episode length: 647.01 +/- 120.98
New best mean reward!
Eval num_timesteps=60000, episode_reward=39.13 +/- 75.53
Episode length: 980.89 +/- 46.38
New best mean reward!
Eval num_timesteps=65000, episode_reward=70.50 +/- 118.81
Episode length: 737.82 +/- 120.45
New best mean reward!
Eval num_timesteps=70000, episode_reward=11.92 +/- 127.63
Episode length: 396.78 +/- 139.51
Eval num_timesteps=75000, episode_reward=-60.04 +/- 88.18
Episode length: 543.98 +/- 276.50
Eval num_timesteps=80000, episode_reward=49.12 +/- 125.64
Episode length: 482.79 +/- 213.44
Eval num_timesteps=85000, episode_reward=-43.83 +/- 106.72
Episode length: 430.03 +/- 211.99
Eval num_timesteps=90000, episode_reward=-82.30 +/- 50.10
Episode length: 596.94 +/- 382.85
Eval num_timesteps=95000, episode_reward=-70.99 +/- 59.54
Episode length: 608.34 +/- 369.26
Eval num_timesteps=100000, episode_reward=-60.97 +/- 48.69
Episode length: 812.96 +/- 315.44
Eval num_timesteps=105000, episode_reward=-67.92 +/- 39.55
Episode length: 728.82 +/- 362.54
Eval num_timesteps=110000, episode_reward=-79.50 +/- 42.81
Episode length: 718.42 +/- 365.27
Eval num_timesteps=115000, episode_reward=-119.00 +/- 55.31
Episode length: 518.77 +/- 322.04
Eval num_timesteps=120000, episode_reward=-108.08 +/- 47.40
Episode length: 563.97 +/- 342.13
Eval num_timesteps=125000, episode_reward=-109.05 +/- 51.28
Episode length: 551.47 +/- 345.89
Eval num_timesteps=130000, episode_reward=-91.23 +/- 54.22
Episode length: 596.22 +/- 359.58
Eval num_timesteps=135000, episode_reward=-102.15 +/- 44.17
Episode length: 556.62 +/- 351.49
Eval num_timesteps=140000, episode_reward=-95.62 +/- 56.70
Episode length: 640.21 +/- 347.10
Eval num_timesteps=145000, episode_reward=-100.08 +/- 49.00
Episode length: 580.19 +/- 346.26
Eval num_timesteps=150000, episode_reward=-102.73 +/- 51.62
Episode length: 606.80 +/- 347.33
FINISHED IN 3507.256494801957 s


starting seed  1014 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-33.46 +/- 24.17
Episode length: 991.42 +/- 85.37
New best mean reward!
Eval num_timesteps=10000, episode_reward=-163.57 +/- 27.89
Episode length: 513.29 +/- 117.01
Eval num_timesteps=15000, episode_reward=-137.61 +/- 25.81
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=-107.23 +/- 26.69
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-112.28 +/- 52.85
Episode length: 839.99 +/- 205.46
Eval num_timesteps=30000, episode_reward=-23.08 +/- 90.36
Episode length: 930.73 +/- 104.84
New best mean reward!
Eval num_timesteps=35000, episode_reward=-22.36 +/- 111.30
Episode length: 366.89 +/- 168.78
New best mean reward!
Eval num_timesteps=40000, episode_reward=-54.02 +/- 104.64
Episode length: 597.96 +/- 252.48
Eval num_timesteps=45000, episode_reward=25.16 +/- 109.53
Episode length: 572.22 +/- 253.27
New best mean reward!
Eval num_timesteps=50000, episode_reward=-44.25 +/- 140.43
Episode length: 427.42 +/- 212.31
Eval num_timesteps=55000, episode_reward=-64.05 +/- 106.76
Episode length: 566.61 +/- 307.73
Eval num_timesteps=60000, episode_reward=-66.55 +/- 40.95
Episode length: 752.62 +/- 344.71
Eval num_timesteps=65000, episode_reward=-74.87 +/- 37.01
Episode length: 671.68 +/- 356.38
Eval num_timesteps=70000, episode_reward=-59.20 +/- 93.21
Episode length: 439.93 +/- 270.59
Eval num_timesteps=75000, episode_reward=2.95 +/- 119.40
Episode length: 410.25 +/- 215.95
Eval num_timesteps=80000, episode_reward=-99.68 +/- 55.01
Episode length: 576.93 +/- 344.43
Eval num_timesteps=85000, episode_reward=-94.33 +/- 53.26
Episode length: 666.56 +/- 335.69
Eval num_timesteps=90000, episode_reward=-122.12 +/- 30.06
Episode length: 529.11 +/- 329.93
Eval num_timesteps=95000, episode_reward=-130.11 +/- 45.85
Episode length: 457.91 +/- 306.54
Eval num_timesteps=100000, episode_reward=-97.38 +/- 61.42
Episode length: 452.09 +/- 303.06
Eval num_timesteps=105000, episode_reward=-86.68 +/- 59.01
Episode length: 455.88 +/- 331.82
Eval num_timesteps=110000, episode_reward=-73.27 +/- 49.96
Episode length: 528.59 +/- 368.15
Eval num_timesteps=115000, episode_reward=-119.01 +/- 45.61
Episode length: 468.70 +/- 339.77
Eval num_timesteps=120000, episode_reward=-102.08 +/- 43.77
Episode length: 466.30 +/- 355.71
Eval num_timesteps=125000, episode_reward=-96.34 +/- 78.18
Episode length: 393.29 +/- 276.91
Eval num_timesteps=130000, episode_reward=-92.45 +/- 46.66
Episode length: 441.35 +/- 350.93
Eval num_timesteps=135000, episode_reward=-92.62 +/- 45.20
Episode length: 454.50 +/- 349.34
Eval num_timesteps=140000, episode_reward=-103.93 +/- 47.82
Episode length: 501.11 +/- 353.01
Eval num_timesteps=145000, episode_reward=-95.46 +/- 71.63
Episode length: 479.32 +/- 345.84
Eval num_timesteps=150000, episode_reward=-105.51 +/- 55.49
Episode length: 479.18 +/- 339.90
FINISHED IN 2877.8700519101694 s


starting seed  1015 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-305.18 +/- 38.75
Episode length: 681.40 +/- 117.91
New best mean reward!
Eval num_timesteps=10000, episode_reward=-301.13 +/- 25.30
Episode length: 625.98 +/- 104.60
New best mean reward!
Eval num_timesteps=15000, episode_reward=-51.45 +/- 47.33
Episode length: 992.88 +/- 24.33
New best mean reward!
Eval num_timesteps=20000, episode_reward=-34.98 +/- 21.84
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=32.28 +/- 120.92
Episode length: 758.51 +/- 183.64
New best mean reward!
Eval num_timesteps=30000, episode_reward=71.51 +/- 99.70
Episode length: 228.60 +/- 110.73
New best mean reward!
Eval num_timesteps=35000, episode_reward=-61.58 +/- 24.70
Episode length: 982.66 +/- 121.38
Eval num_timesteps=40000, episode_reward=84.17 +/- 122.51
Episode length: 606.69 +/- 165.79
New best mean reward!
Eval num_timesteps=45000, episode_reward=-14.20 +/- 82.23
Episode length: 918.51 +/- 130.68
Eval num_timesteps=50000, episode_reward=102.48 +/- 92.68
Episode length: 797.14 +/- 98.03
New best mean reward!
Eval num_timesteps=55000, episode_reward=-76.82 +/- 41.74
Episode length: 903.44 +/- 230.65
Eval num_timesteps=60000, episode_reward=43.64 +/- 120.84
Episode length: 528.66 +/- 193.53
Eval num_timesteps=65000, episode_reward=-140.26 +/- 45.30
Episode length: 753.00 +/- 321.54
Eval num_timesteps=70000, episode_reward=-122.47 +/- 53.45
Episode length: 631.79 +/- 343.94
Eval num_timesteps=75000, episode_reward=-98.50 +/- 69.58
Episode length: 651.72 +/- 328.59
Eval num_timesteps=80000, episode_reward=-101.99 +/- 28.67
Episode length: 771.31 +/- 352.54
Eval num_timesteps=85000, episode_reward=-102.32 +/- 43.96
Episode length: 791.26 +/- 309.82
Eval num_timesteps=90000, episode_reward=-128.66 +/- 24.03
Episode length: 728.79 +/- 361.28
Eval num_timesteps=95000, episode_reward=-34.95 +/- 60.74
Episode length: 885.96 +/- 263.29
Eval num_timesteps=100000, episode_reward=-69.46 +/- 28.56
Episode length: 847.31 +/- 306.44
Eval num_timesteps=105000, episode_reward=-116.68 +/- 27.54
Episode length: 785.34 +/- 329.88
Eval num_timesteps=110000, episode_reward=-108.38 +/- 41.00
Episode length: 636.77 +/- 349.20
Eval num_timesteps=115000, episode_reward=-95.43 +/- 56.82
Episode length: 605.08 +/- 342.11
Eval num_timesteps=120000, episode_reward=-130.90 +/- 37.17
Episode length: 472.40 +/- 328.72
Eval num_timesteps=125000, episode_reward=-127.36 +/- 35.89
Episode length: 533.16 +/- 352.77
Eval num_timesteps=130000, episode_reward=-128.69 +/- 38.28
Episode length: 425.67 +/- 320.68
Eval num_timesteps=135000, episode_reward=-110.27 +/- 48.22
Episode length: 572.18 +/- 356.78
Eval num_timesteps=140000, episode_reward=-125.38 +/- 59.73
Episode length: 482.23 +/- 329.75
Eval num_timesteps=145000, episode_reward=-107.29 +/- 41.66
Episode length: 540.33 +/- 362.30
Eval num_timesteps=150000, episode_reward=-121.61 +/- 37.06
Episode length: 482.63 +/- 337.09
FINISHED IN 3419.447658185847 s


starting seed  1016 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-973.77 +/- 473.92
Episode length: 144.96 +/- 54.32
New best mean reward!
Eval num_timesteps=10000, episode_reward=-1128.52 +/- 234.57
Episode length: 625.93 +/- 104.69
Eval num_timesteps=15000, episode_reward=-304.43 +/- 46.84
Episode length: 670.99 +/- 135.65
New best mean reward!
Eval num_timesteps=20000, episode_reward=-189.96 +/- 26.31
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-173.27 +/- 39.15
Episode length: 517.16 +/- 202.89
New best mean reward!
Eval num_timesteps=30000, episode_reward=-145.01 +/- 58.29
Episode length: 823.96 +/- 227.87
New best mean reward!
Eval num_timesteps=35000, episode_reward=-102.12 +/- 53.95
Episode length: 821.97 +/- 215.84
New best mean reward!
Eval num_timesteps=40000, episode_reward=-120.07 +/- 47.35
Episode length: 947.05 +/- 150.98
Eval num_timesteps=45000, episode_reward=-82.69 +/- 39.01
Episode length: 933.38 +/- 160.90
New best mean reward!
Eval num_timesteps=50000, episode_reward=-146.42 +/- 64.38
Episode length: 787.72 +/- 246.69
Eval num_timesteps=55000, episode_reward=-116.98 +/- 58.99
Episode length: 834.38 +/- 269.18
Eval num_timesteps=60000, episode_reward=-102.88 +/- 27.27
Episode length: 949.16 +/- 182.18
Eval num_timesteps=65000, episode_reward=-88.10 +/- 95.33
Episode length: 579.54 +/- 285.99
Eval num_timesteps=70000, episode_reward=-152.29 +/- 47.00
Episode length: 566.71 +/- 329.51
Eval num_timesteps=75000, episode_reward=-117.27 +/- 64.53
Episode length: 450.58 +/- 289.30
Eval num_timesteps=80000, episode_reward=-72.79 +/- 50.27
Episode length: 721.99 +/- 337.90
New best mean reward!
Eval num_timesteps=85000, episode_reward=-121.06 +/- 35.76
Episode length: 540.61 +/- 348.58
Eval num_timesteps=90000, episode_reward=-148.40 +/- 40.35
Episode length: 389.81 +/- 290.57
Eval num_timesteps=95000, episode_reward=-120.88 +/- 40.58
Episode length: 554.67 +/- 359.78
Eval num_timesteps=100000, episode_reward=-161.75 +/- 53.08
Episode length: 500.01 +/- 340.69
Eval num_timesteps=105000, episode_reward=-158.18 +/- 50.36
Episode length: 505.12 +/- 313.61
Eval num_timesteps=110000, episode_reward=-132.71 +/- 31.59
Episode length: 563.15 +/- 364.67
Eval num_timesteps=115000, episode_reward=-121.26 +/- 37.94
Episode length: 501.26 +/- 359.88
Eval num_timesteps=120000, episode_reward=-130.00 +/- 35.05
Episode length: 502.97 +/- 358.60
Eval num_timesteps=125000, episode_reward=-150.36 +/- 38.99
Episode length: 416.65 +/- 302.18
Eval num_timesteps=130000, episode_reward=-148.28 +/- 35.32
Episode length: 445.43 +/- 317.13
Eval num_timesteps=135000, episode_reward=-149.55 +/- 36.12
Episode length: 456.04 +/- 332.14
Eval num_timesteps=140000, episode_reward=-157.05 +/- 50.09
Episode length: 430.40 +/- 305.95
Eval num_timesteps=145000, episode_reward=-136.93 +/- 36.70
Episode length: 426.05 +/- 324.78
Eval num_timesteps=150000, episode_reward=-138.35 +/- 39.65
Episode length: 459.77 +/- 344.50
FINISHED IN 2972.6550268437713 s


starting seed  1017 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-211.48 +/- 92.99
Episode length: 814.54 +/- 204.58
New best mean reward!
Eval num_timesteps=10000, episode_reward=-122.00 +/- 100.75
Episode length: 930.57 +/- 121.72
New best mean reward!
Eval num_timesteps=15000, episode_reward=-120.05 +/- 41.55
Episode length: 204.67 +/- 61.34
New best mean reward!
Eval num_timesteps=20000, episode_reward=-104.85 +/- 73.54
Episode length: 898.59 +/- 163.81
New best mean reward!
Eval num_timesteps=25000, episode_reward=-105.49 +/- 52.82
Episode length: 642.79 +/- 323.93
Eval num_timesteps=30000, episode_reward=-38.41 +/- 136.77
Episode length: 406.90 +/- 153.82
New best mean reward!
Eval num_timesteps=35000, episode_reward=-8.51 +/- 122.44
Episode length: 719.51 +/- 232.85
New best mean reward!
Eval num_timesteps=40000, episode_reward=-161.85 +/- 57.58
Episode length: 669.96 +/- 290.90
Eval num_timesteps=45000, episode_reward=-42.36 +/- 50.02
Episode length: 991.90 +/- 38.57
Eval num_timesteps=50000, episode_reward=-49.40 +/- 114.61
Episode length: 887.06 +/- 169.24
Eval num_timesteps=55000, episode_reward=-24.38 +/- 133.57
Episode length: 621.21 +/- 170.42
Eval num_timesteps=60000, episode_reward=-19.02 +/- 132.31
Episode length: 579.85 +/- 224.92
Eval num_timesteps=65000, episode_reward=-33.34 +/- 87.17
Episode length: 732.09 +/- 286.49
Eval num_timesteps=70000, episode_reward=-44.17 +/- 39.68
Episode length: 895.59 +/- 254.06
Eval num_timesteps=75000, episode_reward=-124.59 +/- 43.56
Episode length: 526.00 +/- 287.44
Eval num_timesteps=80000, episode_reward=-69.27 +/- 91.84
Episode length: 506.66 +/- 282.29
Eval num_timesteps=85000, episode_reward=-71.37 +/- 62.29
Episode length: 662.16 +/- 355.61
Eval num_timesteps=90000, episode_reward=-104.96 +/- 42.93
Episode length: 368.72 +/- 279.53
Eval num_timesteps=95000, episode_reward=-131.97 +/- 30.95
Episode length: 328.80 +/- 218.55
Eval num_timesteps=100000, episode_reward=-117.04 +/- 40.15
Episode length: 514.70 +/- 346.17
Eval num_timesteps=105000, episode_reward=-102.69 +/- 33.42
Episode length: 494.76 +/- 349.36
Eval num_timesteps=110000, episode_reward=-94.98 +/- 44.13
Episode length: 535.14 +/- 361.80
Eval num_timesteps=115000, episode_reward=-94.93 +/- 57.18
Episode length: 498.88 +/- 335.91
Eval num_timesteps=120000, episode_reward=-131.27 +/- 35.19
Episode length: 453.66 +/- 344.04
Eval num_timesteps=125000, episode_reward=-108.85 +/- 27.03
Episode length: 523.00 +/- 367.45
Eval num_timesteps=130000, episode_reward=-102.69 +/- 49.17
Episode length: 442.28 +/- 321.24
Eval num_timesteps=135000, episode_reward=-78.39 +/- 72.68
Episode length: 467.36 +/- 340.83
Eval num_timesteps=140000, episode_reward=-99.54 +/- 42.41
Episode length: 378.12 +/- 299.44
Eval num_timesteps=145000, episode_reward=-106.83 +/- 37.11
Episode length: 473.97 +/- 362.14
Eval num_timesteps=150000, episode_reward=-101.02 +/- 40.72
Episode length: 453.91 +/- 355.24
FINISHED IN 3073.6090433681384 s


starting seed  1018 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-227.05 +/- 85.90
Episode length: 501.93 +/- 176.55
New best mean reward!
Eval num_timesteps=10000, episode_reward=79.71 +/- 83.80
Episode length: 514.66 +/- 360.92
New best mean reward!
Eval num_timesteps=15000, episode_reward=-70.97 +/- 88.39
Episode length: 806.70 +/- 315.54
Eval num_timesteps=20000, episode_reward=-90.71 +/- 23.81
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-45.82 +/- 22.46
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=30000, episode_reward=30.29 +/- 131.14
Episode length: 314.81 +/- 89.90
Eval num_timesteps=35000, episode_reward=-67.10 +/- 24.20
Episode length: 998.87 +/- 11.24
Eval num_timesteps=40000, episode_reward=-19.80 +/- 116.16
Episode length: 515.82 +/- 253.55
Eval num_timesteps=45000, episode_reward=-119.71 +/- 59.80
Episode length: 578.38 +/- 329.47
Eval num_timesteps=50000, episode_reward=-69.34 +/- 88.18
Episode length: 545.04 +/- 345.76
Eval num_timesteps=55000, episode_reward=-27.92 +/- 99.18
Episode length: 465.16 +/- 332.23
Eval num_timesteps=60000, episode_reward=-95.00 +/- 35.12
Episode length: 723.51 +/- 350.13
Eval num_timesteps=65000, episode_reward=-108.61 +/- 25.14
Episode length: 629.89 +/- 376.82
Eval num_timesteps=70000, episode_reward=-100.38 +/- 40.43
Episode length: 457.30 +/- 344.55
Eval num_timesteps=75000, episode_reward=-19.03 +/- 97.86
Episode length: 702.64 +/- 310.61
Eval num_timesteps=80000, episode_reward=-2.84 +/- 100.38
Episode length: 586.49 +/- 330.10
Eval num_timesteps=85000, episode_reward=19.26 +/- 118.31
Episode length: 451.92 +/- 291.28
Eval num_timesteps=90000, episode_reward=-106.76 +/- 40.80
Episode length: 523.29 +/- 358.07
Eval num_timesteps=95000, episode_reward=-56.76 +/- 87.57
Episode length: 584.65 +/- 339.23
Eval num_timesteps=100000, episode_reward=-67.13 +/- 66.26
Episode length: 502.36 +/- 340.71
Eval num_timesteps=105000, episode_reward=17.77 +/- 114.34
Episode length: 454.30 +/- 232.85
Eval num_timesteps=110000, episode_reward=-62.63 +/- 56.74
Episode length: 612.44 +/- 363.07
Eval num_timesteps=115000, episode_reward=-52.83 +/- 65.94
Episode length: 686.12 +/- 358.65
Eval num_timesteps=120000, episode_reward=-25.03 +/- 91.85
Episode length: 546.21 +/- 329.13
