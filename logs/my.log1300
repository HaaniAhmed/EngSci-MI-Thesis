nohup: ignoring input


starting seed  1300 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-257.41 +/- 119.19
Episode length: 278.35 +/- 79.47
New best mean reward!
Eval num_timesteps=10000, episode_reward=-247.49 +/- 124.54
Episode length: 760.50 +/- 161.11
New best mean reward!
Eval num_timesteps=15000, episode_reward=-151.58 +/- 28.71
Episode length: 394.16 +/- 105.21
New best mean reward!
Eval num_timesteps=20000, episode_reward=-73.47 +/- 118.75
Episode length: 419.06 +/- 164.87
New best mean reward!
Eval num_timesteps=25000, episode_reward=-138.68 +/- 65.89
Episode length: 761.06 +/- 224.71
Eval num_timesteps=30000, episode_reward=-134.45 +/- 56.29
Episode length: 767.16 +/- 255.41
Eval num_timesteps=35000, episode_reward=-102.04 +/- 26.27
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-76.09 +/- 27.66
Episode length: 995.50 +/- 37.78
Eval num_timesteps=45000, episode_reward=-74.99 +/- 25.52
Episode length: 996.82 +/- 23.53
Eval num_timesteps=50000, episode_reward=-94.04 +/- 29.29
Episode length: 995.66 +/- 27.27
Eval num_timesteps=55000, episode_reward=-96.33 +/- 25.33
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-111.35 +/- 26.90
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=65000, episode_reward=-25.79 +/- 24.48
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=70000, episode_reward=-58.62 +/- 27.81
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=75000, episode_reward=-46.22 +/- 24.14
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=80000, episode_reward=-10.02 +/- 40.43
Episode length: 996.26 +/- 23.94
New best mean reward!
Eval num_timesteps=85000, episode_reward=16.36 +/- 55.73
Episode length: 988.89 +/- 35.76
New best mean reward!
Eval num_timesteps=90000, episode_reward=181.33 +/- 57.89
Episode length: 648.15 +/- 106.96
New best mean reward!
Eval num_timesteps=95000, episode_reward=44.35 +/- 81.77
Episode length: 952.35 +/- 88.24
Eval num_timesteps=100000, episode_reward=144.70 +/- 101.35
Episode length: 592.29 +/- 161.08
Eval num_timesteps=105000, episode_reward=125.53 +/- 113.23
Episode length: 628.95 +/- 219.45
Eval num_timesteps=110000, episode_reward=101.55 +/- 111.69
Episode length: 691.82 +/- 236.42
Eval num_timesteps=115000, episode_reward=96.89 +/- 142.29
Episode length: 588.88 +/- 276.51
Eval num_timesteps=120000, episode_reward=108.49 +/- 118.02
Episode length: 515.25 +/- 241.65
Eval num_timesteps=125000, episode_reward=75.60 +/- 120.19
Episode length: 504.37 +/- 212.46
Eval num_timesteps=130000, episode_reward=94.67 +/- 125.37
Episode length: 501.85 +/- 230.02
Eval num_timesteps=135000, episode_reward=91.58 +/- 120.35
Episode length: 563.41 +/- 244.70
Eval num_timesteps=140000, episode_reward=70.91 +/- 120.61
Episode length: 564.95 +/- 235.43
Eval num_timesteps=145000, episode_reward=86.31 +/- 117.07
Episode length: 552.04 +/- 211.55
Eval num_timesteps=150000, episode_reward=81.81 +/- 111.33
Episode length: 636.26 +/- 239.42
FINISHED IN 3933.742892761249 s


starting seed  1301 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-33.84 +/- 130.28
Episode length: 268.10 +/- 163.41
New best mean reward!
Eval num_timesteps=10000, episode_reward=-156.37 +/- 58.98
Episode length: 715.86 +/- 141.57
Eval num_timesteps=15000, episode_reward=-147.88 +/- 56.75
Episode length: 883.29 +/- 170.32
Eval num_timesteps=20000, episode_reward=-84.60 +/- 118.01
Episode length: 718.61 +/- 206.16
Eval num_timesteps=25000, episode_reward=-114.06 +/- 60.09
Episode length: 924.95 +/- 158.59
Eval num_timesteps=30000, episode_reward=-75.06 +/- 94.60
Episode length: 404.88 +/- 122.00
Eval num_timesteps=35000, episode_reward=-52.37 +/- 92.88
Episode length: 793.60 +/- 213.69
Eval num_timesteps=40000, episode_reward=-57.33 +/- 97.82
Episode length: 510.65 +/- 156.46
Eval num_timesteps=45000, episode_reward=1.35 +/- 125.81
Episode length: 781.42 +/- 222.68
New best mean reward!
Eval num_timesteps=50000, episode_reward=-110.53 +/- 82.46
Episode length: 476.07 +/- 208.73
Eval num_timesteps=55000, episode_reward=-135.42 +/- 57.78
Episode length: 549.60 +/- 293.68
Eval num_timesteps=60000, episode_reward=-125.29 +/- 49.43
Episode length: 787.57 +/- 283.33
Eval num_timesteps=65000, episode_reward=-138.69 +/- 45.81
Episode length: 629.55 +/- 299.33
Eval num_timesteps=70000, episode_reward=-108.76 +/- 46.64
Episode length: 607.60 +/- 323.71
Eval num_timesteps=75000, episode_reward=-155.25 +/- 46.98
Episode length: 483.45 +/- 308.91
Eval num_timesteps=80000, episode_reward=-154.23 +/- 46.10
Episode length: 481.18 +/- 300.11
Eval num_timesteps=85000, episode_reward=-109.95 +/- 40.35
Episode length: 675.25 +/- 349.06
Eval num_timesteps=90000, episode_reward=-111.49 +/- 46.87
Episode length: 583.87 +/- 349.20
Eval num_timesteps=95000, episode_reward=-108.98 +/- 44.90
Episode length: 586.18 +/- 372.52
Eval num_timesteps=100000, episode_reward=-133.15 +/- 39.99
Episode length: 484.32 +/- 300.57
Eval num_timesteps=105000, episode_reward=-61.58 +/- 60.36
Episode length: 570.98 +/- 354.97
Eval num_timesteps=110000, episode_reward=-84.72 +/- 63.46
Episode length: 489.99 +/- 317.59
Eval num_timesteps=115000, episode_reward=-93.51 +/- 44.73
Episode length: 542.58 +/- 366.18
Eval num_timesteps=120000, episode_reward=-38.10 +/- 106.04
Episode length: 482.80 +/- 275.13
Eval num_timesteps=125000, episode_reward=7.44 +/- 123.91
Episode length: 471.85 +/- 226.56
New best mean reward!
Eval num_timesteps=130000, episode_reward=-45.55 +/- 94.32
Episode length: 401.59 +/- 238.36
Eval num_timesteps=135000, episode_reward=-8.47 +/- 108.01
Episode length: 413.64 +/- 211.22
Eval num_timesteps=140000, episode_reward=-29.19 +/- 108.16
Episode length: 394.46 +/- 204.22
Eval num_timesteps=145000, episode_reward=-4.72 +/- 109.12
Episode length: 388.45 +/- 206.32
Eval num_timesteps=150000, episode_reward=-36.58 +/- 91.42
Episode length: 380.93 +/- 229.57
FINISHED IN 3007.5346245560795 s


starting seed  1302 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-571.17 +/- 140.20
Episode length: 67.15 +/- 11.08
New best mean reward!
Eval num_timesteps=10000, episode_reward=-592.84 +/- 168.80
Episode length: 68.08 +/- 12.49
Eval num_timesteps=15000, episode_reward=-850.86 +/- 458.53
Episode length: 125.43 +/- 50.89
Eval num_timesteps=20000, episode_reward=-519.61 +/- 30.84
Episode length: 494.31 +/- 63.57
New best mean reward!
Eval num_timesteps=25000, episode_reward=-345.19 +/- 23.69
Episode length: 553.93 +/- 62.34
New best mean reward!
Eval num_timesteps=30000, episode_reward=-75.68 +/- 41.85
Episode length: 995.61 +/- 18.52
New best mean reward!
Eval num_timesteps=35000, episode_reward=-83.25 +/- 24.36
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-39.69 +/- 20.69
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=45000, episode_reward=-16.43 +/- 20.39
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=50000, episode_reward=-17.66 +/- 24.14
Episode length: 998.65 +/- 13.43
Eval num_timesteps=55000, episode_reward=-10.49 +/- 37.77
Episode length: 995.19 +/- 33.53
New best mean reward!
Eval num_timesteps=60000, episode_reward=-48.87 +/- 78.94
Episode length: 939.16 +/- 94.94
Eval num_timesteps=65000, episode_reward=-23.12 +/- 97.12
Episode length: 897.03 +/- 119.35
Eval num_timesteps=70000, episode_reward=59.48 +/- 79.63
Episode length: 865.65 +/- 153.90
New best mean reward!
Eval num_timesteps=75000, episode_reward=143.16 +/- 77.46
Episode length: 736.96 +/- 100.40
New best mean reward!
Eval num_timesteps=80000, episode_reward=73.17 +/- 102.39
Episode length: 877.65 +/- 102.98
Eval num_timesteps=85000, episode_reward=140.81 +/- 78.96
Episode length: 759.18 +/- 87.61
Eval num_timesteps=90000, episode_reward=5.65 +/- 89.34
Episode length: 942.80 +/- 89.79
Eval num_timesteps=95000, episode_reward=-37.33 +/- 21.58
Episode length: 998.65 +/- 13.43
Eval num_timesteps=100000, episode_reward=-38.64 +/- 21.87
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=105000, episode_reward=13.09 +/- 89.25
Episode length: 937.78 +/- 88.91
Eval num_timesteps=110000, episode_reward=110.36 +/- 73.55
Episode length: 876.40 +/- 127.05
Eval num_timesteps=115000, episode_reward=-1.53 +/- 59.14
Episode length: 977.71 +/- 58.81
Eval num_timesteps=120000, episode_reward=-49.51 +/- 37.97
Episode length: 999.27 +/- 6.42
Eval num_timesteps=125000, episode_reward=-34.64 +/- 48.64
Episode length: 987.97 +/- 47.69
Eval num_timesteps=130000, episode_reward=34.50 +/- 79.13
Episode length: 926.39 +/- 130.78
Eval num_timesteps=135000, episode_reward=37.84 +/- 90.26
Episode length: 920.81 +/- 123.36
Eval num_timesteps=140000, episode_reward=31.68 +/- 83.53
Episode length: 919.82 +/- 116.68
Eval num_timesteps=145000, episode_reward=52.23 +/- 93.28
Episode length: 868.43 +/- 158.04
Eval num_timesteps=150000, episode_reward=56.47 +/- 96.26
Episode length: 860.66 +/- 148.64
FINISHED IN 4153.563716843259 s


starting seed  1303 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-811.89 +/- 394.15
Episode length: 122.73 +/- 44.98
New best mean reward!
Eval num_timesteps=10000, episode_reward=-150.99 +/- 74.06
Episode length: 188.73 +/- 67.88
New best mean reward!
Eval num_timesteps=15000, episode_reward=-9.52 +/- 77.99
Episode length: 891.90 +/- 248.89
New best mean reward!
Eval num_timesteps=20000, episode_reward=-129.70 +/- 26.80
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=74.84 +/- 124.24
Episode length: 692.36 +/- 129.39
New best mean reward!
Eval num_timesteps=30000, episode_reward=110.21 +/- 127.58
Episode length: 517.71 +/- 95.15
New best mean reward!
Eval num_timesteps=35000, episode_reward=-0.26 +/- 52.96
Episode length: 158.88 +/- 27.63
Eval num_timesteps=40000, episode_reward=2.11 +/- 33.22
Episode length: 149.23 +/- 28.40
Eval num_timesteps=45000, episode_reward=31.95 +/- 102.10
Episode length: 241.62 +/- 111.73
Eval num_timesteps=50000, episode_reward=-3.55 +/- 97.17
Episode length: 191.87 +/- 65.44
Eval num_timesteps=55000, episode_reward=-17.93 +/- 75.72
Episode length: 946.60 +/- 106.82
Eval num_timesteps=60000, episode_reward=-99.92 +/- 47.97
Episode length: 944.61 +/- 130.50
Eval num_timesteps=65000, episode_reward=-162.53 +/- 42.93
Episode length: 894.00 +/- 184.50
Eval num_timesteps=70000, episode_reward=-137.35 +/- 47.76
Episode length: 777.44 +/- 289.81
Eval num_timesteps=75000, episode_reward=-85.07 +/- 22.10
Episode length: 971.56 +/- 143.63
Eval num_timesteps=80000, episode_reward=-105.13 +/- 41.91
Episode length: 948.74 +/- 147.72
Eval num_timesteps=85000, episode_reward=-72.57 +/- 50.06
Episode length: 915.57 +/- 177.47
Eval num_timesteps=90000, episode_reward=-72.21 +/- 30.22
Episode length: 876.88 +/- 274.48
Eval num_timesteps=95000, episode_reward=-123.23 +/- 57.77
Episode length: 717.23 +/- 315.69
Eval num_timesteps=100000, episode_reward=-80.06 +/- 24.49
Episode length: 928.82 +/- 209.75
Eval num_timesteps=105000, episode_reward=-98.54 +/- 47.79
Episode length: 778.43 +/- 293.17
Eval num_timesteps=110000, episode_reward=-56.64 +/- 36.98
Episode length: 962.01 +/- 139.56
Eval num_timesteps=115000, episode_reward=-112.02 +/- 40.32
Episode length: 515.55 +/- 296.06
Eval num_timesteps=120000, episode_reward=-98.54 +/- 37.48
Episode length: 673.62 +/- 342.49
Eval num_timesteps=125000, episode_reward=-73.01 +/- 33.39
Episode length: 825.49 +/- 313.67
Eval num_timesteps=130000, episode_reward=-81.31 +/- 41.39
Episode length: 724.03 +/- 369.93
Eval num_timesteps=135000, episode_reward=-83.82 +/- 45.37
Episode length: 709.89 +/- 356.90
Eval num_timesteps=140000, episode_reward=-91.75 +/- 34.41
Episode length: 661.63 +/- 349.09
Eval num_timesteps=145000, episode_reward=-92.87 +/- 36.74
Episode length: 705.07 +/- 333.67
Eval num_timesteps=150000, episode_reward=-93.72 +/- 33.47
Episode length: 674.91 +/- 348.09
FINISHED IN 5642.547939028591 s


starting seed  1304 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-186.35 +/- 22.70
Episode length: 265.52 +/- 65.57
New best mean reward!
Eval num_timesteps=10000, episode_reward=-146.69 +/- 27.73
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=-114.85 +/- 27.99
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-112.27 +/- 55.63
Episode length: 920.22 +/- 148.19
New best mean reward!
Eval num_timesteps=25000, episode_reward=-65.23 +/- 25.32
Episode length: 995.35 +/- 35.81
New best mean reward!
Eval num_timesteps=30000, episode_reward=-93.05 +/- 28.74
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=-63.04 +/- 20.74
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=40000, episode_reward=28.39 +/- 112.12
Episode length: 673.72 +/- 195.46
New best mean reward!
Eval num_timesteps=45000, episode_reward=-76.54 +/- 34.98
Episode length: 931.29 +/- 199.63
Eval num_timesteps=50000, episode_reward=-51.84 +/- 53.51
Episode length: 944.12 +/- 160.58
Eval num_timesteps=55000, episode_reward=-142.29 +/- 49.76
Episode length: 540.66 +/- 286.60
Eval num_timesteps=60000, episode_reward=-72.74 +/- 49.59
Episode length: 861.28 +/- 257.19
Eval num_timesteps=65000, episode_reward=-82.46 +/- 34.17
Episode length: 747.90 +/- 331.54
Eval num_timesteps=70000, episode_reward=-33.84 +/- 100.21
Episode length: 608.99 +/- 303.80
Eval num_timesteps=75000, episode_reward=-89.02 +/- 65.05
Episode length: 490.69 +/- 321.00
Eval num_timesteps=80000, episode_reward=-69.28 +/- 62.85
Episode length: 626.86 +/- 349.66
Eval num_timesteps=85000, episode_reward=-9.07 +/- 92.65
Episode length: 512.86 +/- 310.43
Eval num_timesteps=90000, episode_reward=-102.06 +/- 45.50
Episode length: 361.39 +/- 282.93
Eval num_timesteps=95000, episode_reward=-55.80 +/- 81.78
Episode length: 375.64 +/- 266.98
Eval num_timesteps=100000, episode_reward=-68.27 +/- 76.90
Episode length: 540.16 +/- 320.50
Eval num_timesteps=105000, episode_reward=-96.64 +/- 35.21
Episode length: 731.00 +/- 365.01
Eval num_timesteps=110000, episode_reward=-130.19 +/- 52.93
Episode length: 525.87 +/- 329.48
Eval num_timesteps=115000, episode_reward=-113.01 +/- 39.45
Episode length: 488.75 +/- 343.30
Eval num_timesteps=120000, episode_reward=-104.41 +/- 67.33
Episode length: 569.25 +/- 347.34
Eval num_timesteps=125000, episode_reward=-110.80 +/- 71.83
Episode length: 508.06 +/- 338.29
Eval num_timesteps=130000, episode_reward=-74.21 +/- 67.83
Episode length: 569.03 +/- 355.11
Eval num_timesteps=135000, episode_reward=-90.52 +/- 50.73
Episode length: 514.46 +/- 352.69
Eval num_timesteps=140000, episode_reward=-98.24 +/- 67.59
Episode length: 459.67 +/- 329.70
Eval num_timesteps=145000, episode_reward=-80.06 +/- 66.39
Episode length: 450.21 +/- 323.17
Eval num_timesteps=150000, episode_reward=-86.50 +/- 69.99
Episode length: 401.88 +/- 293.39
FINISHED IN 3101.8336565210484 s


starting seed  1305 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-463.88 +/- 210.52
Episode length: 169.49 +/- 36.17
New best mean reward!
Eval num_timesteps=10000, episode_reward=-224.26 +/- 27.33
Episode length: 432.36 +/- 77.31
New best mean reward!
Eval num_timesteps=15000, episode_reward=-52.32 +/- 74.80
Episode length: 961.22 +/- 79.59
New best mean reward!
Eval num_timesteps=20000, episode_reward=-72.22 +/- 20.33
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-73.29 +/- 30.25
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=30000, episode_reward=50.56 +/- 115.46
Episode length: 729.42 +/- 158.83
New best mean reward!
Eval num_timesteps=35000, episode_reward=-130.48 +/- 59.63
Episode length: 651.23 +/- 275.27
Eval num_timesteps=40000, episode_reward=92.39 +/- 115.73
Episode length: 684.92 +/- 118.62
New best mean reward!
Eval num_timesteps=45000, episode_reward=-36.22 +/- 80.58
Episode length: 904.80 +/- 166.48
Eval num_timesteps=50000, episode_reward=74.83 +/- 129.83
Episode length: 425.55 +/- 136.18
Eval num_timesteps=55000, episode_reward=49.85 +/- 128.63
Episode length: 485.67 +/- 189.67
Eval num_timesteps=60000, episode_reward=-56.88 +/- 92.19
Episode length: 687.17 +/- 334.19
Eval num_timesteps=65000, episode_reward=-84.43 +/- 72.87
Episode length: 491.79 +/- 311.74
Eval num_timesteps=70000, episode_reward=-104.40 +/- 51.97
Episode length: 514.30 +/- 331.40
Eval num_timesteps=75000, episode_reward=-134.65 +/- 44.87
Episode length: 558.95 +/- 332.21
Eval num_timesteps=80000, episode_reward=-89.99 +/- 52.07
Episode length: 826.68 +/- 306.45
Eval num_timesteps=85000, episode_reward=4.52 +/- 110.98
Episode length: 697.74 +/- 292.66
Eval num_timesteps=90000, episode_reward=-59.96 +/- 105.24
Episode length: 615.64 +/- 307.63
Eval num_timesteps=95000, episode_reward=0.73 +/- 121.05
Episode length: 368.00 +/- 177.56
Eval num_timesteps=100000, episode_reward=-5.51 +/- 118.87
Episode length: 309.78 +/- 164.23
Eval num_timesteps=105000, episode_reward=-0.35 +/- 124.92
Episode length: 374.86 +/- 172.54
Eval num_timesteps=110000, episode_reward=-43.53 +/- 87.28
Episode length: 653.75 +/- 330.58
Eval num_timesteps=115000, episode_reward=-42.36 +/- 76.23
Episode length: 644.69 +/- 348.31
Eval num_timesteps=120000, episode_reward=-10.53 +/- 101.98
Episode length: 637.69 +/- 311.44
Eval num_timesteps=125000, episode_reward=-34.08 +/- 98.45
Episode length: 566.74 +/- 330.71
Eval num_timesteps=130000, episode_reward=-67.53 +/- 78.71
Episode length: 466.45 +/- 312.21
Eval num_timesteps=135000, episode_reward=-47.15 +/- 95.41
Episode length: 517.56 +/- 304.99
Eval num_timesteps=140000, episode_reward=-43.76 +/- 88.97
Episode length: 647.93 +/- 361.47
Eval num_timesteps=145000, episode_reward=-44.18 +/- 96.48
Episode length: 506.52 +/- 324.57
Eval num_timesteps=150000, episode_reward=-20.24 +/- 95.81
Episode length: 600.44 +/- 330.34
FINISHED IN 2916.0689013949595 s


starting seed  1306 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-449.01 +/- 35.32
Episode length: 259.65 +/- 65.14
New best mean reward!
Eval num_timesteps=10000, episode_reward=-256.04 +/- 30.29
Episode length: 376.68 +/- 92.28
New best mean reward!
Eval num_timesteps=15000, episode_reward=-88.85 +/- 23.55
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-8.87 +/- 72.45
Episode length: 969.76 +/- 67.16
New best mean reward!
Eval num_timesteps=25000, episode_reward=101.42 +/- 102.19
Episode length: 764.15 +/- 111.27
New best mean reward!
Eval num_timesteps=30000, episode_reward=149.67 +/- 97.39
Episode length: 542.87 +/- 133.39
New best mean reward!
Eval num_timesteps=35000, episode_reward=-34.58 +/- 107.47
Episode length: 450.01 +/- 139.79
Eval num_timesteps=40000, episode_reward=-37.28 +/- 54.28
Episode length: 988.25 +/- 39.40
Eval num_timesteps=45000, episode_reward=-45.54 +/- 24.17
Episode length: 999.77 +/- 2.29
Eval num_timesteps=50000, episode_reward=-106.13 +/- 24.04
Episode length: 987.96 +/- 87.56
Eval num_timesteps=55000, episode_reward=9.66 +/- 128.49
Episode length: 435.39 +/- 179.17
Eval num_timesteps=60000, episode_reward=-30.14 +/- 114.64
Episode length: 510.04 +/- 260.02
Eval num_timesteps=65000, episode_reward=-68.73 +/- 107.33
Episode length: 537.24 +/- 224.24
Eval num_timesteps=70000, episode_reward=-29.94 +/- 114.74
Episode length: 542.25 +/- 249.05
Eval num_timesteps=75000, episode_reward=38.95 +/- 122.41
Episode length: 581.16 +/- 216.43
Eval num_timesteps=80000, episode_reward=-20.72 +/- 102.23
Episode length: 746.72 +/- 226.82
Eval num_timesteps=85000, episode_reward=19.74 +/- 124.46
Episode length: 760.07 +/- 214.26
Eval num_timesteps=90000, episode_reward=-45.29 +/- 98.30
Episode length: 578.89 +/- 311.77
Eval num_timesteps=95000, episode_reward=-68.50 +/- 141.58
Episode length: 538.92 +/- 255.25
Eval num_timesteps=100000, episode_reward=-64.84 +/- 108.10
Episode length: 595.77 +/- 292.14
Eval num_timesteps=105000, episode_reward=-100.56 +/- 68.84
Episode length: 435.02 +/- 273.53
Eval num_timesteps=110000, episode_reward=-69.26 +/- 101.81
Episode length: 359.36 +/- 205.09
Eval num_timesteps=115000, episode_reward=-93.37 +/- 97.11
Episode length: 341.03 +/- 187.01
Eval num_timesteps=120000, episode_reward=-97.81 +/- 97.04
Episode length: 377.60 +/- 219.64
Eval num_timesteps=125000, episode_reward=-117.10 +/- 101.98
Episode length: 409.39 +/- 240.62
Eval num_timesteps=130000, episode_reward=-119.60 +/- 80.40
Episode length: 326.61 +/- 194.03
Eval num_timesteps=135000, episode_reward=-113.27 +/- 92.17
Episode length: 361.77 +/- 270.08
Eval num_timesteps=140000, episode_reward=-109.59 +/- 95.20
Episode length: 383.40 +/- 242.59
Eval num_timesteps=145000, episode_reward=-92.57 +/- 106.64
Episode length: 415.45 +/- 254.90
Eval num_timesteps=150000, episode_reward=-112.64 +/- 86.14
Episode length: 339.84 +/- 226.93
FINISHED IN 2695.934428760782 s


starting seed  1307 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-611.45 +/- 175.70
Episode length: 69.44 +/- 13.50
New best mean reward!
Eval num_timesteps=10000, episode_reward=-577.47 +/- 169.62
Episode length: 67.00 +/- 13.79
New best mean reward!
Eval num_timesteps=15000, episode_reward=-750.53 +/- 238.37
Episode length: 205.64 +/- 70.21
Eval num_timesteps=20000, episode_reward=-1265.00 +/- 486.34
Episode length: 575.25 +/- 197.56
Eval num_timesteps=25000, episode_reward=-121.13 +/- 101.30
Episode length: 642.26 +/- 349.30
New best mean reward!
Eval num_timesteps=30000, episode_reward=67.92 +/- 112.57
Episode length: 704.99 +/- 238.51
New best mean reward!
Eval num_timesteps=35000, episode_reward=-9.51 +/- 88.93
Episode length: 161.88 +/- 100.28
Eval num_timesteps=40000, episode_reward=-24.02 +/- 42.72
Episode length: 126.94 +/- 23.97
Eval num_timesteps=45000, episode_reward=-70.33 +/- 44.73
Episode length: 989.03 +/- 40.96
Eval num_timesteps=50000, episode_reward=-138.89 +/- 54.36
Episode length: 966.51 +/- 111.12
Eval num_timesteps=55000, episode_reward=-187.69 +/- 55.17
Episode length: 597.89 +/- 229.25
Eval num_timesteps=60000, episode_reward=-57.71 +/- 35.29
Episode length: 994.21 +/- 29.43
Eval num_timesteps=65000, episode_reward=8.96 +/- 108.75
Episode length: 811.86 +/- 184.42
Eval num_timesteps=70000, episode_reward=-16.21 +/- 100.96
Episode length: 794.75 +/- 235.24
Eval num_timesteps=75000, episode_reward=-52.16 +/- 59.84
Episode length: 925.37 +/- 166.33
Eval num_timesteps=80000, episode_reward=7.03 +/- 118.60
Episode length: 470.69 +/- 174.59
Eval num_timesteps=85000, episode_reward=-72.23 +/- 102.23
Episode length: 465.66 +/- 216.57
Eval num_timesteps=90000, episode_reward=-0.71 +/- 118.15
Episode length: 609.90 +/- 214.13
Eval num_timesteps=95000, episode_reward=37.58 +/- 124.01
Episode length: 434.90 +/- 140.13
Eval num_timesteps=100000, episode_reward=-118.91 +/- 58.27
Episode length: 477.46 +/- 269.93
Eval num_timesteps=105000, episode_reward=-71.54 +/- 83.17
Episode length: 588.83 +/- 299.24
Eval num_timesteps=110000, episode_reward=-84.37 +/- 71.11
Episode length: 621.49 +/- 314.75
Eval num_timesteps=115000, episode_reward=-61.83 +/- 89.44
Episode length: 434.22 +/- 249.44
Eval num_timesteps=120000, episode_reward=-31.19 +/- 107.15
Episode length: 432.33 +/- 201.06
Eval num_timesteps=125000, episode_reward=-32.34 +/- 99.11
Episode length: 491.45 +/- 264.91
Eval num_timesteps=130000, episode_reward=-98.72 +/- 45.64
Episode length: 543.08 +/- 336.56
Eval num_timesteps=135000, episode_reward=-98.39 +/- 53.48
Episode length: 448.78 +/- 287.09
Eval num_timesteps=140000, episode_reward=-85.65 +/- 61.62
Episode length: 527.93 +/- 321.92
Eval num_timesteps=145000, episode_reward=-104.65 +/- 43.67
Episode length: 453.97 +/- 310.36
Eval num_timesteps=150000, episode_reward=-118.79 +/- 46.68
Episode length: 457.22 +/- 280.59
FINISHED IN 2441.53126432281 s


starting seed  1308 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-421.24 +/- 145.83
Episode length: 76.95 +/- 16.38
New best mean reward!
Eval num_timesteps=10000, episode_reward=-217.49 +/- 71.60
Episode length: 70.97 +/- 12.94
New best mean reward!
Eval num_timesteps=15000, episode_reward=217.96 +/- 82.40
Episode length: 317.68 +/- 89.40
New best mean reward!
FINISHED IN 74.55732727376744 s


starting seed  1309 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-156.21 +/- 39.04
Episode length: 68.87 +/- 11.08
New best mean reward!
Eval num_timesteps=10000, episode_reward=80.10 +/- 108.39
Episode length: 499.56 +/- 275.08
New best mean reward!
Eval num_timesteps=15000, episode_reward=-65.98 +/- 25.55
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=-160.65 +/- 37.65
Episode length: 482.88 +/- 209.30
Eval num_timesteps=25000, episode_reward=-205.13 +/- 58.18
Episode length: 856.12 +/- 173.35
Eval num_timesteps=30000, episode_reward=-120.46 +/- 60.38
Episode length: 919.40 +/- 170.39
Eval num_timesteps=35000, episode_reward=-116.67 +/- 77.66
Episode length: 696.99 +/- 238.13
Eval num_timesteps=40000, episode_reward=-115.39 +/- 19.74
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-95.91 +/- 24.36
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=50000, episode_reward=-155.28 +/- 35.21
Episode length: 992.56 +/- 37.25
Eval num_timesteps=55000, episode_reward=-61.66 +/- 23.22
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-40.76 +/- 22.77
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=65000, episode_reward=-65.80 +/- 38.24
Episode length: 995.69 +/- 22.70
Eval num_timesteps=70000, episode_reward=-72.83 +/- 110.56
Episode length: 610.60 +/- 178.43
Eval num_timesteps=75000, episode_reward=-126.65 +/- 60.97
Episode length: 699.12 +/- 266.64
Eval num_timesteps=80000, episode_reward=-77.49 +/- 52.66
Episode length: 899.30 +/- 205.32
Eval num_timesteps=85000, episode_reward=-54.71 +/- 26.75
Episode length: 897.83 +/- 219.85
Eval num_timesteps=90000, episode_reward=-108.63 +/- 53.38
Episode length: 823.53 +/- 246.10
Eval num_timesteps=95000, episode_reward=-150.47 +/- 54.16
Episode length: 560.09 +/- 275.42
Eval num_timesteps=100000, episode_reward=-129.62 +/- 55.69
Episode length: 563.74 +/- 291.26
Eval num_timesteps=105000, episode_reward=-104.11 +/- 52.49
Episode length: 590.61 +/- 325.13
Eval num_timesteps=110000, episode_reward=-87.07 +/- 72.14
Episode length: 537.22 +/- 344.18
Eval num_timesteps=115000, episode_reward=-107.35 +/- 44.25
Episode length: 498.90 +/- 326.83
Eval num_timesteps=120000, episode_reward=-114.62 +/- 56.76
Episode length: 523.31 +/- 338.26
Eval num_timesteps=125000, episode_reward=-130.30 +/- 37.90
Episode length: 452.72 +/- 293.63
Eval num_timesteps=130000, episode_reward=-142.79 +/- 34.84
Episode length: 431.97 +/- 278.77
Eval num_timesteps=135000, episode_reward=-120.79 +/- 35.29
Episode length: 426.33 +/- 305.97
Eval num_timesteps=140000, episode_reward=-127.18 +/- 33.95
Episode length: 424.57 +/- 284.69
Eval num_timesteps=145000, episode_reward=-121.97 +/- 33.85
Episode length: 544.10 +/- 339.37
Eval num_timesteps=150000, episode_reward=-119.23 +/- 33.43
Episode length: 463.81 +/- 333.85
FINISHED IN 3314.6549005089328 s


starting seed  1310 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-153.90 +/- 36.13
Episode length: 283.89 +/- 105.02
New best mean reward!
Eval num_timesteps=10000, episode_reward=-43.20 +/- 70.45
Episode length: 976.88 +/- 79.18
New best mean reward!
Eval num_timesteps=15000, episode_reward=-118.32 +/- 50.52
Episode length: 453.51 +/- 143.39
Eval num_timesteps=20000, episode_reward=28.54 +/- 118.81
Episode length: 904.15 +/- 102.98
New best mean reward!
Eval num_timesteps=25000, episode_reward=51.38 +/- 109.28
Episode length: 877.62 +/- 123.03
New best mean reward!
Eval num_timesteps=30000, episode_reward=-120.46 +/- 64.96
Episode length: 721.09 +/- 318.50
Eval num_timesteps=35000, episode_reward=-127.74 +/- 48.10
Episode length: 410.78 +/- 247.39
Eval num_timesteps=40000, episode_reward=-134.76 +/- 58.15
Episode length: 560.57 +/- 338.03
Eval num_timesteps=45000, episode_reward=36.54 +/- 127.86
Episode length: 474.03 +/- 205.90
Eval num_timesteps=50000, episode_reward=-49.07 +/- 107.93
Episode length: 374.86 +/- 213.46
Eval num_timesteps=55000, episode_reward=-5.50 +/- 132.67
Episode length: 497.64 +/- 238.21
Eval num_timesteps=60000, episode_reward=-28.02 +/- 110.22
Episode length: 564.66 +/- 295.41
Eval num_timesteps=65000, episode_reward=-111.36 +/- 38.16
Episode length: 587.64 +/- 358.17
Eval num_timesteps=70000, episode_reward=-24.23 +/- 104.16
Episode length: 344.67 +/- 169.46
Eval num_timesteps=75000, episode_reward=2.25 +/- 116.24
Episode length: 396.65 +/- 251.59
Eval num_timesteps=80000, episode_reward=-56.84 +/- 39.05
Episode length: 934.13 +/- 211.68
Eval num_timesteps=85000, episode_reward=-57.29 +/- 28.31
Episode length: 968.35 +/- 155.25
Eval num_timesteps=90000, episode_reward=-62.16 +/- 21.03
Episode length: 952.94 +/- 186.39
Eval num_timesteps=95000, episode_reward=41.19 +/- 110.04
Episode length: 727.77 +/- 197.23
Eval num_timesteps=100000, episode_reward=-11.55 +/- 55.05
Episode length: 981.50 +/- 95.18
Eval num_timesteps=105000, episode_reward=-13.13 +/- 26.21
Episode length: 999.85 +/- 1.49
Eval num_timesteps=110000, episode_reward=-42.50 +/- 21.38
Episode length: 992.71 +/- 72.53
Eval num_timesteps=115000, episode_reward=-4.81 +/- 60.12
Episode length: 977.61 +/- 71.31
Eval num_timesteps=120000, episode_reward=-29.31 +/- 69.89
Episode length: 860.81 +/- 237.29
Eval num_timesteps=125000, episode_reward=-5.03 +/- 93.22
Episode length: 842.79 +/- 211.17
Eval num_timesteps=130000, episode_reward=53.32 +/- 104.04
Episode length: 688.33 +/- 244.89
New best mean reward!
Eval num_timesteps=135000, episode_reward=-2.67 +/- 81.33
Episode length: 839.98 +/- 274.37
Eval num_timesteps=140000, episode_reward=54.96 +/- 98.92
Episode length: 744.91 +/- 256.12
New best mean reward!
Eval num_timesteps=145000, episode_reward=53.55 +/- 103.93
Episode length: 755.60 +/- 249.58
Eval num_timesteps=150000, episode_reward=87.07 +/- 94.86
Episode length: 736.55 +/- 240.18
New best mean reward!
FINISHED IN 3444.199831577018 s


starting seed  1311 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-809.27 +/- 417.53
Episode length: 121.02 +/- 47.27
New best mean reward!
Eval num_timesteps=10000, episode_reward=-33.68 +/- 93.05
Episode length: 307.22 +/- 63.56
New best mean reward!
Eval num_timesteps=15000, episode_reward=120.37 +/- 123.92
Episode length: 628.92 +/- 214.16
New best mean reward!
Eval num_timesteps=20000, episode_reward=-70.88 +/- 70.15
Episode length: 990.06 +/- 54.58
Eval num_timesteps=25000, episode_reward=25.85 +/- 124.93
Episode length: 641.54 +/- 101.11
Eval num_timesteps=30000, episode_reward=-43.52 +/- 84.70
Episode length: 907.42 +/- 157.27
Eval num_timesteps=35000, episode_reward=108.25 +/- 115.46
Episode length: 562.05 +/- 115.00
Eval num_timesteps=40000, episode_reward=18.75 +/- 100.76
Episode length: 894.77 +/- 114.41
Eval num_timesteps=45000, episode_reward=-35.81 +/- 48.11
Episode length: 995.65 +/- 17.01
Eval num_timesteps=50000, episode_reward=-2.39 +/- 151.56
Episode length: 507.50 +/- 214.95
Eval num_timesteps=55000, episode_reward=-75.79 +/- 116.18
Episode length: 244.48 +/- 110.13
Eval num_timesteps=60000, episode_reward=-86.34 +/- 96.30
Episode length: 541.18 +/- 229.92
Eval num_timesteps=65000, episode_reward=-54.34 +/- 27.80
Episode length: 943.44 +/- 194.20
Eval num_timesteps=70000, episode_reward=-88.77 +/- 48.85
Episode length: 675.94 +/- 346.71
Eval num_timesteps=75000, episode_reward=-153.45 +/- 52.13
Episode length: 491.20 +/- 298.26
Eval num_timesteps=80000, episode_reward=-66.76 +/- 96.77
Episode length: 491.11 +/- 272.23
Eval num_timesteps=85000, episode_reward=-113.62 +/- 47.53
Episode length: 545.93 +/- 355.15
Eval num_timesteps=90000, episode_reward=-96.45 +/- 37.09
Episode length: 746.01 +/- 353.11
Eval num_timesteps=95000, episode_reward=-138.01 +/- 47.86
Episode length: 492.12 +/- 307.48
Eval num_timesteps=100000, episode_reward=-106.67 +/- 35.83
Episode length: 492.64 +/- 335.55
Eval num_timesteps=105000, episode_reward=-93.35 +/- 79.77
Episode length: 370.35 +/- 229.58
Eval num_timesteps=110000, episode_reward=-75.93 +/- 92.16
Episode length: 328.66 +/- 165.95
Eval num_timesteps=115000, episode_reward=-82.83 +/- 73.74
Episode length: 338.94 +/- 238.17
Eval num_timesteps=120000, episode_reward=-48.45 +/- 105.30
Episode length: 305.46 +/- 155.27
Eval num_timesteps=125000, episode_reward=-47.09 +/- 110.24
Episode length: 377.65 +/- 250.31
Eval num_timesteps=130000, episode_reward=-67.87 +/- 101.67
Episode length: 374.27 +/- 249.21
Eval num_timesteps=135000, episode_reward=-52.59 +/- 110.72
Episode length: 402.31 +/- 274.67
Eval num_timesteps=140000, episode_reward=-69.50 +/- 96.73
Episode length: 421.39 +/- 279.16
Eval num_timesteps=145000, episode_reward=-61.36 +/- 108.41
Episode length: 411.78 +/- 275.95
Eval num_timesteps=150000, episode_reward=-71.06 +/- 106.96
Episode length: 413.93 +/- 263.86
FINISHED IN 2563.465046116151 s


starting seed  1312 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-851.55 +/- 533.67
Episode length: 123.23 +/- 53.03
New best mean reward!
Eval num_timesteps=10000, episode_reward=63.08 +/- 111.36
Episode length: 370.50 +/- 232.81
New best mean reward!
Eval num_timesteps=15000, episode_reward=-121.74 +/- 78.20
Episode length: 897.33 +/- 138.84
Eval num_timesteps=20000, episode_reward=-10.00 +/- 106.79
Episode length: 803.22 +/- 184.68
Eval num_timesteps=25000, episode_reward=-14.53 +/- 54.04
Episode length: 988.48 +/- 58.99
Eval num_timesteps=30000, episode_reward=-26.76 +/- 109.59
Episode length: 820.65 +/- 119.34
Eval num_timesteps=35000, episode_reward=-80.89 +/- 24.32
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-56.76 +/- 21.07
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-33.17 +/- 25.96
Episode length: 998.15 +/- 18.41
Eval num_timesteps=50000, episode_reward=-118.17 +/- 24.63
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=55000, episode_reward=-108.73 +/- 23.58
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-39.24 +/- 22.39
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=65000, episode_reward=-67.09 +/- 25.20
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=70000, episode_reward=-39.06 +/- 23.74
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=75000, episode_reward=-60.93 +/- 27.40
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=80000, episode_reward=-71.73 +/- 33.63
Episode length: 990.80 +/- 40.47
Eval num_timesteps=85000, episode_reward=78.22 +/- 136.74
Episode length: 672.59 +/- 166.79
New best mean reward!
Eval num_timesteps=90000, episode_reward=91.60 +/- 134.57
Episode length: 504.84 +/- 162.91
New best mean reward!
Eval num_timesteps=95000, episode_reward=71.12 +/- 136.13
Episode length: 628.48 +/- 200.80
Eval num_timesteps=100000, episode_reward=10.73 +/- 118.43
Episode length: 781.03 +/- 225.20
Eval num_timesteps=105000, episode_reward=38.01 +/- 122.57
Episode length: 693.75 +/- 211.46
Eval num_timesteps=110000, episode_reward=67.65 +/- 122.25
Episode length: 613.41 +/- 212.54
Eval num_timesteps=115000, episode_reward=36.95 +/- 115.03
Episode length: 606.21 +/- 285.58
Eval num_timesteps=120000, episode_reward=-12.33 +/- 115.58
Episode length: 529.70 +/- 272.10
Eval num_timesteps=125000, episode_reward=36.93 +/- 120.86
Episode length: 538.93 +/- 259.11
Eval num_timesteps=130000, episode_reward=-1.59 +/- 134.72
Episode length: 437.25 +/- 194.65
Eval num_timesteps=135000, episode_reward=-12.09 +/- 119.37
Episode length: 397.03 +/- 176.66
Eval num_timesteps=140000, episode_reward=5.28 +/- 132.84
Episode length: 411.65 +/- 177.58
Eval num_timesteps=145000, episode_reward=0.88 +/- 131.14
Episode length: 413.03 +/- 186.58
Eval num_timesteps=150000, episode_reward=-30.79 +/- 114.64
Episode length: 389.26 +/- 169.73
FINISHED IN 3477.4350146809593 s


starting seed  1313 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-871.78 +/- 511.06
Episode length: 126.66 +/- 54.73
New best mean reward!
Eval num_timesteps=10000, episode_reward=-574.78 +/- 183.60
Episode length: 68.24 +/- 14.91
New best mean reward!
Eval num_timesteps=15000, episode_reward=-607.22 +/- 119.92
Episode length: 69.37 +/- 7.67
Eval num_timesteps=20000, episode_reward=-616.28 +/- 67.57
Episode length: 81.32 +/- 9.65
Eval num_timesteps=25000, episode_reward=-116.40 +/- 67.54
Episode length: 896.75 +/- 247.13
New best mean reward!
Eval num_timesteps=30000, episode_reward=-97.20 +/- 30.63
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=35000, episode_reward=-39.57 +/- 58.57
Episode length: 988.21 +/- 32.08
New best mean reward!
Eval num_timesteps=40000, episode_reward=14.25 +/- 98.22
Episode length: 705.33 +/- 171.04
New best mean reward!
Eval num_timesteps=45000, episode_reward=-148.28 +/- 39.81
Episode length: 597.89 +/- 154.23
Eval num_timesteps=50000, episode_reward=-61.03 +/- 110.97
Episode length: 618.03 +/- 191.39
Eval num_timesteps=55000, episode_reward=-109.42 +/- 18.51
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-0.70 +/- 127.09
Episode length: 490.65 +/- 170.83
Eval num_timesteps=65000, episode_reward=-99.38 +/- 18.64
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=70000, episode_reward=-151.12 +/- 40.92
Episode length: 991.32 +/- 86.36
Eval num_timesteps=75000, episode_reward=-37.19 +/- 23.93
Episode length: 992.45 +/- 75.12
Eval num_timesteps=80000, episode_reward=-62.58 +/- 89.99
Episode length: 872.01 +/- 193.25
Eval num_timesteps=85000, episode_reward=26.93 +/- 86.58
Episode length: 953.43 +/- 97.89
New best mean reward!
Eval num_timesteps=90000, episode_reward=8.49 +/- 72.57
Episode length: 976.05 +/- 65.07
Eval num_timesteps=95000, episode_reward=6.43 +/- 114.85
Episode length: 889.99 +/- 162.09
Eval num_timesteps=100000, episode_reward=-132.90 +/- 52.72
Episode length: 679.54 +/- 341.43
Eval num_timesteps=105000, episode_reward=-91.28 +/- 47.95
Episode length: 615.70 +/- 349.29
Eval num_timesteps=110000, episode_reward=-61.90 +/- 97.61
Episode length: 495.92 +/- 271.98
Eval num_timesteps=115000, episode_reward=-135.15 +/- 55.24
Episode length: 559.90 +/- 351.52
Eval num_timesteps=120000, episode_reward=-112.42 +/- 46.81
Episode length: 671.29 +/- 349.90
Eval num_timesteps=125000, episode_reward=-81.60 +/- 73.35
Episode length: 582.89 +/- 333.62
Eval num_timesteps=130000, episode_reward=-51.25 +/- 83.97
Episode length: 654.58 +/- 340.28
Eval num_timesteps=135000, episode_reward=-63.44 +/- 75.49
Episode length: 724.58 +/- 342.66
Eval num_timesteps=140000, episode_reward=-33.44 +/- 92.15
Episode length: 624.51 +/- 325.93
Eval num_timesteps=145000, episode_reward=-65.54 +/- 78.54
Episode length: 607.44 +/- 344.98
Eval num_timesteps=150000, episode_reward=-82.53 +/- 72.71
Episode length: 663.24 +/- 319.15
FINISHED IN 3434.494137582835 s


starting seed  1314 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-817.12 +/- 470.54
Episode length: 121.32 +/- 46.74
New best mean reward!
Eval num_timesteps=10000, episode_reward=-475.52 +/- 196.94
Episode length: 136.24 +/- 38.57
New best mean reward!
Eval num_timesteps=15000, episode_reward=-320.99 +/- 54.43
Episode length: 305.00 +/- 61.81
New best mean reward!
Eval num_timesteps=20000, episode_reward=-161.02 +/- 22.75
Episode length: 264.37 +/- 79.23
New best mean reward!
Eval num_timesteps=25000, episode_reward=-111.89 +/- 27.08
Episode length: 933.15 +/- 154.93
New best mean reward!
Eval num_timesteps=30000, episode_reward=-108.09 +/- 46.36
Episode length: 879.08 +/- 201.86
New best mean reward!
Eval num_timesteps=35000, episode_reward=-108.98 +/- 41.30
Episode length: 881.32 +/- 201.60
Eval num_timesteps=40000, episode_reward=-170.55 +/- 43.60
Episode length: 408.08 +/- 235.86
Eval num_timesteps=45000, episode_reward=-145.73 +/- 50.13
Episode length: 525.24 +/- 265.73
Eval num_timesteps=50000, episode_reward=-138.74 +/- 33.04
Episode length: 870.42 +/- 209.53
Eval num_timesteps=55000, episode_reward=-75.82 +/- 29.98
Episode length: 978.35 +/- 90.43
New best mean reward!
Eval num_timesteps=60000, episode_reward=-147.62 +/- 36.11
Episode length: 598.51 +/- 204.28
Eval num_timesteps=65000, episode_reward=-136.88 +/- 22.09
Episode length: 998.09 +/- 19.00
Eval num_timesteps=70000, episode_reward=-72.69 +/- 18.52
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=75000, episode_reward=-51.27 +/- 20.79
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=80000, episode_reward=-67.89 +/- 24.74
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=85000, episode_reward=-64.03 +/- 21.57
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=90000, episode_reward=-122.51 +/- 26.99
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=95000, episode_reward=-38.17 +/- 19.41
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=100000, episode_reward=-17.91 +/- 20.41
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=105000, episode_reward=-13.77 +/- 24.70
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=110000, episode_reward=12.48 +/- 77.46
Episode length: 952.57 +/- 79.02
New best mean reward!
Eval num_timesteps=115000, episode_reward=-45.17 +/- 41.77
Episode length: 996.46 +/- 21.51
Eval num_timesteps=120000, episode_reward=37.25 +/- 114.80
Episode length: 744.29 +/- 152.57
New best mean reward!
Eval num_timesteps=125000, episode_reward=-42.59 +/- 113.91
Episode length: 502.04 +/- 193.62
Eval num_timesteps=130000, episode_reward=-97.20 +/- 61.41
Episode length: 335.86 +/- 137.38
Eval num_timesteps=135000, episode_reward=-45.89 +/- 106.57
Episode length: 502.30 +/- 210.62
Eval num_timesteps=140000, episode_reward=-48.01 +/- 90.67
Episode length: 864.90 +/- 189.33
Eval num_timesteps=145000, episode_reward=-76.23 +/- 85.73
Episode length: 870.05 +/- 181.79
Eval num_timesteps=150000, episode_reward=-41.30 +/- 73.26
Episode length: 954.01 +/- 101.46
FINISHED IN 3594.295610452071 s


starting seed  1315 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-26.39 +/- 32.86
Episode length: 968.64 +/- 153.66
New best mean reward!
Eval num_timesteps=10000, episode_reward=-103.47 +/- 37.03
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=15000, episode_reward=84.92 +/- 116.72
Episode length: 286.64 +/- 109.97
New best mean reward!
Eval num_timesteps=20000, episode_reward=-0.27 +/- 147.52
Episode length: 332.25 +/- 96.39
Eval num_timesteps=25000, episode_reward=-120.91 +/- 83.36
Episode length: 744.74 +/- 278.61
Eval num_timesteps=30000, episode_reward=-79.14 +/- 104.88
Episode length: 447.74 +/- 242.09
Eval num_timesteps=35000, episode_reward=-87.33 +/- 88.81
Episode length: 335.55 +/- 170.44
Eval num_timesteps=40000, episode_reward=-110.65 +/- 60.05
Episode length: 663.03 +/- 343.31
Eval num_timesteps=45000, episode_reward=-51.59 +/- 79.92
Episode length: 595.47 +/- 307.05
Eval num_timesteps=50000, episode_reward=-62.34 +/- 56.29
Episode length: 734.03 +/- 346.58
Eval num_timesteps=55000, episode_reward=-124.28 +/- 47.20
Episode length: 569.54 +/- 328.59
Eval num_timesteps=60000, episode_reward=-85.14 +/- 61.18
Episode length: 529.96 +/- 333.94
Eval num_timesteps=65000, episode_reward=-25.64 +/- 97.17
Episode length: 474.95 +/- 289.59
Eval num_timesteps=70000, episode_reward=-79.76 +/- 64.44
Episode length: 590.26 +/- 351.04
Eval num_timesteps=75000, episode_reward=-21.09 +/- 105.23
Episode length: 613.40 +/- 320.57
Eval num_timesteps=80000, episode_reward=-98.99 +/- 74.11
Episode length: 413.99 +/- 282.21
Eval num_timesteps=85000, episode_reward=-22.55 +/- 114.79
Episode length: 298.83 +/- 144.25
Eval num_timesteps=90000, episode_reward=-82.27 +/- 53.73
Episode length: 568.32 +/- 362.03
Eval num_timesteps=95000, episode_reward=-62.17 +/- 80.20
Episode length: 640.00 +/- 366.53
Eval num_timesteps=100000, episode_reward=-24.04 +/- 105.31
Episode length: 569.32 +/- 266.26
Eval num_timesteps=105000, episode_reward=-121.66 +/- 53.36
Episode length: 748.75 +/- 352.10
Eval num_timesteps=110000, episode_reward=-137.05 +/- 60.99
Episode length: 633.53 +/- 341.30
Eval num_timesteps=115000, episode_reward=-61.20 +/- 95.38
Episode length: 487.61 +/- 305.51
Eval num_timesteps=120000, episode_reward=-60.81 +/- 63.57
Episode length: 663.30 +/- 375.95
Eval num_timesteps=125000, episode_reward=-68.09 +/- 55.62
Episode length: 804.64 +/- 330.63
Eval num_timesteps=130000, episode_reward=-72.03 +/- 86.28
Episode length: 542.24 +/- 318.53
Eval num_timesteps=135000, episode_reward=-20.08 +/- 112.19
Episode length: 530.41 +/- 284.41
Eval num_timesteps=140000, episode_reward=-48.57 +/- 93.50
Episode length: 467.97 +/- 297.09
Eval num_timesteps=145000, episode_reward=-27.90 +/- 98.19
Episode length: 486.08 +/- 319.34
Eval num_timesteps=150000, episode_reward=-27.65 +/- 106.53
Episode length: 542.64 +/- 297.45
FINISHED IN 3083.9616571548395 s


starting seed  1316 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-627.93 +/- 158.39
Episode length: 385.68 +/- 39.34
New best mean reward!
Eval num_timesteps=10000, episode_reward=-153.62 +/- 62.80
Episode length: 961.21 +/- 78.39
New best mean reward!
Eval num_timesteps=15000, episode_reward=-76.08 +/- 27.63
Episode length: 996.36 +/- 36.22
New best mean reward!
Eval num_timesteps=20000, episode_reward=-110.35 +/- 54.40
Episode length: 755.37 +/- 289.99
Eval num_timesteps=25000, episode_reward=-147.54 +/- 47.35
Episode length: 587.30 +/- 331.58
Eval num_timesteps=30000, episode_reward=-175.14 +/- 49.65
Episode length: 785.63 +/- 259.30
Eval num_timesteps=35000, episode_reward=-104.15 +/- 45.85
Episode length: 957.05 +/- 163.64
Eval num_timesteps=40000, episode_reward=-125.17 +/- 73.99
Episode length: 869.95 +/- 209.12
Eval num_timesteps=45000, episode_reward=-94.52 +/- 28.74
Episode length: 956.49 +/- 160.93
Eval num_timesteps=50000, episode_reward=-97.67 +/- 44.59
Episode length: 739.01 +/- 327.29
Eval num_timesteps=55000, episode_reward=-125.12 +/- 59.65
Episode length: 588.01 +/- 329.07
Eval num_timesteps=60000, episode_reward=-106.08 +/- 47.03
Episode length: 568.49 +/- 346.63
Eval num_timesteps=65000, episode_reward=-86.52 +/- 37.81
Episode length: 691.09 +/- 376.70
Eval num_timesteps=70000, episode_reward=-71.72 +/- 53.72
Episode length: 752.90 +/- 332.51
New best mean reward!
Eval num_timesteps=75000, episode_reward=-107.99 +/- 47.62
Episode length: 634.22 +/- 379.69
Eval num_timesteps=80000, episode_reward=-121.86 +/- 46.61
Episode length: 641.16 +/- 360.03
Eval num_timesteps=85000, episode_reward=-130.52 +/- 39.91
Episode length: 500.28 +/- 353.46
Eval num_timesteps=90000, episode_reward=-125.40 +/- 37.51
Episode length: 408.75 +/- 310.32
Eval num_timesteps=95000, episode_reward=-135.31 +/- 36.74
Episode length: 385.72 +/- 298.90
Eval num_timesteps=100000, episode_reward=-112.27 +/- 43.37
Episode length: 407.61 +/- 316.54
Eval num_timesteps=105000, episode_reward=-112.43 +/- 44.50
Episode length: 425.03 +/- 313.61
Eval num_timesteps=110000, episode_reward=-129.52 +/- 29.52
Episode length: 328.87 +/- 274.95
Eval num_timesteps=115000, episode_reward=-156.28 +/- 49.12
Episode length: 477.26 +/- 314.98
Eval num_timesteps=120000, episode_reward=-128.15 +/- 50.61
Episode length: 554.89 +/- 362.26
Eval num_timesteps=125000, episode_reward=-123.02 +/- 30.14
Episode length: 576.97 +/- 367.00
Eval num_timesteps=130000, episode_reward=-136.36 +/- 44.94
Episode length: 488.82 +/- 334.51
Eval num_timesteps=135000, episode_reward=-139.59 +/- 46.36
Episode length: 472.85 +/- 320.77
Eval num_timesteps=140000, episode_reward=-133.96 +/- 41.37
Episode length: 503.12 +/- 348.61
Eval num_timesteps=145000, episode_reward=-132.26 +/- 41.05
Episode length: 427.51 +/- 303.00
Eval num_timesteps=150000, episode_reward=-133.33 +/- 41.11
Episode length: 456.87 +/- 323.43
FINISHED IN 3294.586945865769 s


starting seed  1317 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-154.15 +/- 25.58
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-8.92 +/- 89.70
Episode length: 953.63 +/- 75.16
New best mean reward!
Eval num_timesteps=15000, episode_reward=-231.54 +/- 42.66
Episode length: 993.08 +/- 55.41
Eval num_timesteps=20000, episode_reward=-16.88 +/- 28.09
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-130.69 +/- 40.72
Episode length: 521.63 +/- 215.05
Eval num_timesteps=30000, episode_reward=-142.61 +/- 47.70
Episode length: 720.22 +/- 261.22
Eval num_timesteps=35000, episode_reward=-88.87 +/- 83.14
Episode length: 692.39 +/- 271.70
Eval num_timesteps=40000, episode_reward=-115.43 +/- 55.49
Episode length: 565.09 +/- 328.42
Eval num_timesteps=45000, episode_reward=-92.50 +/- 44.03
Episode length: 918.48 +/- 221.34
Eval num_timesteps=50000, episode_reward=-111.40 +/- 53.21
Episode length: 568.17 +/- 344.66
Eval num_timesteps=55000, episode_reward=-70.12 +/- 33.46
Episode length: 779.09 +/- 347.21
Eval num_timesteps=60000, episode_reward=-103.16 +/- 35.01
Episode length: 827.16 +/- 314.39
Eval num_timesteps=65000, episode_reward=-130.47 +/- 30.91
Episode length: 621.32 +/- 373.13
Eval num_timesteps=70000, episode_reward=-117.48 +/- 37.06
Episode length: 441.28 +/- 318.85
Eval num_timesteps=75000, episode_reward=-79.59 +/- 94.80
Episode length: 323.89 +/- 213.52
Eval num_timesteps=80000, episode_reward=-126.55 +/- 46.83
Episode length: 453.77 +/- 315.83
Eval num_timesteps=85000, episode_reward=-145.32 +/- 43.74
Episode length: 434.98 +/- 314.96
Eval num_timesteps=90000, episode_reward=-122.12 +/- 47.28
Episode length: 447.19 +/- 339.29
Eval num_timesteps=95000, episode_reward=-132.80 +/- 36.22
Episode length: 403.01 +/- 297.89
Eval num_timesteps=100000, episode_reward=-135.22 +/- 33.33
Episode length: 460.61 +/- 365.39
Eval num_timesteps=105000, episode_reward=-132.22 +/- 31.45
Episode length: 463.22 +/- 352.50
Eval num_timesteps=110000, episode_reward=-114.60 +/- 30.99
Episode length: 469.56 +/- 360.34
Eval num_timesteps=115000, episode_reward=-129.55 +/- 47.23
Episode length: 457.79 +/- 316.64
Eval num_timesteps=120000, episode_reward=-101.94 +/- 39.49
Episode length: 532.43 +/- 390.13
