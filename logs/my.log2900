nohup: ignoring input


starting seed  2900 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-700.39 +/- 183.12
Episode length: 181.89 +/- 101.75
New best mean reward!
Eval num_timesteps=10000, episode_reward=-133.07 +/- 35.49
Episode length: 68.74 +/- 11.55
New best mean reward!
Eval num_timesteps=15000, episode_reward=-127.19 +/- 46.70
Episode length: 70.76 +/- 14.25
New best mean reward!
Eval num_timesteps=20000, episode_reward=-131.60 +/- 40.24
Episode length: 70.44 +/- 11.64
Eval num_timesteps=25000, episode_reward=-138.50 +/- 39.82
Episode length: 70.57 +/- 11.90
Eval num_timesteps=30000, episode_reward=-118.98 +/- 50.63
Episode length: 78.54 +/- 20.57
New best mean reward!
Eval num_timesteps=35000, episode_reward=-127.43 +/- 59.15
Episode length: 102.58 +/- 44.40
Eval num_timesteps=40000, episode_reward=-183.37 +/- 87.06
Episode length: 127.23 +/- 78.15
Eval num_timesteps=45000, episode_reward=-183.89 +/- 39.64
Episode length: 340.57 +/- 47.93
Eval num_timesteps=50000, episode_reward=-186.87 +/- 27.98
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=55000, episode_reward=-107.46 +/- 26.58
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=60000, episode_reward=-82.34 +/- 27.42
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=65000, episode_reward=-112.61 +/- 24.13
Episode length: 999.04 +/- 9.55
Eval num_timesteps=70000, episode_reward=-89.48 +/- 28.55
Episode length: 996.92 +/- 17.65
Eval num_timesteps=75000, episode_reward=-66.28 +/- 21.30
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=80000, episode_reward=-58.61 +/- 74.59
Episode length: 983.39 +/- 46.33
New best mean reward!
Eval num_timesteps=85000, episode_reward=-84.65 +/- 77.08
Episode length: 371.38 +/- 101.25
Eval num_timesteps=90000, episode_reward=13.47 +/- 116.49
Episode length: 727.84 +/- 161.33
New best mean reward!
Eval num_timesteps=95000, episode_reward=-94.67 +/- 59.75
Episode length: 826.62 +/- 232.34
Eval num_timesteps=100000, episode_reward=-88.19 +/- 71.04
Episode length: 766.61 +/- 245.50
Eval num_timesteps=105000, episode_reward=-86.34 +/- 90.91
Episode length: 569.05 +/- 221.97
Eval num_timesteps=110000, episode_reward=-69.41 +/- 92.79
Episode length: 341.51 +/- 140.55
Eval num_timesteps=115000, episode_reward=-103.77 +/- 67.54
Episode length: 423.32 +/- 205.18
Eval num_timesteps=120000, episode_reward=-163.57 +/- 61.44
Episode length: 615.65 +/- 254.69
Eval num_timesteps=125000, episode_reward=-102.15 +/- 51.72
Episode length: 766.67 +/- 294.59
Eval num_timesteps=130000, episode_reward=-83.65 +/- 34.04
Episode length: 967.01 +/- 130.75
Eval num_timesteps=135000, episode_reward=-137.88 +/- 45.68
Episode length: 949.85 +/- 163.67
Eval num_timesteps=140000, episode_reward=-87.99 +/- 67.11
Episode length: 781.74 +/- 268.13
Eval num_timesteps=145000, episode_reward=-100.39 +/- 46.80
Episode length: 568.76 +/- 309.56
Eval num_timesteps=150000, episode_reward=-102.18 +/- 74.18
Episode length: 558.76 +/- 314.35
Eval num_timesteps=155000, episode_reward=-113.13 +/- 43.97
Episode length: 608.87 +/- 323.36
Eval num_timesteps=160000, episode_reward=-99.63 +/- 60.93
Episode length: 531.23 +/- 302.59
Eval num_timesteps=165000, episode_reward=-105.41 +/- 83.53
Episode length: 549.77 +/- 304.42
Eval num_timesteps=170000, episode_reward=-34.06 +/- 99.03
Episode length: 640.75 +/- 287.50
Eval num_timesteps=175000, episode_reward=-104.92 +/- 50.84
Episode length: 492.32 +/- 314.58
Eval num_timesteps=180000, episode_reward=-103.96 +/- 48.92
Episode length: 445.14 +/- 293.57
Eval num_timesteps=185000, episode_reward=-103.87 +/- 36.30
Episode length: 470.42 +/- 316.21
Eval num_timesteps=190000, episode_reward=-116.34 +/- 39.88
Episode length: 417.06 +/- 276.67
Eval num_timesteps=195000, episode_reward=-113.21 +/- 40.23
Episode length: 434.86 +/- 306.48
Eval num_timesteps=200000, episode_reward=-94.88 +/- 27.73
Episode length: 514.37 +/- 372.03
Eval num_timesteps=205000, episode_reward=-119.33 +/- 41.44
Episode length: 523.94 +/- 339.90
Eval num_timesteps=210000, episode_reward=-134.29 +/- 41.88
Episode length: 580.89 +/- 340.57
Eval num_timesteps=215000, episode_reward=-130.72 +/- 40.32
Episode length: 504.08 +/- 322.35
Eval num_timesteps=220000, episode_reward=-104.79 +/- 38.23
Episode length: 552.75 +/- 371.29
Eval num_timesteps=225000, episode_reward=-110.10 +/- 31.72
Episode length: 519.17 +/- 354.14
Eval num_timesteps=230000, episode_reward=-113.84 +/- 40.35
Episode length: 491.55 +/- 350.94
Eval num_timesteps=235000, episode_reward=-112.99 +/- 34.63
Episode length: 452.78 +/- 334.68
Eval num_timesteps=240000, episode_reward=-106.99 +/- 32.05
Episode length: 527.66 +/- 359.41
Eval num_timesteps=245000, episode_reward=-109.22 +/- 37.32
Episode length: 471.95 +/- 337.81
Eval num_timesteps=250000, episode_reward=-112.76 +/- 38.95
Episode length: 495.84 +/- 348.70
FINISHED IN 1779.4597050510056 s


starting seed  2901 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Eval num_timesteps=5000, episode_reward=-7052.13 +/- 1217.28
Episode length: 814.44 +/- 59.53
New best mean reward!
Eval num_timesteps=10000, episode_reward=-358.08 +/- 118.13
Episode length: 85.98 +/- 11.02
New best mean reward!
Eval num_timesteps=15000, episode_reward=-135.30 +/- 92.28
Episode length: 484.01 +/- 224.85
New best mean reward!
Eval num_timesteps=20000, episode_reward=-141.43 +/- 85.83
Episode length: 272.56 +/- 93.37
Eval num_timesteps=25000, episode_reward=-728.12 +/- 158.51
Episode length: 705.59 +/- 207.44
Eval num_timesteps=30000, episode_reward=-136.80 +/- 39.22
Episode length: 590.09 +/- 134.08
Eval num_timesteps=35000, episode_reward=-68.94 +/- 26.89
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=40000, episode_reward=-131.98 +/- 70.19
Episode length: 822.03 +/- 238.41
Eval num_timesteps=45000, episode_reward=-98.24 +/- 22.74
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=50000, episode_reward=-51.09 +/- 24.65
Episode length: 999.12 +/- 8.76
New best mean reward!
Eval num_timesteps=55000, episode_reward=-83.86 +/- 27.77
Episode length: 998.15 +/- 16.09
Eval num_timesteps=60000, episode_reward=-77.40 +/- 19.57
Episode length: 994.68 +/- 41.72
Eval num_timesteps=65000, episode_reward=-79.55 +/- 27.61
Episode length: 993.98 +/- 40.48
Eval num_timesteps=70000, episode_reward=-74.50 +/- 59.40
Episode length: 969.31 +/- 80.54
Eval num_timesteps=75000, episode_reward=-70.54 +/- 26.50
Episode length: 995.47 +/- 37.72
Eval num_timesteps=80000, episode_reward=-88.80 +/- 62.90
Episode length: 802.38 +/- 260.76
Eval num_timesteps=85000, episode_reward=-78.46 +/- 59.25
Episode length: 868.22 +/- 215.27
Eval num_timesteps=90000, episode_reward=67.71 +/- 86.81
Episode length: 884.07 +/- 119.71
New best mean reward!
Eval num_timesteps=95000, episode_reward=-39.14 +/- 29.41
Episode length: 993.04 +/- 69.25
Eval num_timesteps=100000, episode_reward=-83.19 +/- 26.96
Episode length: 950.34 +/- 186.74
Eval num_timesteps=105000, episode_reward=-43.32 +/- 38.84
Episode length: 940.16 +/- 201.45
Eval num_timesteps=110000, episode_reward=-122.44 +/- 22.77
Episode length: 939.41 +/- 201.44
Eval num_timesteps=115000, episode_reward=-119.45 +/- 36.69
Episode length: 836.45 +/- 276.66
Eval num_timesteps=120000, episode_reward=-93.22 +/- 30.14
Episode length: 768.43 +/- 324.26
Eval num_timesteps=125000, episode_reward=-120.88 +/- 52.64
Episode length: 752.99 +/- 295.49
Eval num_timesteps=130000, episode_reward=-99.40 +/- 32.41
Episode length: 838.98 +/- 297.60
Eval num_timesteps=135000, episode_reward=-140.97 +/- 52.29
Episode length: 729.28 +/- 317.45
Eval num_timesteps=140000, episode_reward=-122.94 +/- 42.53
Episode length: 609.03 +/- 354.84
Eval num_timesteps=145000, episode_reward=-117.11 +/- 29.88
Episode length: 557.36 +/- 368.22
Eval num_timesteps=150000, episode_reward=-121.48 +/- 31.00
Episode length: 498.02 +/- 328.50
Eval num_timesteps=155000, episode_reward=-123.92 +/- 49.80
Episode length: 649.91 +/- 347.48
Eval num_timesteps=160000, episode_reward=-119.35 +/- 42.28
Episode length: 521.67 +/- 350.12
Eval num_timesteps=165000, episode_reward=-91.68 +/- 30.43
Episode length: 706.59 +/- 362.89
Eval num_timesteps=170000, episode_reward=-127.73 +/- 41.45
Episode length: 753.97 +/- 340.90
Eval num_timesteps=175000, episode_reward=-122.53 +/- 37.98
Episode length: 598.15 +/- 350.06
Eval num_timesteps=180000, episode_reward=-121.12 +/- 31.18
Episode length: 492.34 +/- 350.16
Eval num_timesteps=185000, episode_reward=-113.94 +/- 39.42
Episode length: 528.30 +/- 337.36
Eval num_timesteps=190000, episode_reward=-142.57 +/- 38.63
Episode length: 485.92 +/- 339.26
Eval num_timesteps=195000, episode_reward=-141.31 +/- 39.46
Episode length: 533.91 +/- 356.93
Eval num_timesteps=200000, episode_reward=-115.99 +/- 31.62
Episode length: 538.83 +/- 379.06
Eval num_timesteps=205000, episode_reward=-138.63 +/- 31.95
Episode length: 440.75 +/- 327.46
Eval num_timesteps=210000, episode_reward=-139.53 +/- 35.10
Episode length: 527.37 +/- 354.19
Eval num_timesteps=215000, episode_reward=-119.35 +/- 35.99
Episode length: 570.24 +/- 387.20
Eval num_timesteps=220000, episode_reward=-135.92 +/- 30.94
Episode length: 495.23 +/- 366.14
Eval num_timesteps=225000, episode_reward=-136.93 +/- 36.70
Episode length: 440.36 +/- 326.69
Eval num_timesteps=230000, episode_reward=-144.21 +/- 30.14
Episode length: 427.23 +/- 311.44
Eval num_timesteps=235000, episode_reward=-140.77 +/- 31.76
Episode length: 455.38 +/- 339.11
Eval num_timesteps=240000, episode_reward=-140.81 +/- 30.72
Episode length: 468.74 +/- 346.60
Eval num_timesteps=245000, episode_reward=-140.46 +/- 29.03
Episode length: 378.30 +/- 297.45
Eval num_timesteps=250000, episode_reward=-145.37 +/- 31.15
Episode length: 398.39 +/- 303.76
FINISHED IN 2483.497100913024 s


starting seed  2902 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-808.79 +/- 249.72
Episode length: 328.07 +/- 366.39
New best mean reward!
Eval num_timesteps=10000, episode_reward=-326.34 +/- 50.00
Episode length: 181.44 +/- 35.04
New best mean reward!
Eval num_timesteps=15000, episode_reward=-54.93 +/- 20.65
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=27.67 +/- 95.09
Episode length: 731.62 +/- 243.45
New best mean reward!
Eval num_timesteps=25000, episode_reward=-118.55 +/- 68.93
Episode length: 906.74 +/- 135.51
Eval num_timesteps=30000, episode_reward=-189.81 +/- 58.22
Episode length: 818.04 +/- 185.49
Eval num_timesteps=35000, episode_reward=-78.97 +/- 32.27
Episode length: 997.81 +/- 19.35
Eval num_timesteps=40000, episode_reward=-3.15 +/- 101.41
Episode length: 919.10 +/- 99.02
Eval num_timesteps=45000, episode_reward=-53.50 +/- 59.49
Episode length: 947.95 +/- 113.84
Eval num_timesteps=50000, episode_reward=72.72 +/- 106.47
Episode length: 731.43 +/- 124.25
New best mean reward!
Eval num_timesteps=55000, episode_reward=-113.65 +/- 58.21
Episode length: 720.69 +/- 283.96
Eval num_timesteps=60000, episode_reward=-59.07 +/- 84.22
Episode length: 885.41 +/- 174.74
Eval num_timesteps=65000, episode_reward=-14.24 +/- 89.80
Episode length: 930.99 +/- 120.33
Eval num_timesteps=70000, episode_reward=10.80 +/- 114.81
Episode length: 790.19 +/- 194.25
Eval num_timesteps=75000, episode_reward=-94.91 +/- 75.00
Episode length: 791.76 +/- 271.68
Eval num_timesteps=80000, episode_reward=-26.49 +/- 105.53
Episode length: 592.73 +/- 249.49
Eval num_timesteps=85000, episode_reward=6.24 +/- 112.25
Episode length: 604.29 +/- 267.14
Eval num_timesteps=90000, episode_reward=-71.44 +/- 84.64
Episode length: 410.45 +/- 280.75
Eval num_timesteps=95000, episode_reward=-110.41 +/- 40.24
Episode length: 580.07 +/- 322.99
Eval num_timesteps=100000, episode_reward=-110.09 +/- 55.96
Episode length: 617.00 +/- 355.88
Eval num_timesteps=105000, episode_reward=-136.66 +/- 43.53
Episode length: 545.38 +/- 320.12
Eval num_timesteps=110000, episode_reward=-138.02 +/- 40.25
Episode length: 499.79 +/- 326.75
Eval num_timesteps=115000, episode_reward=-99.66 +/- 28.20
Episode length: 669.76 +/- 373.60
Eval num_timesteps=120000, episode_reward=-119.60 +/- 57.28
Episode length: 621.81 +/- 330.44
Eval num_timesteps=125000, episode_reward=-128.59 +/- 33.19
Episode length: 508.08 +/- 342.11
Eval num_timesteps=130000, episode_reward=-136.02 +/- 35.11
Episode length: 598.41 +/- 372.92
Eval num_timesteps=135000, episode_reward=-136.05 +/- 31.84
Episode length: 472.79 +/- 344.30
Eval num_timesteps=140000, episode_reward=-144.36 +/- 40.32
Episode length: 464.21 +/- 292.09
Eval num_timesteps=145000, episode_reward=-123.87 +/- 36.85
Episode length: 561.47 +/- 375.87
Eval num_timesteps=150000, episode_reward=-110.74 +/- 39.54
Episode length: 587.48 +/- 372.19
Eval num_timesteps=155000, episode_reward=-155.55 +/- 48.90
Episode length: 453.93 +/- 337.80
Eval num_timesteps=160000, episode_reward=-168.14 +/- 45.47
Episode length: 348.37 +/- 280.57
Eval num_timesteps=165000, episode_reward=-152.24 +/- 38.67
Episode length: 334.72 +/- 265.72
Eval num_timesteps=170000, episode_reward=-165.62 +/- 44.57
Episode length: 431.09 +/- 329.25
Eval num_timesteps=175000, episode_reward=-127.87 +/- 30.95
Episode length: 430.73 +/- 328.63
Eval num_timesteps=180000, episode_reward=-154.94 +/- 45.78
Episode length: 476.92 +/- 326.66
Eval num_timesteps=185000, episode_reward=-142.12 +/- 33.75
Episode length: 625.58 +/- 374.09
Eval num_timesteps=190000, episode_reward=-113.99 +/- 34.44
Episode length: 527.23 +/- 368.53
Eval num_timesteps=195000, episode_reward=-155.72 +/- 43.88
Episode length: 546.88 +/- 324.80
Eval num_timesteps=200000, episode_reward=-124.80 +/- 30.31
Episode length: 427.37 +/- 332.60
Eval num_timesteps=205000, episode_reward=-154.50 +/- 48.12
Episode length: 509.95 +/- 338.49
Eval num_timesteps=210000, episode_reward=-135.72 +/- 34.16
Episode length: 495.87 +/- 351.99
Eval num_timesteps=215000, episode_reward=-154.56 +/- 41.74
Episode length: 492.50 +/- 347.59
Eval num_timesteps=220000, episode_reward=-145.57 +/- 32.91
Episode length: 490.45 +/- 350.16
Eval num_timesteps=225000, episode_reward=-144.97 +/- 47.51
Episode length: 482.27 +/- 334.58
Eval num_timesteps=230000, episode_reward=-141.87 +/- 37.73
Episode length: 453.98 +/- 344.45
Eval num_timesteps=235000, episode_reward=-144.67 +/- 42.83
Episode length: 442.22 +/- 346.08
Eval num_timesteps=240000, episode_reward=-146.65 +/- 41.90
Episode length: 495.00 +/- 361.15
Eval num_timesteps=245000, episode_reward=-157.52 +/- 43.48
Episode length: 465.27 +/- 325.02
Eval num_timesteps=250000, episode_reward=-149.30 +/- 34.98
Episode length: 422.04 +/- 311.89
FINISHED IN 2217.768076781009 s


starting seed  2903 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-584.52 +/- 160.13
Episode length: 66.19 +/- 11.70
New best mean reward!
Eval num_timesteps=10000, episode_reward=-968.23 +/- 285.27
Episode length: 248.83 +/- 65.84
Eval num_timesteps=15000, episode_reward=-666.33 +/- 247.60
Episode length: 708.05 +/- 217.53
Eval num_timesteps=20000, episode_reward=-279.20 +/- 44.72
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-82.88 +/- 24.00
Episode length: 992.63 +/- 73.33
New best mean reward!
Eval num_timesteps=30000, episode_reward=-193.21 +/- 31.40
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=-81.07 +/- 41.06
Episode length: 996.02 +/- 36.71
New best mean reward!
Eval num_timesteps=40000, episode_reward=-266.53 +/- 46.46
Episode length: 764.99 +/- 131.54
Eval num_timesteps=45000, episode_reward=-118.97 +/- 19.32
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=50000, episode_reward=-62.77 +/- 44.65
Episode length: 993.41 +/- 33.01
New best mean reward!
Eval num_timesteps=55000, episode_reward=-96.81 +/- 25.69
Episode length: 986.09 +/- 54.74
Eval num_timesteps=60000, episode_reward=-114.73 +/- 72.05
Episode length: 947.34 +/- 92.20
Eval num_timesteps=65000, episode_reward=-93.03 +/- 20.32
Episode length: 998.68 +/- 11.14
Eval num_timesteps=70000, episode_reward=-106.47 +/- 40.99
Episode length: 952.21 +/- 98.81
Eval num_timesteps=75000, episode_reward=-83.79 +/- 24.25
Episode length: 991.86 +/- 40.48
Eval num_timesteps=80000, episode_reward=-32.41 +/- 93.21
Episode length: 930.56 +/- 102.16
New best mean reward!
Eval num_timesteps=85000, episode_reward=-41.96 +/- 55.54
Episode length: 941.28 +/- 148.92
Eval num_timesteps=90000, episode_reward=57.29 +/- 118.69
Episode length: 640.08 +/- 216.38
New best mean reward!
Eval num_timesteps=95000, episode_reward=87.42 +/- 127.03
Episode length: 566.32 +/- 153.06
New best mean reward!
Eval num_timesteps=100000, episode_reward=74.26 +/- 115.41
Episode length: 626.60 +/- 176.53
Eval num_timesteps=105000, episode_reward=-33.35 +/- 89.88
Episode length: 661.38 +/- 300.68
Eval num_timesteps=110000, episode_reward=-43.14 +/- 96.00
Episode length: 552.63 +/- 315.59
Eval num_timesteps=115000, episode_reward=-56.04 +/- 85.33
Episode length: 459.34 +/- 295.31
Eval num_timesteps=120000, episode_reward=-67.35 +/- 83.78
Episode length: 409.38 +/- 237.83
Eval num_timesteps=125000, episode_reward=-56.28 +/- 59.47
Episode length: 598.20 +/- 356.17
Eval num_timesteps=130000, episode_reward=-96.27 +/- 58.97
Episode length: 583.82 +/- 351.29
Eval num_timesteps=135000, episode_reward=-53.67 +/- 35.71
Episode length: 871.19 +/- 275.63
Eval num_timesteps=140000, episode_reward=-122.97 +/- 47.45
Episode length: 620.92 +/- 343.72
Eval num_timesteps=145000, episode_reward=-108.80 +/- 49.38
Episode length: 733.83 +/- 312.93
Eval num_timesteps=150000, episode_reward=-132.61 +/- 50.60
Episode length: 591.59 +/- 321.13
Eval num_timesteps=155000, episode_reward=-110.80 +/- 40.15
Episode length: 644.23 +/- 333.75
Eval num_timesteps=160000, episode_reward=-107.54 +/- 49.53
Episode length: 541.82 +/- 343.53
Eval num_timesteps=165000, episode_reward=-94.12 +/- 36.65
Episode length: 490.28 +/- 344.87
Eval num_timesteps=170000, episode_reward=-95.09 +/- 39.97
Episode length: 559.36 +/- 349.76
Eval num_timesteps=175000, episode_reward=-101.63 +/- 53.46
Episode length: 483.28 +/- 322.07
Eval num_timesteps=180000, episode_reward=-102.75 +/- 41.24
Episode length: 406.87 +/- 293.32
Eval num_timesteps=185000, episode_reward=-110.63 +/- 31.58
Episode length: 478.63 +/- 335.00
Eval num_timesteps=190000, episode_reward=-105.62 +/- 30.42
Episode length: 480.79 +/- 354.90
Eval num_timesteps=195000, episode_reward=-105.08 +/- 47.16
Episode length: 461.32 +/- 321.72
Eval num_timesteps=200000, episode_reward=-113.81 +/- 37.00
Episode length: 394.88 +/- 291.07
Eval num_timesteps=205000, episode_reward=-104.08 +/- 47.58
Episode length: 383.28 +/- 263.89
Eval num_timesteps=210000, episode_reward=-103.91 +/- 54.34
Episode length: 433.06 +/- 311.21
Eval num_timesteps=215000, episode_reward=-99.74 +/- 42.02
Episode length: 511.74 +/- 358.67
Eval num_timesteps=220000, episode_reward=-116.99 +/- 29.08
Episode length: 318.03 +/- 207.04
Eval num_timesteps=225000, episode_reward=-114.22 +/- 53.16
Episode length: 399.99 +/- 289.53
Eval num_timesteps=230000, episode_reward=-114.24 +/- 34.75
Episode length: 350.00 +/- 248.49
Eval num_timesteps=235000, episode_reward=-90.84 +/- 60.63
Episode length: 374.25 +/- 276.53
Eval num_timesteps=240000, episode_reward=-102.87 +/- 49.20
Episode length: 406.50 +/- 295.21
Eval num_timesteps=245000, episode_reward=-101.04 +/- 61.62
Episode length: 385.49 +/- 293.72
Eval num_timesteps=250000, episode_reward=-101.39 +/- 42.55
Episode length: 432.67 +/- 315.73
FINISHED IN 2422.7060368859675 s


starting seed  2904 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-209.61 +/- 161.86
Episode length: 375.10 +/- 164.88
New best mean reward!
Eval num_timesteps=10000, episode_reward=-117.55 +/- 58.52
Episode length: 984.53 +/- 101.11
New best mean reward!
Eval num_timesteps=15000, episode_reward=-383.53 +/- 58.51
Episode length: 825.35 +/- 102.88
Eval num_timesteps=20000, episode_reward=-0.99 +/- 84.84
Episode length: 911.82 +/- 220.36
New best mean reward!
Eval num_timesteps=25000, episode_reward=120.10 +/- 123.26
Episode length: 289.16 +/- 126.61
New best mean reward!
Eval num_timesteps=30000, episode_reward=-102.42 +/- 104.42
Episode length: 681.20 +/- 138.02
Eval num_timesteps=35000, episode_reward=-63.86 +/- 44.03
Episode length: 996.34 +/- 18.02
Eval num_timesteps=40000, episode_reward=136.85 +/- 67.43
Episode length: 803.68 +/- 100.10
New best mean reward!
Eval num_timesteps=45000, episode_reward=120.23 +/- 112.34
Episode length: 612.11 +/- 119.59
Eval num_timesteps=50000, episode_reward=104.88 +/- 109.00
Episode length: 717.87 +/- 116.62
Eval num_timesteps=55000, episode_reward=-101.52 +/- 59.62
Episode length: 950.10 +/- 106.73
Eval num_timesteps=60000, episode_reward=82.93 +/- 117.43
Episode length: 686.62 +/- 102.13
Eval num_timesteps=65000, episode_reward=12.45 +/- 130.23
Episode length: 656.79 +/- 164.31
Eval num_timesteps=70000, episode_reward=-61.52 +/- 22.92
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=75000, episode_reward=128.87 +/- 83.24
Episode length: 782.94 +/- 79.67
Eval num_timesteps=80000, episode_reward=58.96 +/- 143.00
Episode length: 551.34 +/- 140.94
Eval num_timesteps=85000, episode_reward=16.22 +/- 125.31
Episode length: 506.75 +/- 184.91
Eval num_timesteps=90000, episode_reward=22.41 +/- 119.51
Episode length: 493.17 +/- 218.95
Eval num_timesteps=95000, episode_reward=-58.26 +/- 97.23
Episode length: 535.22 +/- 283.49
Eval num_timesteps=100000, episode_reward=-83.79 +/- 34.15
Episode length: 749.01 +/- 330.93
Eval num_timesteps=105000, episode_reward=-103.21 +/- 59.10
Episode length: 644.01 +/- 332.23
Eval num_timesteps=110000, episode_reward=-38.22 +/- 104.41
Episode length: 604.85 +/- 277.56
Eval num_timesteps=115000, episode_reward=-86.55 +/- 72.21
Episode length: 350.04 +/- 207.56
Eval num_timesteps=120000, episode_reward=-87.65 +/- 68.18
Episode length: 541.58 +/- 329.53
Eval num_timesteps=125000, episode_reward=-93.73 +/- 69.79
Episode length: 328.63 +/- 216.50
Eval num_timesteps=130000, episode_reward=-106.85 +/- 58.50
Episode length: 649.28 +/- 357.84
Eval num_timesteps=135000, episode_reward=-71.20 +/- 50.88
Episode length: 650.42 +/- 381.69
Eval num_timesteps=140000, episode_reward=-55.15 +/- 98.20
Episode length: 553.39 +/- 336.47
Eval num_timesteps=145000, episode_reward=-20.30 +/- 117.41
Episode length: 410.18 +/- 239.04
Eval num_timesteps=150000, episode_reward=-27.82 +/- 116.12
Episode length: 363.83 +/- 201.32
Eval num_timesteps=155000, episode_reward=-45.25 +/- 92.68
Episode length: 432.10 +/- 265.23
Eval num_timesteps=160000, episode_reward=-77.01 +/- 100.55
Episode length: 380.46 +/- 200.44
Eval num_timesteps=165000, episode_reward=-39.39 +/- 97.93
Episode length: 325.28 +/- 195.90
Eval num_timesteps=170000, episode_reward=-72.36 +/- 95.27
Episode length: 394.84 +/- 210.76
Eval num_timesteps=175000, episode_reward=-3.13 +/- 109.17
Episode length: 501.63 +/- 295.43
Eval num_timesteps=180000, episode_reward=-5.31 +/- 106.80
Episode length: 597.08 +/- 338.04
Eval num_timesteps=185000, episode_reward=15.15 +/- 118.05
Episode length: 512.82 +/- 322.08
Eval num_timesteps=190000, episode_reward=-7.68 +/- 108.68
Episode length: 551.92 +/- 343.04
Eval num_timesteps=195000, episode_reward=57.00 +/- 120.40
Episode length: 535.70 +/- 308.23
Eval num_timesteps=200000, episode_reward=30.85 +/- 125.39
Episode length: 445.64 +/- 223.25
Eval num_timesteps=205000, episode_reward=23.44 +/- 118.60
Episode length: 493.51 +/- 251.51
Eval num_timesteps=210000, episode_reward=-17.20 +/- 107.61
Episode length: 461.02 +/- 304.72
Eval num_timesteps=215000, episode_reward=-31.93 +/- 118.33
Episode length: 387.38 +/- 258.84
Eval num_timesteps=220000, episode_reward=-4.37 +/- 111.26
Episode length: 460.21 +/- 285.08
Eval num_timesteps=225000, episode_reward=-18.94 +/- 105.63
Episode length: 468.03 +/- 333.60
Eval num_timesteps=230000, episode_reward=-16.55 +/- 109.67
Episode length: 483.90 +/- 316.08
Eval num_timesteps=235000, episode_reward=-39.86 +/- 104.30
Episode length: 526.27 +/- 327.09
Eval num_timesteps=240000, episode_reward=-49.28 +/- 92.20
Episode length: 457.07 +/- 331.32
Eval num_timesteps=245000, episode_reward=-56.57 +/- 93.87
Episode length: 465.88 +/- 324.48
Eval num_timesteps=250000, episode_reward=-59.66 +/- 92.10
Episode length: 454.11 +/- 329.45
FINISHED IN 2151.4867741800263 s


starting seed  2905 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-145.73 +/- 121.70
Episode length: 685.26 +/- 385.68
New best mean reward!
Eval num_timesteps=10000, episode_reward=-293.55 +/- 26.97
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=15000, episode_reward=32.10 +/- 89.46
Episode length: 853.72 +/- 167.73
New best mean reward!
Eval num_timesteps=20000, episode_reward=44.88 +/- 120.24
Episode length: 537.12 +/- 189.24
New best mean reward!
Eval num_timesteps=25000, episode_reward=6.04 +/- 126.94
Episode length: 467.53 +/- 133.46
Eval num_timesteps=30000, episode_reward=103.72 +/- 116.10
Episode length: 530.86 +/- 164.85
New best mean reward!
Eval num_timesteps=35000, episode_reward=-85.72 +/- 61.28
Episode length: 867.35 +/- 197.66
Eval num_timesteps=40000, episode_reward=-141.67 +/- 42.73
Episode length: 903.95 +/- 159.94
Eval num_timesteps=45000, episode_reward=-154.66 +/- 33.67
Episode length: 867.27 +/- 219.15
Eval num_timesteps=50000, episode_reward=-79.77 +/- 53.18
Episode length: 905.42 +/- 201.97
Eval num_timesteps=55000, episode_reward=79.26 +/- 114.94
Episode length: 641.28 +/- 218.42
Eval num_timesteps=60000, episode_reward=60.00 +/- 137.96
Episode length: 404.28 +/- 135.88
Eval num_timesteps=65000, episode_reward=-69.39 +/- 90.73
Episode length: 743.62 +/- 240.15
Eval num_timesteps=70000, episode_reward=-14.62 +/- 113.95
Episode length: 462.55 +/- 185.27
Eval num_timesteps=75000, episode_reward=-93.80 +/- 55.43
Episode length: 485.38 +/- 313.18
Eval num_timesteps=80000, episode_reward=-143.09 +/- 58.76
Episode length: 502.78 +/- 331.47
Eval num_timesteps=85000, episode_reward=-135.33 +/- 41.18
Episode length: 405.41 +/- 284.94
Eval num_timesteps=90000, episode_reward=-152.39 +/- 56.44
Episode length: 564.69 +/- 346.93
Eval num_timesteps=95000, episode_reward=-152.79 +/- 52.07
Episode length: 506.62 +/- 341.18
Eval num_timesteps=100000, episode_reward=-130.35 +/- 29.63
Episode length: 342.45 +/- 238.49
Eval num_timesteps=105000, episode_reward=-128.11 +/- 31.16
Episode length: 325.38 +/- 239.58
Eval num_timesteps=110000, episode_reward=-137.94 +/- 41.62
Episode length: 483.57 +/- 337.01
Eval num_timesteps=115000, episode_reward=-111.97 +/- 39.34
Episode length: 626.97 +/- 357.95
Eval num_timesteps=120000, episode_reward=-101.72 +/- 28.66
Episode length: 585.49 +/- 382.80
Eval num_timesteps=125000, episode_reward=-122.66 +/- 38.17
Episode length: 492.74 +/- 339.48
Eval num_timesteps=130000, episode_reward=-139.66 +/- 35.18
Episode length: 485.22 +/- 317.49
Eval num_timesteps=135000, episode_reward=-134.09 +/- 40.11
Episode length: 516.38 +/- 331.30
Eval num_timesteps=140000, episode_reward=-96.62 +/- 56.12
Episode length: 492.71 +/- 335.47
Eval num_timesteps=145000, episode_reward=-119.89 +/- 50.05
Episode length: 454.37 +/- 332.17
Eval num_timesteps=150000, episode_reward=-115.44 +/- 41.31
Episode length: 537.05 +/- 350.81
Eval num_timesteps=155000, episode_reward=-129.91 +/- 42.89
Episode length: 467.91 +/- 350.51
Eval num_timesteps=160000, episode_reward=-117.40 +/- 35.64
Episode length: 471.50 +/- 320.71
Eval num_timesteps=165000, episode_reward=-117.01 +/- 44.07
Episode length: 362.88 +/- 268.55
Eval num_timesteps=170000, episode_reward=-97.75 +/- 46.98
Episode length: 334.13 +/- 254.91
Eval num_timesteps=175000, episode_reward=-87.98 +/- 65.38
Episode length: 364.44 +/- 275.26
Eval num_timesteps=180000, episode_reward=-92.76 +/- 55.86
Episode length: 349.31 +/- 270.01
Eval num_timesteps=185000, episode_reward=-99.63 +/- 47.05
Episode length: 414.14 +/- 308.18
Eval num_timesteps=190000, episode_reward=-120.93 +/- 31.91
Episode length: 390.06 +/- 293.75
Eval num_timesteps=195000, episode_reward=-124.98 +/- 38.09
Episode length: 378.42 +/- 273.31
Eval num_timesteps=200000, episode_reward=-125.54 +/- 40.67
Episode length: 457.29 +/- 326.38
Eval num_timesteps=205000, episode_reward=-119.27 +/- 31.73
Episode length: 490.71 +/- 343.22
Eval num_timesteps=210000, episode_reward=-130.33 +/- 39.75
Episode length: 429.43 +/- 279.30
Eval num_timesteps=215000, episode_reward=-122.77 +/- 39.01
Episode length: 456.87 +/- 312.65
Eval num_timesteps=220000, episode_reward=-115.53 +/- 37.69
Episode length: 474.33 +/- 317.19
Eval num_timesteps=225000, episode_reward=-98.24 +/- 35.71
Episode length: 496.52 +/- 352.01
Eval num_timesteps=230000, episode_reward=-97.27 +/- 35.95
Episode length: 438.25 +/- 343.64
Eval num_timesteps=235000, episode_reward=-101.28 +/- 27.16
Episode length: 430.62 +/- 338.58
Eval num_timesteps=240000, episode_reward=-106.47 +/- 35.17
Episode length: 483.13 +/- 353.85
Eval num_timesteps=245000, episode_reward=-106.02 +/- 29.91
Episode length: 478.10 +/- 342.13
Eval num_timesteps=250000, episode_reward=-117.76 +/- 38.31
Episode length: 500.29 +/- 337.67
FINISHED IN 1860.6229676340008 s


starting seed  2906 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-191.88 +/- 57.93
Episode length: 69.89 +/- 10.89
New best mean reward!
Eval num_timesteps=10000, episode_reward=-314.15 +/- 60.44
Episode length: 214.71 +/- 42.01
Eval num_timesteps=15000, episode_reward=-216.47 +/- 22.66
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=-148.22 +/- 25.92
Episode length: 993.02 +/- 69.45
New best mean reward!
Eval num_timesteps=25000, episode_reward=-279.68 +/- 44.27
Episode length: 820.77 +/- 121.68
Eval num_timesteps=30000, episode_reward=-97.37 +/- 74.46
Episode length: 243.54 +/- 51.45
New best mean reward!
Eval num_timesteps=35000, episode_reward=175.65 +/- 57.87
Episode length: 691.60 +/- 111.52
New best mean reward!
Eval num_timesteps=40000, episode_reward=-96.02 +/- 89.11
Episode length: 478.43 +/- 104.73
Eval num_timesteps=45000, episode_reward=-79.29 +/- 92.75
Episode length: 419.38 +/- 124.50
Eval num_timesteps=50000, episode_reward=-7.27 +/- 143.97
Episode length: 889.95 +/- 111.09
Eval num_timesteps=55000, episode_reward=-91.65 +/- 65.55
Episode length: 305.03 +/- 79.34
Eval num_timesteps=60000, episode_reward=52.61 +/- 114.19
Episode length: 737.21 +/- 145.32
Eval num_timesteps=65000, episode_reward=78.63 +/- 132.48
Episode length: 636.56 +/- 104.21
Eval num_timesteps=70000, episode_reward=-131.23 +/- 64.08
Episode length: 937.53 +/- 114.48
Eval num_timesteps=75000, episode_reward=96.44 +/- 96.25
Episode length: 807.87 +/- 87.01
Eval num_timesteps=80000, episode_reward=131.79 +/- 108.31
Episode length: 554.02 +/- 126.77
Eval num_timesteps=85000, episode_reward=-24.10 +/- 29.46
Episode length: 998.12 +/- 15.92
Eval num_timesteps=90000, episode_reward=-57.53 +/- 22.42
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=95000, episode_reward=-20.49 +/- 58.60
Episode length: 993.79 +/- 23.57
Eval num_timesteps=100000, episode_reward=194.70 +/- 89.57
Episode length: 413.24 +/- 78.73
New best mean reward!
Eval num_timesteps=105000, episode_reward=152.78 +/- 121.75
Episode length: 348.96 +/- 96.27
Eval num_timesteps=110000, episode_reward=197.10 +/- 88.64
Episode length: 446.53 +/- 147.34
New best mean reward!
FINISHED IN 910.882731352991 s


starting seed  2907 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-215.59 +/- 53.38
Episode length: 820.96 +/- 211.02
New best mean reward!
Eval num_timesteps=10000, episode_reward=-200.42 +/- 42.76
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=-119.26 +/- 30.28
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=75.24 +/- 91.93
Episode length: 771.02 +/- 216.72
New best mean reward!
Eval num_timesteps=25000, episode_reward=62.79 +/- 106.65
Episode length: 928.71 +/- 72.93
Eval num_timesteps=30000, episode_reward=-48.97 +/- 116.92
Episode length: 644.84 +/- 231.90
Eval num_timesteps=35000, episode_reward=-35.42 +/- 134.78
Episode length: 517.79 +/- 182.60
Eval num_timesteps=40000, episode_reward=-53.81 +/- 116.36
Episode length: 563.84 +/- 184.77
Eval num_timesteps=45000, episode_reward=-33.60 +/- 108.96
Episode length: 692.21 +/- 230.05
Eval num_timesteps=50000, episode_reward=55.24 +/- 104.61
Episode length: 700.34 +/- 184.48
Eval num_timesteps=55000, episode_reward=44.97 +/- 112.21
Episode length: 755.13 +/- 197.50
Eval num_timesteps=60000, episode_reward=-38.78 +/- 115.24
Episode length: 542.37 +/- 308.74
Eval num_timesteps=65000, episode_reward=-77.11 +/- 55.51
Episode length: 866.08 +/- 242.45
Eval num_timesteps=70000, episode_reward=-47.42 +/- 68.12
Episode length: 847.83 +/- 266.48
Eval num_timesteps=75000, episode_reward=-96.05 +/- 41.52
Episode length: 741.90 +/- 294.97
Eval num_timesteps=80000, episode_reward=-70.76 +/- 92.06
Episode length: 709.43 +/- 262.20
Eval num_timesteps=85000, episode_reward=4.61 +/- 136.67
Episode length: 349.65 +/- 110.10
Eval num_timesteps=90000, episode_reward=-56.24 +/- 98.59
Episode length: 383.39 +/- 173.88
Eval num_timesteps=95000, episode_reward=-45.41 +/- 108.26
Episode length: 432.01 +/- 221.61
Eval num_timesteps=100000, episode_reward=-85.28 +/- 79.87
Episode length: 487.29 +/- 263.68
Eval num_timesteps=105000, episode_reward=-50.68 +/- 105.14
Episode length: 463.30 +/- 212.02
Eval num_timesteps=110000, episode_reward=-107.62 +/- 82.27
Episode length: 584.65 +/- 294.35
Eval num_timesteps=115000, episode_reward=-39.90 +/- 131.26
Episode length: 460.65 +/- 219.33
Eval num_timesteps=120000, episode_reward=-17.23 +/- 114.71
Episode length: 487.49 +/- 227.68
Eval num_timesteps=125000, episode_reward=-60.91 +/- 24.97
Episode length: 875.41 +/- 276.86
Eval num_timesteps=130000, episode_reward=-98.08 +/- 75.61
Episode length: 723.42 +/- 317.40
Eval num_timesteps=135000, episode_reward=-16.20 +/- 94.20
Episode length: 830.85 +/- 264.40
Eval num_timesteps=140000, episode_reward=-88.84 +/- 59.97
Episode length: 792.76 +/- 315.33
Eval num_timesteps=145000, episode_reward=-102.47 +/- 55.34
Episode length: 743.29 +/- 328.32
Eval num_timesteps=150000, episode_reward=-136.41 +/- 36.67
Episode length: 352.95 +/- 252.29
Eval num_timesteps=155000, episode_reward=-96.92 +/- 72.51
Episode length: 372.91 +/- 238.93
Eval num_timesteps=160000, episode_reward=-118.51 +/- 47.44
Episode length: 292.30 +/- 176.97
Eval num_timesteps=165000, episode_reward=-139.34 +/- 30.97
Episode length: 305.61 +/- 220.31
Eval num_timesteps=170000, episode_reward=-129.16 +/- 50.81
Episode length: 382.49 +/- 261.82
Eval num_timesteps=175000, episode_reward=-82.29 +/- 89.80
Episode length: 374.20 +/- 220.06
Eval num_timesteps=180000, episode_reward=-81.69 +/- 84.66
Episode length: 380.41 +/- 205.78
Eval num_timesteps=185000, episode_reward=-75.69 +/- 85.83
Episode length: 385.90 +/- 214.95
Eval num_timesteps=190000, episode_reward=-77.75 +/- 92.15
Episode length: 401.09 +/- 232.58
Eval num_timesteps=195000, episode_reward=-80.67 +/- 85.64
Episode length: 416.64 +/- 255.86
Eval num_timesteps=200000, episode_reward=-84.30 +/- 76.77
Episode length: 362.84 +/- 217.50
Eval num_timesteps=205000, episode_reward=-105.23 +/- 60.49
Episode length: 378.10 +/- 243.03
Eval num_timesteps=210000, episode_reward=-97.69 +/- 61.24
Episode length: 368.18 +/- 253.91
Eval num_timesteps=215000, episode_reward=-90.30 +/- 73.91
Episode length: 368.68 +/- 253.49
Eval num_timesteps=220000, episode_reward=-72.11 +/- 87.44
Episode length: 343.03 +/- 224.09
Eval num_timesteps=225000, episode_reward=-85.82 +/- 65.95
Episode length: 328.60 +/- 179.69
Eval num_timesteps=230000, episode_reward=-46.80 +/- 100.52
Episode length: 341.13 +/- 185.66
Eval num_timesteps=235000, episode_reward=-83.42 +/- 79.96
Episode length: 331.01 +/- 199.07
Eval num_timesteps=240000, episode_reward=-79.98 +/- 89.96
Episode length: 341.65 +/- 184.30
Eval num_timesteps=245000, episode_reward=-72.22 +/- 87.31
Episode length: 360.11 +/- 226.30
Eval num_timesteps=250000, episode_reward=-63.44 +/- 98.82
Episode length: 380.55 +/- 224.09
FINISHED IN 1768.907370248984 s


starting seed  2908 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-215.60 +/- 82.04
Episode length: 69.40 +/- 12.18
New best mean reward!
Eval num_timesteps=10000, episode_reward=-582.86 +/- 101.35
Episode length: 364.99 +/- 54.63
Eval num_timesteps=15000, episode_reward=-114.35 +/- 52.62
Episode length: 983.64 +/- 47.99
New best mean reward!
Eval num_timesteps=20000, episode_reward=-50.54 +/- 29.04
Episode length: 998.16 +/- 15.58
New best mean reward!
Eval num_timesteps=25000, episode_reward=-55.42 +/- 98.48
Episode length: 480.21 +/- 202.21
Eval num_timesteps=30000, episode_reward=-135.98 +/- 44.00
Episode length: 810.69 +/- 219.68
Eval num_timesteps=35000, episode_reward=-106.51 +/- 58.82
Episode length: 750.71 +/- 259.63
Eval num_timesteps=40000, episode_reward=-59.90 +/- 47.27
Episode length: 979.39 +/- 64.54
Eval num_timesteps=45000, episode_reward=6.45 +/- 114.29
Episode length: 562.03 +/- 202.98
New best mean reward!
Eval num_timesteps=50000, episode_reward=25.56 +/- 112.37
Episode length: 467.74 +/- 212.33
New best mean reward!
Eval num_timesteps=55000, episode_reward=-71.75 +/- 97.25
Episode length: 487.35 +/- 246.09
Eval num_timesteps=60000, episode_reward=-88.75 +/- 76.38
Episode length: 759.23 +/- 261.01
Eval num_timesteps=65000, episode_reward=-90.28 +/- 50.02
Episode length: 861.33 +/- 238.04
Eval num_timesteps=70000, episode_reward=32.00 +/- 108.69
Episode length: 710.15 +/- 229.35
New best mean reward!
Eval num_timesteps=75000, episode_reward=3.72 +/- 127.91
Episode length: 434.57 +/- 199.32
Eval num_timesteps=80000, episode_reward=-105.82 +/- 48.45
Episode length: 681.95 +/- 313.60
Eval num_timesteps=85000, episode_reward=-139.62 +/- 53.32
Episode length: 634.29 +/- 291.90
Eval num_timesteps=90000, episode_reward=-150.84 +/- 47.05
Episode length: 688.08 +/- 293.31
Eval num_timesteps=95000, episode_reward=-131.68 +/- 48.75
Episode length: 587.46 +/- 316.06
Eval num_timesteps=100000, episode_reward=-145.65 +/- 48.38
Episode length: 651.85 +/- 304.64
Eval num_timesteps=105000, episode_reward=-132.22 +/- 52.91
Episode length: 559.04 +/- 323.62
Eval num_timesteps=110000, episode_reward=-125.88 +/- 42.83
Episode length: 479.00 +/- 313.01
Eval num_timesteps=115000, episode_reward=-125.71 +/- 33.13
Episode length: 360.10 +/- 246.52
Eval num_timesteps=120000, episode_reward=-111.85 +/- 41.72
Episode length: 535.71 +/- 346.36
Eval num_timesteps=125000, episode_reward=-118.24 +/- 36.50
Episode length: 494.29 +/- 332.24
Eval num_timesteps=130000, episode_reward=-113.45 +/- 35.64
Episode length: 425.87 +/- 326.83
Eval num_timesteps=135000, episode_reward=-130.17 +/- 31.94
Episode length: 553.18 +/- 358.33
Eval num_timesteps=140000, episode_reward=-123.25 +/- 23.41
Episode length: 357.05 +/- 267.50
Eval num_timesteps=145000, episode_reward=-119.20 +/- 43.81
Episode length: 412.95 +/- 288.46
Eval num_timesteps=150000, episode_reward=-92.33 +/- 76.28
Episode length: 418.24 +/- 296.37
Eval num_timesteps=155000, episode_reward=-91.35 +/- 59.06
Episode length: 550.26 +/- 344.36
Eval num_timesteps=160000, episode_reward=-125.97 +/- 48.25
Episode length: 350.85 +/- 240.48
Eval num_timesteps=165000, episode_reward=-113.55 +/- 45.81
Episode length: 383.52 +/- 281.03
Eval num_timesteps=170000, episode_reward=-125.55 +/- 31.62
Episode length: 387.28 +/- 294.20
Eval num_timesteps=175000, episode_reward=-133.78 +/- 34.33
Episode length: 379.85 +/- 268.85
Eval num_timesteps=180000, episode_reward=-128.45 +/- 30.38
Episode length: 416.53 +/- 330.90
Eval num_timesteps=185000, episode_reward=-133.13 +/- 32.03
Episode length: 404.37 +/- 289.08
Eval num_timesteps=190000, episode_reward=-121.52 +/- 34.92
Episode length: 400.27 +/- 287.90
Eval num_timesteps=195000, episode_reward=-137.29 +/- 35.99
Episode length: 375.75 +/- 275.45
Eval num_timesteps=200000, episode_reward=-131.40 +/- 33.78
Episode length: 383.52 +/- 295.01
Eval num_timesteps=205000, episode_reward=-130.33 +/- 37.54
Episode length: 430.34 +/- 315.63
Eval num_timesteps=210000, episode_reward=-123.05 +/- 45.55
Episode length: 459.44 +/- 330.58
Eval num_timesteps=215000, episode_reward=-115.67 +/- 29.64
Episode length: 476.15 +/- 330.99
Eval num_timesteps=220000, episode_reward=-120.30 +/- 32.54
Episode length: 400.03 +/- 315.24
Eval num_timesteps=225000, episode_reward=-126.15 +/- 35.06
Episode length: 440.19 +/- 328.65
Eval num_timesteps=230000, episode_reward=-121.69 +/- 28.53
Episode length: 396.88 +/- 301.91
Eval num_timesteps=235000, episode_reward=-128.56 +/- 33.00
Episode length: 383.17 +/- 284.71
Eval num_timesteps=240000, episode_reward=-128.74 +/- 36.10
Episode length: 394.79 +/- 304.38
Eval num_timesteps=245000, episode_reward=-129.40 +/- 33.45
Episode length: 355.69 +/- 263.20
Eval num_timesteps=250000, episode_reward=-134.19 +/- 31.54
Episode length: 375.42 +/- 273.45
FINISHED IN 1945.3337396809948 s


starting seed  2909 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-626.42 +/- 56.00
Episode length: 418.60 +/- 39.95
New best mean reward!
Eval num_timesteps=10000, episode_reward=-106.61 +/- 22.35
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=-46.23 +/- 16.73
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-71.55 +/- 21.60
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=25000, episode_reward=-105.24 +/- 22.39
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=30000, episode_reward=21.39 +/- 85.52
Episode length: 929.95 +/- 89.82
New best mean reward!
Eval num_timesteps=35000, episode_reward=16.13 +/- 78.02
Episode length: 979.35 +/- 42.88
Eval num_timesteps=40000, episode_reward=33.04 +/- 113.43
Episode length: 761.58 +/- 168.57
New best mean reward!
Eval num_timesteps=45000, episode_reward=-57.91 +/- 120.40
Episode length: 690.92 +/- 166.35
Eval num_timesteps=50000, episode_reward=-34.79 +/- 136.33
Episode length: 570.57 +/- 168.15
Eval num_timesteps=55000, episode_reward=116.87 +/- 116.01
Episode length: 387.51 +/- 142.23
New best mean reward!
Eval num_timesteps=60000, episode_reward=-4.68 +/- 122.83
Episode length: 455.95 +/- 198.59
Eval num_timesteps=65000, episode_reward=-101.52 +/- 78.83
Episode length: 670.43 +/- 310.52
Eval num_timesteps=70000, episode_reward=-117.75 +/- 61.08
Episode length: 799.99 +/- 262.80
Eval num_timesteps=75000, episode_reward=-94.33 +/- 79.72
Episode length: 497.93 +/- 256.43
Eval num_timesteps=80000, episode_reward=-83.42 +/- 68.25
Episode length: 556.80 +/- 284.47
Eval num_timesteps=85000, episode_reward=-18.16 +/- 111.83
Episode length: 560.21 +/- 260.66
Eval num_timesteps=90000, episode_reward=-93.70 +/- 59.42
Episode length: 587.54 +/- 311.42
Eval num_timesteps=95000, episode_reward=-83.62 +/- 43.59
Episode length: 599.87 +/- 373.83
Eval num_timesteps=100000, episode_reward=-88.58 +/- 30.60
Episode length: 596.00 +/- 374.87
Eval num_timesteps=105000, episode_reward=-67.80 +/- 36.31
Episode length: 733.52 +/- 361.85
Eval num_timesteps=110000, episode_reward=-50.71 +/- 88.37
Episode length: 489.36 +/- 330.78
Eval num_timesteps=115000, episode_reward=-77.41 +/- 62.65
Episode length: 573.49 +/- 356.10
Eval num_timesteps=120000, episode_reward=-120.54 +/- 47.31
Episode length: 332.46 +/- 242.11
Eval num_timesteps=125000, episode_reward=-57.74 +/- 79.59
Episode length: 598.62 +/- 355.25
Eval num_timesteps=130000, episode_reward=-73.88 +/- 31.16
Episode length: 740.06 +/- 365.18
Eval num_timesteps=135000, episode_reward=-114.44 +/- 29.10
Episode length: 601.34 +/- 384.41
Eval num_timesteps=140000, episode_reward=-126.08 +/- 36.98
Episode length: 409.35 +/- 292.91
Eval num_timesteps=145000, episode_reward=-119.82 +/- 40.95
Episode length: 367.80 +/- 267.09
Eval num_timesteps=150000, episode_reward=-126.56 +/- 45.70
Episode length: 459.22 +/- 335.51
Eval num_timesteps=155000, episode_reward=-87.80 +/- 31.06
Episode length: 632.01 +/- 391.98
Eval num_timesteps=160000, episode_reward=-114.50 +/- 29.24
Episode length: 418.62 +/- 321.27
Eval num_timesteps=165000, episode_reward=-123.56 +/- 29.80
Episode length: 425.71 +/- 356.44
Eval num_timesteps=170000, episode_reward=-112.15 +/- 33.59
Episode length: 465.89 +/- 358.75
Eval num_timesteps=175000, episode_reward=-116.72 +/- 38.07
Episode length: 401.59 +/- 310.73
Eval num_timesteps=180000, episode_reward=-89.14 +/- 45.04
Episode length: 457.32 +/- 358.55
Eval num_timesteps=185000, episode_reward=-118.04 +/- 52.77
Episode length: 452.24 +/- 317.22
Eval num_timesteps=190000, episode_reward=-62.54 +/- 63.47
Episode length: 584.64 +/- 375.56
Eval num_timesteps=195000, episode_reward=-84.53 +/- 58.28
Episode length: 573.22 +/- 379.65
Eval num_timesteps=200000, episode_reward=-78.46 +/- 82.84
Episode length: 471.51 +/- 323.68
Eval num_timesteps=205000, episode_reward=-70.17 +/- 84.90
Episode length: 404.06 +/- 275.56
Eval num_timesteps=210000, episode_reward=-79.98 +/- 108.39
Episode length: 428.44 +/- 278.42
Eval num_timesteps=215000, episode_reward=-89.52 +/- 72.33
Episode length: 454.57 +/- 296.61
Eval num_timesteps=220000, episode_reward=-66.93 +/- 93.38
Episode length: 508.14 +/- 328.70
Eval num_timesteps=225000, episode_reward=-73.11 +/- 53.30
Episode length: 613.88 +/- 390.11
Eval num_timesteps=230000, episode_reward=-71.21 +/- 67.09
Episode length: 551.65 +/- 372.72
Eval num_timesteps=235000, episode_reward=-93.75 +/- 47.85
Episode length: 513.36 +/- 371.75
Eval num_timesteps=240000, episode_reward=-78.42 +/- 55.04
Episode length: 630.03 +/- 384.32
Eval num_timesteps=245000, episode_reward=-87.04 +/- 48.09
Episode length: 569.79 +/- 390.13
Eval num_timesteps=250000, episode_reward=-87.29 +/- 45.25
Episode length: 479.50 +/- 373.42
FINISHED IN 2152.6363613330177 s


starting seed  2910 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-2351.85 +/- 1134.26
Episode length: 614.26 +/- 241.16
New best mean reward!
Eval num_timesteps=10000, episode_reward=-203.76 +/- 24.80
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=-248.65 +/- 22.12
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=-34.06 +/- 23.49
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-34.08 +/- 112.21
Episode length: 761.58 +/- 223.51
Eval num_timesteps=30000, episode_reward=-127.21 +/- 60.87
Episode length: 546.37 +/- 262.69
Eval num_timesteps=35000, episode_reward=-87.27 +/- 101.03
Episode length: 502.81 +/- 230.54
Eval num_timesteps=40000, episode_reward=-15.23 +/- 106.68
Episode length: 765.66 +/- 198.24
New best mean reward!
Eval num_timesteps=45000, episode_reward=-24.83 +/- 116.30
Episode length: 469.85 +/- 214.93
Eval num_timesteps=50000, episode_reward=-25.04 +/- 116.40
Episode length: 705.81 +/- 235.88
Eval num_timesteps=55000, episode_reward=-117.17 +/- 52.97
Episode length: 541.70 +/- 295.98
Eval num_timesteps=60000, episode_reward=-120.26 +/- 41.86
Episode length: 484.51 +/- 323.95
Eval num_timesteps=65000, episode_reward=-104.15 +/- 50.72
Episode length: 693.54 +/- 335.09
Eval num_timesteps=70000, episode_reward=-117.58 +/- 54.52
Episode length: 758.92 +/- 321.79
Eval num_timesteps=75000, episode_reward=-202.37 +/- 60.29
Episode length: 656.66 +/- 337.88
Eval num_timesteps=80000, episode_reward=-138.24 +/- 35.70
Episode length: 730.36 +/- 335.42
Eval num_timesteps=85000, episode_reward=-114.49 +/- 53.25
Episode length: 536.01 +/- 332.91
Eval num_timesteps=90000, episode_reward=-126.95 +/- 33.15
Episode length: 522.32 +/- 333.32
Eval num_timesteps=95000, episode_reward=-157.40 +/- 46.61
Episode length: 424.82 +/- 318.55
Eval num_timesteps=100000, episode_reward=-155.43 +/- 37.73
Episode length: 385.57 +/- 285.87
Eval num_timesteps=105000, episode_reward=-128.87 +/- 37.88
Episode length: 427.27 +/- 334.41
Eval num_timesteps=110000, episode_reward=-140.38 +/- 35.66
Episode length: 447.37 +/- 315.49
Eval num_timesteps=115000, episode_reward=-134.62 +/- 33.19
Episode length: 442.99 +/- 312.26
Eval num_timesteps=120000, episode_reward=-131.86 +/- 48.25
Episode length: 487.50 +/- 345.95
Eval num_timesteps=125000, episode_reward=-133.25 +/- 36.44
Episode length: 427.98 +/- 314.40
Eval num_timesteps=130000, episode_reward=-143.62 +/- 36.49
Episode length: 461.46 +/- 326.43
Eval num_timesteps=135000, episode_reward=-173.91 +/- 44.00
Episode length: 453.60 +/- 322.73
Eval num_timesteps=140000, episode_reward=-126.80 +/- 51.09
Episode length: 410.61 +/- 300.82
Eval num_timesteps=145000, episode_reward=-91.38 +/- 57.68
Episode length: 379.42 +/- 279.74
Eval num_timesteps=150000, episode_reward=-110.51 +/- 55.12
Episode length: 407.35 +/- 299.21
Eval num_timesteps=155000, episode_reward=-105.34 +/- 42.37
Episode length: 482.67 +/- 346.91
Eval num_timesteps=160000, episode_reward=-102.98 +/- 49.87
Episode length: 454.57 +/- 310.80
Eval num_timesteps=165000, episode_reward=-119.97 +/- 43.71
Episode length: 488.63 +/- 357.47
Eval num_timesteps=170000, episode_reward=-124.05 +/- 66.38
Episode length: 455.89 +/- 300.74
Eval num_timesteps=175000, episode_reward=-95.59 +/- 48.24
Episode length: 400.31 +/- 297.48
Eval num_timesteps=180000, episode_reward=-93.39 +/- 39.64
Episode length: 517.47 +/- 349.19
Eval num_timesteps=185000, episode_reward=-90.99 +/- 53.69
Episode length: 558.46 +/- 369.45
Eval num_timesteps=190000, episode_reward=-97.64 +/- 57.36
Episode length: 562.28 +/- 352.27
Eval num_timesteps=195000, episode_reward=-125.82 +/- 34.60
Episode length: 466.21 +/- 346.18
Eval num_timesteps=200000, episode_reward=-122.79 +/- 40.48
Episode length: 515.60 +/- 335.53
Eval num_timesteps=205000, episode_reward=-126.46 +/- 54.47
Episode length: 515.80 +/- 342.25
Eval num_timesteps=210000, episode_reward=-101.35 +/- 55.26
Episode length: 549.49 +/- 350.59
Eval num_timesteps=215000, episode_reward=-115.43 +/- 40.29
Episode length: 433.24 +/- 318.64
Eval num_timesteps=220000, episode_reward=-106.41 +/- 34.25
Episode length: 453.60 +/- 342.15
Eval num_timesteps=225000, episode_reward=-106.89 +/- 44.86
Episode length: 494.83 +/- 346.58
Eval num_timesteps=230000, episode_reward=-93.55 +/- 53.19
Episode length: 479.02 +/- 339.64
Eval num_timesteps=235000, episode_reward=-104.12 +/- 43.66
Episode length: 477.18 +/- 343.45
Eval num_timesteps=240000, episode_reward=-104.55 +/- 45.65
Episode length: 482.61 +/- 338.33
Eval num_timesteps=245000, episode_reward=-100.78 +/- 54.15
Episode length: 501.72 +/- 353.31
Eval num_timesteps=250000, episode_reward=-107.69 +/- 52.15
Episode length: 466.51 +/- 342.80
FINISHED IN 2864.847103948996 s


starting seed  2911 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-499.83 +/- 197.59
Episode length: 161.33 +/- 40.68
New best mean reward!
Eval num_timesteps=10000, episode_reward=-600.87 +/- 97.86
Episode length: 299.40 +/- 51.75
Eval num_timesteps=15000, episode_reward=-156.35 +/- 26.53
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-142.20 +/- 23.01
Episode length: 402.26 +/- 137.99
New best mean reward!
Eval num_timesteps=25000, episode_reward=-168.26 +/- 21.75
Episode length: 432.35 +/- 174.62
Eval num_timesteps=30000, episode_reward=-149.30 +/- 26.60
Episode length: 404.03 +/- 152.09
Eval num_timesteps=35000, episode_reward=-165.66 +/- 39.76
Episode length: 494.90 +/- 196.32
Eval num_timesteps=40000, episode_reward=-120.77 +/- 61.48
Episode length: 805.29 +/- 234.12
New best mean reward!
Eval num_timesteps=45000, episode_reward=-53.83 +/- 49.05
Episode length: 968.56 +/- 92.99
New best mean reward!
Eval num_timesteps=50000, episode_reward=-87.25 +/- 57.47
Episode length: 814.28 +/- 223.03
Eval num_timesteps=55000, episode_reward=-88.66 +/- 52.72
Episode length: 791.55 +/- 281.50
Eval num_timesteps=60000, episode_reward=-149.83 +/- 20.09
Episode length: 345.71 +/- 149.64
Eval num_timesteps=65000, episode_reward=-100.54 +/- 56.12
Episode length: 652.77 +/- 313.71
Eval num_timesteps=70000, episode_reward=-146.22 +/- 73.40
Episode length: 792.50 +/- 290.17
Eval num_timesteps=75000, episode_reward=-86.32 +/- 88.81
Episode length: 595.01 +/- 276.78
Eval num_timesteps=80000, episode_reward=-137.50 +/- 52.44
Episode length: 534.76 +/- 312.81
Eval num_timesteps=85000, episode_reward=-81.91 +/- 76.70
Episode length: 492.60 +/- 276.69
Eval num_timesteps=90000, episode_reward=-136.36 +/- 58.46
Episode length: 540.45 +/- 314.98
Eval num_timesteps=95000, episode_reward=-102.43 +/- 62.78
Episode length: 419.20 +/- 273.89
Eval num_timesteps=100000, episode_reward=-129.17 +/- 34.63
Episode length: 344.42 +/- 207.89
Eval num_timesteps=105000, episode_reward=-123.59 +/- 48.20
Episode length: 445.24 +/- 272.02
Eval num_timesteps=110000, episode_reward=-135.95 +/- 35.44
Episode length: 379.79 +/- 259.45
Eval num_timesteps=115000, episode_reward=-114.43 +/- 54.52
Episode length: 470.74 +/- 311.15
Eval num_timesteps=120000, episode_reward=-146.69 +/- 37.08
Episode length: 438.39 +/- 297.21
Eval num_timesteps=125000, episode_reward=-148.99 +/- 40.20
Episode length: 542.76 +/- 337.19
Eval num_timesteps=130000, episode_reward=-172.59 +/- 37.52
Episode length: 635.79 +/- 356.20
Eval num_timesteps=135000, episode_reward=-127.70 +/- 32.73
Episode length: 651.40 +/- 370.09
Eval num_timesteps=140000, episode_reward=-145.37 +/- 45.07
Episode length: 632.39 +/- 336.54
Eval num_timesteps=145000, episode_reward=-140.93 +/- 33.27
Episode length: 481.95 +/- 315.62
Eval num_timesteps=150000, episode_reward=-131.86 +/- 48.01
Episode length: 556.08 +/- 343.46
Eval num_timesteps=155000, episode_reward=-138.08 +/- 36.12
Episode length: 456.20 +/- 321.02
Eval num_timesteps=160000, episode_reward=-125.67 +/- 36.05
Episode length: 499.75 +/- 342.88
Eval num_timesteps=165000, episode_reward=-161.64 +/- 36.75
Episode length: 376.64 +/- 269.38
Eval num_timesteps=170000, episode_reward=-149.69 +/- 34.31
Episode length: 422.30 +/- 294.80
Eval num_timesteps=175000, episode_reward=-156.90 +/- 41.77
Episode length: 397.77 +/- 286.36
Eval num_timesteps=180000, episode_reward=-144.34 +/- 36.61
Episode length: 409.68 +/- 300.96
Eval num_timesteps=185000, episode_reward=-162.61 +/- 36.04
Episode length: 371.31 +/- 243.50
Eval num_timesteps=190000, episode_reward=-158.15 +/- 37.07
Episode length: 426.79 +/- 300.17
Eval num_timesteps=195000, episode_reward=-157.35 +/- 36.08
Episode length: 408.59 +/- 283.18
Eval num_timesteps=200000, episode_reward=-144.04 +/- 31.64
Episode length: 399.21 +/- 272.76
Eval num_timesteps=205000, episode_reward=-143.31 +/- 31.28
Episode length: 411.09 +/- 303.63
Eval num_timesteps=210000, episode_reward=-141.44 +/- 35.40
Episode length: 415.01 +/- 313.90
Eval num_timesteps=215000, episode_reward=-139.52 +/- 34.65
Episode length: 427.29 +/- 310.10
Eval num_timesteps=220000, episode_reward=-136.83 +/- 33.31
Episode length: 378.62 +/- 281.25
Eval num_timesteps=225000, episode_reward=-135.42 +/- 36.68
Episode length: 412.58 +/- 323.59
Eval num_timesteps=230000, episode_reward=-139.39 +/- 33.05
Episode length: 395.80 +/- 297.02
Eval num_timesteps=235000, episode_reward=-138.43 +/- 32.21
Episode length: 406.40 +/- 306.89
Eval num_timesteps=240000, episode_reward=-141.85 +/- 33.03
Episode length: 445.51 +/- 323.54
Eval num_timesteps=245000, episode_reward=-147.45 +/- 39.38
Episode length: 436.59 +/- 329.62
Eval num_timesteps=250000, episode_reward=-144.46 +/- 33.91
Episode length: 475.21 +/- 342.92
FINISHED IN 2521.2156679310137 s


starting seed  2912 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-579.98 +/- 178.64
Episode length: 67.41 +/- 14.15
New best mean reward!
Eval num_timesteps=10000, episode_reward=-582.95 +/- 156.56
Episode length: 66.80 +/- 12.03
Eval num_timesteps=15000, episode_reward=-763.42 +/- 184.85
Episode length: 302.49 +/- 250.84
Eval num_timesteps=20000, episode_reward=-236.14 +/- 43.25
Episode length: 996.39 +/- 24.71
New best mean reward!
Eval num_timesteps=25000, episode_reward=-53.73 +/- 44.04
Episode length: 987.71 +/- 49.05
New best mean reward!
Eval num_timesteps=30000, episode_reward=-121.94 +/- 25.05
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=-63.72 +/- 26.17
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-90.51 +/- 22.28
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=45000, episode_reward=-122.80 +/- 25.24
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=50000, episode_reward=-134.07 +/- 23.29
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=55000, episode_reward=-99.43 +/- 17.98
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=60000, episode_reward=-91.20 +/- 27.12
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=65000, episode_reward=-64.44 +/- 31.98
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=70000, episode_reward=-64.24 +/- 36.85
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=75000, episode_reward=-55.94 +/- 54.27
Episode length: 979.10 +/- 71.18
Eval num_timesteps=80000, episode_reward=-94.18 +/- 80.69
Episode length: 692.15 +/- 234.66
Eval num_timesteps=85000, episode_reward=-97.27 +/- 59.09
Episode length: 912.63 +/- 146.02
Eval num_timesteps=90000, episode_reward=-37.02 +/- 114.29
Episode length: 828.14 +/- 172.99
New best mean reward!
Eval num_timesteps=95000, episode_reward=25.08 +/- 118.22
Episode length: 587.62 +/- 185.39
New best mean reward!
Eval num_timesteps=100000, episode_reward=-42.65 +/- 94.95
Episode length: 752.92 +/- 242.08
Eval num_timesteps=105000, episode_reward=-73.79 +/- 83.49
Episode length: 409.70 +/- 200.45
Eval num_timesteps=110000, episode_reward=15.41 +/- 120.23
Episode length: 294.22 +/- 120.41
Eval num_timesteps=115000, episode_reward=-52.50 +/- 97.26
Episode length: 565.08 +/- 270.89
Eval num_timesteps=120000, episode_reward=-66.09 +/- 71.77
Episode length: 700.20 +/- 310.52
Eval num_timesteps=125000, episode_reward=-56.25 +/- 91.06
Episode length: 512.30 +/- 264.38
Eval num_timesteps=130000, episode_reward=-29.13 +/- 103.12
Episode length: 476.08 +/- 293.60
Eval num_timesteps=135000, episode_reward=-71.21 +/- 82.97
Episode length: 511.82 +/- 278.64
Eval num_timesteps=140000, episode_reward=-46.30 +/- 101.54
Episode length: 485.61 +/- 268.45
Eval num_timesteps=145000, episode_reward=-58.64 +/- 76.39
Episode length: 695.79 +/- 297.53
Eval num_timesteps=150000, episode_reward=-87.68 +/- 68.99
Episode length: 645.33 +/- 294.08
Eval num_timesteps=155000, episode_reward=-110.70 +/- 38.28
Episode length: 734.33 +/- 318.83
Eval num_timesteps=160000, episode_reward=-98.66 +/- 73.53
Episode length: 564.07 +/- 253.65
Eval num_timesteps=165000, episode_reward=-77.58 +/- 87.22
Episode length: 579.75 +/- 264.78
Eval num_timesteps=170000, episode_reward=-50.65 +/- 100.41
Episode length: 598.69 +/- 276.79
Eval num_timesteps=175000, episode_reward=2.25 +/- 133.33
Episode length: 538.32 +/- 236.68
Eval num_timesteps=180000, episode_reward=-46.87 +/- 108.07
Episode length: 636.52 +/- 276.91
Eval num_timesteps=185000, episode_reward=-65.95 +/- 60.47
Episode length: 835.87 +/- 267.79
Eval num_timesteps=190000, episode_reward=-86.57 +/- 52.62
Episode length: 682.48 +/- 320.81
Eval num_timesteps=195000, episode_reward=-87.87 +/- 58.34
Episode length: 716.86 +/- 318.02
Eval num_timesteps=200000, episode_reward=-83.18 +/- 43.79
Episode length: 754.71 +/- 328.87
Eval num_timesteps=205000, episode_reward=-90.84 +/- 34.70
Episode length: 652.57 +/- 361.85
Eval num_timesteps=210000, episode_reward=-90.03 +/- 78.27
Episode length: 642.46 +/- 320.12
Eval num_timesteps=215000, episode_reward=-49.22 +/- 109.60
Episode length: 600.69 +/- 272.06
Eval num_timesteps=220000, episode_reward=-46.78 +/- 92.06
Episode length: 757.32 +/- 297.39
Eval num_timesteps=225000, episode_reward=-85.15 +/- 60.18
Episode length: 737.68 +/- 320.68
Eval num_timesteps=230000, episode_reward=-69.81 +/- 64.07
Episode length: 772.25 +/- 317.19
Eval num_timesteps=235000, episode_reward=-72.30 +/- 77.91
Episode length: 701.67 +/- 339.29
Eval num_timesteps=240000, episode_reward=-70.28 +/- 87.29
Episode length: 691.31 +/- 326.68
Eval num_timesteps=245000, episode_reward=-82.07 +/- 63.22
Episode length: 691.29 +/- 326.36
Eval num_timesteps=250000, episode_reward=-68.03 +/- 89.22
Episode length: 668.50 +/- 323.44
FINISHED IN 3318.496598991973 s


starting seed  2913 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-665.98 +/- 88.71
Episode length: 103.80 +/- 21.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-46.54 +/- 67.13
Episode length: 759.32 +/- 365.01
New best mean reward!
Eval num_timesteps=15000, episode_reward=-135.44 +/- 69.86
Episode length: 959.43 +/- 177.32
Eval num_timesteps=20000, episode_reward=-74.19 +/- 83.03
Episode length: 381.46 +/- 152.83
Eval num_timesteps=25000, episode_reward=-101.00 +/- 66.91
Episode length: 695.47 +/- 243.85
Eval num_timesteps=30000, episode_reward=18.92 +/- 97.58
Episode length: 866.52 +/- 186.53
New best mean reward!
Eval num_timesteps=35000, episode_reward=-122.47 +/- 36.96
Episode length: 555.00 +/- 213.56
Eval num_timesteps=40000, episode_reward=-64.17 +/- 46.86
Episode length: 975.17 +/- 84.88
Eval num_timesteps=45000, episode_reward=-110.20 +/- 63.02
Episode length: 722.98 +/- 239.33
Eval num_timesteps=50000, episode_reward=-73.34 +/- 25.48
Episode length: 982.85 +/- 94.43
Eval num_timesteps=55000, episode_reward=-132.84 +/- 33.88
Episode length: 453.46 +/- 256.08
Eval num_timesteps=60000, episode_reward=-134.35 +/- 44.00
Episode length: 485.34 +/- 278.03
Eval num_timesteps=65000, episode_reward=-116.86 +/- 43.48
Episode length: 581.22 +/- 333.14
Eval num_timesteps=70000, episode_reward=-82.20 +/- 88.04
Episode length: 467.33 +/- 275.10
Eval num_timesteps=75000, episode_reward=-110.83 +/- 53.32
Episode length: 623.93 +/- 346.21
Eval num_timesteps=80000, episode_reward=-124.70 +/- 42.49
Episode length: 465.96 +/- 275.42
Eval num_timesteps=85000, episode_reward=-158.74 +/- 47.34
Episode length: 353.22 +/- 249.01
Eval num_timesteps=90000, episode_reward=-129.22 +/- 40.78
Episode length: 573.47 +/- 314.29
Eval num_timesteps=95000, episode_reward=-119.24 +/- 37.22
Episode length: 420.41 +/- 283.18
Eval num_timesteps=100000, episode_reward=-134.79 +/- 35.47
Episode length: 410.99 +/- 279.36
Eval num_timesteps=105000, episode_reward=-97.67 +/- 47.41
Episode length: 369.53 +/- 268.23
Eval num_timesteps=110000, episode_reward=-125.91 +/- 35.21
Episode length: 367.01 +/- 257.33
Eval num_timesteps=115000, episode_reward=-131.87 +/- 34.43
Episode length: 428.88 +/- 304.60
Eval num_timesteps=120000, episode_reward=-158.85 +/- 46.51
Episode length: 459.58 +/- 318.75
Eval num_timesteps=125000, episode_reward=-117.52 +/- 45.41
Episode length: 470.90 +/- 349.81
Eval num_timesteps=130000, episode_reward=-118.34 +/- 22.86
Episode length: 621.13 +/- 386.07
Eval num_timesteps=135000, episode_reward=-103.79 +/- 33.13
Episode length: 572.23 +/- 378.72
Eval num_timesteps=140000, episode_reward=-124.63 +/- 50.69
Episode length: 450.28 +/- 318.33
Eval num_timesteps=145000, episode_reward=-117.40 +/- 36.25
Episode length: 485.55 +/- 337.39
Eval num_timesteps=150000, episode_reward=-143.29 +/- 43.84
Episode length: 423.38 +/- 299.59
Eval num_timesteps=155000, episode_reward=-134.58 +/- 42.11
Episode length: 447.92 +/- 333.40
Eval num_timesteps=160000, episode_reward=-129.26 +/- 35.68
Episode length: 402.00 +/- 305.44
Eval num_timesteps=165000, episode_reward=-137.03 +/- 44.97
Episode length: 376.09 +/- 275.15
Eval num_timesteps=170000, episode_reward=-131.01 +/- 37.97
Episode length: 387.12 +/- 284.46
Eval num_timesteps=175000, episode_reward=-137.42 +/- 34.82
Episode length: 379.64 +/- 278.51
Eval num_timesteps=180000, episode_reward=-139.12 +/- 36.29
Episode length: 453.11 +/- 326.06
Eval num_timesteps=185000, episode_reward=-150.06 +/- 51.26
Episode length: 408.95 +/- 297.27
Eval num_timesteps=190000, episode_reward=-116.17 +/- 37.09
Episode length: 390.89 +/- 309.38
Eval num_timesteps=195000, episode_reward=-130.79 +/- 33.95
Episode length: 388.73 +/- 295.34
Eval num_timesteps=200000, episode_reward=-128.75 +/- 32.32
Episode length: 398.45 +/- 309.60
Eval num_timesteps=205000, episode_reward=-129.82 +/- 37.38
Episode length: 451.71 +/- 317.65
Eval num_timesteps=210000, episode_reward=-126.54 +/- 35.92
Episode length: 437.65 +/- 305.03
Eval num_timesteps=215000, episode_reward=-128.53 +/- 39.85
Episode length: 393.44 +/- 299.70
Eval num_timesteps=220000, episode_reward=-122.34 +/- 36.06
Episode length: 437.52 +/- 326.14
Eval num_timesteps=225000, episode_reward=-127.39 +/- 38.97
Episode length: 460.59 +/- 342.12
Eval num_timesteps=230000, episode_reward=-122.63 +/- 44.84
Episode length: 483.64 +/- 337.03
Eval num_timesteps=235000, episode_reward=-125.00 +/- 47.32
Episode length: 423.42 +/- 302.81
Eval num_timesteps=240000, episode_reward=-113.45 +/- 41.47
Episode length: 430.04 +/- 319.92
Eval num_timesteps=245000, episode_reward=-111.34 +/- 43.07
Episode length: 361.61 +/- 282.44
Eval num_timesteps=250000, episode_reward=-126.29 +/- 49.25
Episode length: 421.65 +/- 309.34
FINISHED IN 2737.9964453650173 s


starting seed  2914 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-64.92 +/- 20.84
Episode length: 991.65 +/- 83.08
New best mean reward!
Eval num_timesteps=10000, episode_reward=-51.70 +/- 66.54
Episode length: 963.04 +/- 75.30
New best mean reward!
Eval num_timesteps=15000, episode_reward=-128.57 +/- 29.06
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=-10.94 +/- 21.44
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=100.71 +/- 93.12
Episode length: 722.43 +/- 271.48
New best mean reward!
Eval num_timesteps=30000, episode_reward=62.17 +/- 95.34
Episode length: 844.44 +/- 161.80
Eval num_timesteps=35000, episode_reward=124.69 +/- 93.74
Episode length: 698.73 +/- 165.71
New best mean reward!
Eval num_timesteps=40000, episode_reward=-98.69 +/- 84.47
Episode length: 618.09 +/- 249.32
Eval num_timesteps=45000, episode_reward=75.25 +/- 114.29
Episode length: 673.25 +/- 207.08
Eval num_timesteps=50000, episode_reward=-42.95 +/- 25.82
Episode length: 992.46 +/- 75.02
Eval num_timesteps=55000, episode_reward=-107.97 +/- 51.62
Episode length: 624.56 +/- 346.38
Eval num_timesteps=60000, episode_reward=-79.10 +/- 51.60
Episode length: 726.84 +/- 332.36
Eval num_timesteps=65000, episode_reward=-52.19 +/- 34.93
Episode length: 850.07 +/- 295.46
Eval num_timesteps=70000, episode_reward=-120.70 +/- 47.67
Episode length: 513.85 +/- 313.27
Eval num_timesteps=75000, episode_reward=-130.79 +/- 52.70
Episode length: 541.65 +/- 328.73
Eval num_timesteps=80000, episode_reward=-73.90 +/- 55.81
Episode length: 521.97 +/- 350.59
Eval num_timesteps=85000, episode_reward=-111.41 +/- 38.27
Episode length: 566.06 +/- 347.51
Eval num_timesteps=90000, episode_reward=-120.84 +/- 40.02
Episode length: 489.90 +/- 334.91
Eval num_timesteps=95000, episode_reward=-110.11 +/- 43.63
Episode length: 467.44 +/- 347.95
Eval num_timesteps=100000, episode_reward=-124.22 +/- 41.67
Episode length: 445.32 +/- 315.25
Eval num_timesteps=105000, episode_reward=-129.49 +/- 35.23
Episode length: 298.88 +/- 222.75
Eval num_timesteps=110000, episode_reward=-101.11 +/- 50.91
Episode length: 542.95 +/- 348.05
Eval num_timesteps=115000, episode_reward=-109.24 +/- 32.73
Episode length: 539.30 +/- 365.69
Eval num_timesteps=120000, episode_reward=-147.29 +/- 41.67
Episode length: 430.02 +/- 309.05
Eval num_timesteps=125000, episode_reward=-154.29 +/- 36.44
Episode length: 369.93 +/- 272.94
Eval num_timesteps=130000, episode_reward=-152.86 +/- 40.89
Episode length: 424.13 +/- 320.77
Eval num_timesteps=135000, episode_reward=-156.32 +/- 44.27
Episode length: 460.41 +/- 320.01
Eval num_timesteps=140000, episode_reward=-149.24 +/- 44.10
Episode length: 454.13 +/- 344.30
Eval num_timesteps=145000, episode_reward=-135.03 +/- 33.41
Episode length: 481.34 +/- 330.04
Eval num_timesteps=150000, episode_reward=-131.33 +/- 50.66
Episode length: 488.59 +/- 331.18
Eval num_timesteps=155000, episode_reward=-164.82 +/- 43.06
Episode length: 486.43 +/- 346.42
Eval num_timesteps=160000, episode_reward=-177.77 +/- 58.19
Episode length: 396.58 +/- 284.05
Eval num_timesteps=165000, episode_reward=-173.99 +/- 59.39
Episode length: 464.18 +/- 336.44
Eval num_timesteps=170000, episode_reward=-116.59 +/- 33.86
Episode length: 474.43 +/- 344.69
Eval num_timesteps=175000, episode_reward=-150.83 +/- 45.50
Episode length: 513.14 +/- 334.49
Eval num_timesteps=180000, episode_reward=-145.57 +/- 34.86
Episode length: 430.67 +/- 314.30
Eval num_timesteps=185000, episode_reward=-119.96 +/- 39.71
Episode length: 435.66 +/- 317.42
Eval num_timesteps=190000, episode_reward=-118.06 +/- 32.60
Episode length: 469.34 +/- 342.54
Eval num_timesteps=195000, episode_reward=-133.15 +/- 31.95
Episode length: 418.41 +/- 320.23
Eval num_timesteps=200000, episode_reward=-132.21 +/- 32.93
Episode length: 392.82 +/- 307.37
Eval num_timesteps=205000, episode_reward=-129.35 +/- 38.68
Episode length: 385.22 +/- 287.89
Eval num_timesteps=210000, episode_reward=-122.91 +/- 37.03
Episode length: 429.30 +/- 317.57
Eval num_timesteps=215000, episode_reward=-122.82 +/- 26.58
Episode length: 377.27 +/- 289.03
Eval num_timesteps=220000, episode_reward=-125.73 +/- 41.11
Episode length: 480.26 +/- 332.98
Eval num_timesteps=225000, episode_reward=-121.88 +/- 37.13
Episode length: 461.33 +/- 316.78
Eval num_timesteps=230000, episode_reward=-116.78 +/- 36.16
Episode length: 511.56 +/- 351.46
Eval num_timesteps=235000, episode_reward=-128.12 +/- 38.96
Episode length: 460.42 +/- 329.25
Eval num_timesteps=240000, episode_reward=-126.30 +/- 34.04
Episode length: 433.25 +/- 305.03
Eval num_timesteps=245000, episode_reward=-121.17 +/- 32.58
Episode length: 459.28 +/- 346.00
Eval num_timesteps=250000, episode_reward=-128.43 +/- 37.49
Episode length: 433.15 +/- 322.49
FINISHED IN 2681.802134039055 s


starting seed  2915 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-807.67 +/- 380.10
Episode length: 119.71 +/- 48.04
New best mean reward!
Eval num_timesteps=10000, episode_reward=-685.27 +/- 144.97
Episode length: 94.28 +/- 19.08
New best mean reward!
Eval num_timesteps=15000, episode_reward=-579.13 +/- 176.32
Episode length: 68.12 +/- 17.35
New best mean reward!
Eval num_timesteps=20000, episode_reward=-145.96 +/- 56.41
Episode length: 910.26 +/- 269.55
New best mean reward!
Eval num_timesteps=25000, episode_reward=-814.25 +/- 79.21
Episode length: 650.81 +/- 61.67
Eval num_timesteps=30000, episode_reward=-182.60 +/- 39.62
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=35000, episode_reward=89.53 +/- 81.86
Episode length: 825.69 +/- 211.79
New best mean reward!
Eval num_timesteps=40000, episode_reward=120.71 +/- 90.77
Episode length: 763.02 +/- 122.86
New best mean reward!
Eval num_timesteps=45000, episode_reward=35.28 +/- 110.61
Episode length: 300.33 +/- 144.92
Eval num_timesteps=50000, episode_reward=48.11 +/- 128.29
Episode length: 698.41 +/- 129.10
Eval num_timesteps=55000, episode_reward=-11.36 +/- 150.35
Episode length: 633.70 +/- 150.91
Eval num_timesteps=60000, episode_reward=22.66 +/- 127.59
Episode length: 558.07 +/- 147.83
Eval num_timesteps=65000, episode_reward=17.37 +/- 136.36
Episode length: 425.94 +/- 197.02
Eval num_timesteps=70000, episode_reward=-50.26 +/- 117.59
Episode length: 621.02 +/- 213.47
Eval num_timesteps=75000, episode_reward=-103.95 +/- 60.06
Episode length: 708.63 +/- 280.04
Eval num_timesteps=80000, episode_reward=-89.55 +/- 79.31
Episode length: 544.47 +/- 301.38
Eval num_timesteps=85000, episode_reward=-48.56 +/- 87.92
Episode length: 632.20 +/- 316.60
Eval num_timesteps=90000, episode_reward=-91.64 +/- 90.33
Episode length: 483.09 +/- 238.05
Eval num_timesteps=95000, episode_reward=-104.97 +/- 46.72
Episode length: 709.43 +/- 320.37
Eval num_timesteps=100000, episode_reward=-52.52 +/- 116.90
Episode length: 595.18 +/- 280.97
Eval num_timesteps=105000, episode_reward=-101.29 +/- 59.66
Episode length: 624.89 +/- 299.48
Eval num_timesteps=110000, episode_reward=-108.18 +/- 49.28
Episode length: 611.22 +/- 331.65
Eval num_timesteps=115000, episode_reward=-122.12 +/- 47.67
Episode length: 546.46 +/- 286.46
Eval num_timesteps=120000, episode_reward=-114.23 +/- 55.45
Episode length: 483.88 +/- 322.28
Eval num_timesteps=125000, episode_reward=-79.30 +/- 74.78
Episode length: 522.64 +/- 323.92
Eval num_timesteps=130000, episode_reward=-119.86 +/- 32.62
Episode length: 386.48 +/- 297.87
Eval num_timesteps=135000, episode_reward=-101.24 +/- 52.31
Episode length: 454.32 +/- 311.64
Eval num_timesteps=140000, episode_reward=-126.48 +/- 30.83
Episode length: 451.88 +/- 322.14
Eval num_timesteps=145000, episode_reward=-143.57 +/- 35.22
Episode length: 418.20 +/- 287.76
Eval num_timesteps=150000, episode_reward=-130.53 +/- 37.16
Episode length: 330.36 +/- 265.13
Eval num_timesteps=155000, episode_reward=-164.92 +/- 51.89
Episode length: 343.24 +/- 247.27
Eval num_timesteps=160000, episode_reward=-128.46 +/- 33.73
Episode length: 506.96 +/- 345.98
Eval num_timesteps=165000, episode_reward=-116.66 +/- 47.20
Episode length: 428.64 +/- 296.73
Eval num_timesteps=170000, episode_reward=-142.65 +/- 42.68
Episode length: 377.53 +/- 254.58
Eval num_timesteps=175000, episode_reward=-121.44 +/- 34.64
Episode length: 381.11 +/- 276.67
Eval num_timesteps=180000, episode_reward=-148.00 +/- 50.27
Episode length: 400.88 +/- 291.92
Eval num_timesteps=185000, episode_reward=-146.82 +/- 37.41
Episode length: 341.30 +/- 228.89
Eval num_timesteps=190000, episode_reward=-133.59 +/- 39.74
Episode length: 372.77 +/- 280.96
Eval num_timesteps=195000, episode_reward=-131.33 +/- 33.98
Episode length: 435.37 +/- 315.76
Eval num_timesteps=200000, episode_reward=-126.55 +/- 35.76
Episode length: 470.34 +/- 332.22
Eval num_timesteps=205000, episode_reward=-140.93 +/- 40.16
Episode length: 506.64 +/- 353.48
Eval num_timesteps=210000, episode_reward=-145.80 +/- 36.96
Episode length: 454.04 +/- 311.18
Eval num_timesteps=215000, episode_reward=-129.38 +/- 34.21
Episode length: 378.97 +/- 297.09
Eval num_timesteps=220000, episode_reward=-136.01 +/- 36.62
Episode length: 415.57 +/- 313.33
Eval num_timesteps=225000, episode_reward=-143.70 +/- 38.77
Episode length: 415.77 +/- 303.38
Eval num_timesteps=230000, episode_reward=-143.34 +/- 39.84
Episode length: 404.01 +/- 295.59
Eval num_timesteps=235000, episode_reward=-133.41 +/- 34.41
Episode length: 408.32 +/- 297.06
Eval num_timesteps=240000, episode_reward=-138.96 +/- 37.70
Episode length: 438.66 +/- 316.16
Eval num_timesteps=245000, episode_reward=-136.31 +/- 34.41
Episode length: 420.59 +/- 286.61
Eval num_timesteps=250000, episode_reward=-133.09 +/- 32.58
Episode length: 438.87 +/- 324.84
FINISHED IN 2432.90982298 s


starting seed  2916 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-595.65 +/- 419.36
Episode length: 420.16 +/- 149.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-297.36 +/- 58.91
Episode length: 453.28 +/- 122.57
New best mean reward!
Eval num_timesteps=15000, episode_reward=-145.42 +/- 29.91
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-75.16 +/- 33.64
Episode length: 998.33 +/- 16.62
New best mean reward!
Eval num_timesteps=25000, episode_reward=-85.44 +/- 81.00
Episode length: 922.61 +/- 146.80
Eval num_timesteps=30000, episode_reward=-48.91 +/- 45.52
Episode length: 962.52 +/- 115.39
New best mean reward!
Eval num_timesteps=35000, episode_reward=-109.62 +/- 81.75
Episode length: 451.53 +/- 206.12
Eval num_timesteps=40000, episode_reward=49.47 +/- 121.66
Episode length: 540.30 +/- 198.88
New best mean reward!
Eval num_timesteps=45000, episode_reward=-91.20 +/- 31.00
Episode length: 913.66 +/- 211.86
Eval num_timesteps=50000, episode_reward=-98.14 +/- 66.82
Episode length: 765.74 +/- 330.86
Eval num_timesteps=55000, episode_reward=23.63 +/- 116.20
Episode length: 584.58 +/- 240.19
Eval num_timesteps=60000, episode_reward=1.31 +/- 90.97
Episode length: 753.68 +/- 281.53
Eval num_timesteps=65000, episode_reward=-133.54 +/- 46.57
Episode length: 559.42 +/- 330.81
Eval num_timesteps=70000, episode_reward=-6.77 +/- 103.05
Episode length: 602.06 +/- 316.41
Eval num_timesteps=75000, episode_reward=-90.10 +/- 99.28
Episode length: 384.96 +/- 213.54
Eval num_timesteps=80000, episode_reward=-86.30 +/- 86.56
Episode length: 558.24 +/- 325.40
Eval num_timesteps=85000, episode_reward=-121.06 +/- 62.53
Episode length: 497.62 +/- 307.74
Eval num_timesteps=90000, episode_reward=-119.80 +/- 46.92
Episode length: 603.70 +/- 340.52
Eval num_timesteps=95000, episode_reward=-97.53 +/- 69.98
Episode length: 469.73 +/- 296.39
Eval num_timesteps=100000, episode_reward=-159.66 +/- 43.33
Episode length: 518.68 +/- 320.29
Eval num_timesteps=105000, episode_reward=-134.34 +/- 37.31
Episode length: 392.89 +/- 294.35
Eval num_timesteps=110000, episode_reward=-121.05 +/- 38.13
Episode length: 430.25 +/- 310.83
Eval num_timesteps=115000, episode_reward=-162.60 +/- 46.23
Episode length: 517.93 +/- 344.97
Eval num_timesteps=120000, episode_reward=-156.11 +/- 43.38
Episode length: 416.39 +/- 284.10
Eval num_timesteps=125000, episode_reward=-151.58 +/- 41.48
Episode length: 377.03 +/- 288.05
Eval num_timesteps=130000, episode_reward=-150.00 +/- 45.85
Episode length: 459.09 +/- 333.68
Eval num_timesteps=135000, episode_reward=-140.89 +/- 39.75
Episode length: 390.74 +/- 269.71
Eval num_timesteps=140000, episode_reward=-159.42 +/- 51.56
Episode length: 517.02 +/- 300.51
Eval num_timesteps=145000, episode_reward=-112.38 +/- 30.82
Episode length: 565.89 +/- 377.72
Eval num_timesteps=150000, episode_reward=-136.89 +/- 45.72
Episode length: 475.16 +/- 321.54
Eval num_timesteps=155000, episode_reward=-119.41 +/- 38.19
Episode length: 475.19 +/- 327.54
Eval num_timesteps=160000, episode_reward=-132.78 +/- 35.81
Episode length: 562.78 +/- 342.64
Eval num_timesteps=165000, episode_reward=-131.40 +/- 33.27
Episode length: 445.24 +/- 335.90
Eval num_timesteps=170000, episode_reward=-144.58 +/- 52.93
Episode length: 454.27 +/- 319.98
Eval num_timesteps=175000, episode_reward=-132.26 +/- 34.06
Episode length: 447.24 +/- 329.73
Eval num_timesteps=180000, episode_reward=-125.34 +/- 35.95
Episode length: 494.79 +/- 338.03
Eval num_timesteps=185000, episode_reward=-141.01 +/- 46.16
Episode length: 462.12 +/- 311.47
Eval num_timesteps=190000, episode_reward=-135.33 +/- 39.62
Episode length: 371.68 +/- 281.98
Eval num_timesteps=195000, episode_reward=-141.85 +/- 38.46
Episode length: 381.81 +/- 273.96
Eval num_timesteps=200000, episode_reward=-126.72 +/- 35.39
Episode length: 356.87 +/- 267.69
Eval num_timesteps=205000, episode_reward=-131.98 +/- 34.01
Episode length: 364.22 +/- 262.42
Eval num_timesteps=210000, episode_reward=-125.81 +/- 31.56
Episode length: 421.36 +/- 306.52
Eval num_timesteps=215000, episode_reward=-122.29 +/- 37.63
Episode length: 482.35 +/- 331.51
Eval num_timesteps=220000, episode_reward=-135.58 +/- 38.96
Episode length: 479.83 +/- 331.98
Eval num_timesteps=225000, episode_reward=-128.94 +/- 37.26
Episode length: 435.93 +/- 335.94
Eval num_timesteps=230000, episode_reward=-126.58 +/- 30.81
Episode length: 448.93 +/- 330.56
Eval num_timesteps=235000, episode_reward=-128.58 +/- 36.99
Episode length: 453.49 +/- 324.49
Eval num_timesteps=240000, episode_reward=-118.68 +/- 32.58
Episode length: 455.43 +/- 325.28
Eval num_timesteps=245000, episode_reward=-125.25 +/- 37.34
Episode length: 406.71 +/- 306.02
Eval num_timesteps=250000, episode_reward=-123.83 +/- 33.04
Episode length: 421.12 +/- 294.25
FINISHED IN 2805.282148369006 s


starting seed  2917 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-24.23 +/- 91.93
Episode length: 503.31 +/- 407.57
New best mean reward!
Eval num_timesteps=10000, episode_reward=-521.58 +/- 78.22
Episode length: 789.75 +/- 137.16
Eval num_timesteps=15000, episode_reward=-89.01 +/- 22.81
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=20000, episode_reward=105.98 +/- 74.46
Episode length: 806.84 +/- 201.06
New best mean reward!
Eval num_timesteps=25000, episode_reward=-74.12 +/- 27.46
Episode length: 999.57 +/- 4.28
Eval num_timesteps=30000, episode_reward=8.68 +/- 130.02
Episode length: 409.09 +/- 170.09
Eval num_timesteps=35000, episode_reward=-92.78 +/- 60.87
Episode length: 781.90 +/- 249.16
Eval num_timesteps=40000, episode_reward=-198.03 +/- 39.88
Episode length: 551.32 +/- 224.31
Eval num_timesteps=45000, episode_reward=-122.05 +/- 76.55
Episode length: 828.58 +/- 224.44
Eval num_timesteps=50000, episode_reward=-85.85 +/- 28.54
Episode length: 978.24 +/- 83.35
Eval num_timesteps=55000, episode_reward=-152.97 +/- 52.83
Episode length: 745.86 +/- 252.72
Eval num_timesteps=60000, episode_reward=-73.43 +/- 59.65
Episode length: 913.12 +/- 172.06
Eval num_timesteps=65000, episode_reward=-102.24 +/- 32.16
Episode length: 946.74 +/- 145.47
Eval num_timesteps=70000, episode_reward=-60.30 +/- 36.52
Episode length: 968.57 +/- 107.89
Eval num_timesteps=75000, episode_reward=-90.95 +/- 52.16
Episode length: 744.82 +/- 265.84
Eval num_timesteps=80000, episode_reward=6.53 +/- 114.92
Episode length: 692.23 +/- 242.61
Eval num_timesteps=85000, episode_reward=-90.36 +/- 58.76
Episode length: 658.52 +/- 316.84
Eval num_timesteps=90000, episode_reward=-33.48 +/- 99.12
Episode length: 541.72 +/- 309.98
Eval num_timesteps=95000, episode_reward=-97.68 +/- 65.42
Episode length: 560.41 +/- 312.74
Eval num_timesteps=100000, episode_reward=-108.25 +/- 34.34
Episode length: 466.54 +/- 324.57
Eval num_timesteps=105000, episode_reward=-82.39 +/- 54.34
Episode length: 562.17 +/- 356.57
Eval num_timesteps=110000, episode_reward=-142.17 +/- 34.29
Episode length: 479.12 +/- 276.86
Eval num_timesteps=115000, episode_reward=-124.90 +/- 35.77
Episode length: 452.58 +/- 347.03
Eval num_timesteps=120000, episode_reward=-126.76 +/- 39.85
Episode length: 442.64 +/- 310.65
Eval num_timesteps=125000, episode_reward=-119.61 +/- 39.52
Episode length: 489.46 +/- 334.47
Eval num_timesteps=130000, episode_reward=-148.85 +/- 55.37
Episode length: 485.38 +/- 308.46
Eval num_timesteps=135000, episode_reward=-123.40 +/- 68.21
Episode length: 499.36 +/- 325.33
Eval num_timesteps=140000, episode_reward=-105.59 +/- 64.92
Episode length: 488.72 +/- 317.38
Eval num_timesteps=145000, episode_reward=-108.96 +/- 33.01
Episode length: 546.63 +/- 363.13
Eval num_timesteps=150000, episode_reward=-127.22 +/- 39.44
Episode length: 485.79 +/- 331.47
Eval num_timesteps=155000, episode_reward=-84.83 +/- 40.01
Episode length: 596.60 +/- 363.67
Eval num_timesteps=160000, episode_reward=-128.26 +/- 40.35
Episode length: 449.97 +/- 311.00
Eval num_timesteps=165000, episode_reward=-113.56 +/- 42.22
Episode length: 528.61 +/- 332.81
Eval num_timesteps=170000, episode_reward=-118.72 +/- 29.49
Episode length: 452.25 +/- 323.30
Eval num_timesteps=175000, episode_reward=-125.89 +/- 38.71
Episode length: 462.16 +/- 321.37
Eval num_timesteps=180000, episode_reward=-99.69 +/- 48.41
Episode length: 494.72 +/- 336.08
Eval num_timesteps=185000, episode_reward=-106.72 +/- 53.64
Episode length: 345.74 +/- 239.81
Eval num_timesteps=190000, episode_reward=-125.87 +/- 33.18
Episode length: 396.26 +/- 278.74
Eval num_timesteps=195000, episode_reward=-125.47 +/- 34.51
Episode length: 402.52 +/- 299.43
Eval num_timesteps=200000, episode_reward=-133.53 +/- 40.53
Episode length: 347.40 +/- 261.32
Eval num_timesteps=205000, episode_reward=-127.06 +/- 32.89
Episode length: 334.78 +/- 241.41
Eval num_timesteps=210000, episode_reward=-132.64 +/- 35.67
Episode length: 398.27 +/- 287.39
Eval num_timesteps=215000, episode_reward=-139.21 +/- 45.99
Episode length: 438.68 +/- 316.10
Eval num_timesteps=220000, episode_reward=-133.15 +/- 43.10
Episode length: 378.54 +/- 278.44
Eval num_timesteps=225000, episode_reward=-130.56 +/- 36.93
Episode length: 446.23 +/- 312.72
Eval num_timesteps=230000, episode_reward=-136.56 +/- 42.46
Episode length: 402.46 +/- 289.09
Eval num_timesteps=235000, episode_reward=-129.03 +/- 38.14
Episode length: 437.61 +/- 328.53
Eval num_timesteps=240000, episode_reward=-136.38 +/- 41.47
Episode length: 383.34 +/- 277.19
Eval num_timesteps=245000, episode_reward=-133.61 +/- 39.84
Episode length: 365.78 +/- 278.37
Eval num_timesteps=250000, episode_reward=-136.71 +/- 38.48
Episode length: 369.53 +/- 278.78
FINISHED IN 2712.6872884460026 s


starting seed  2918 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-576.25 +/- 98.76
Episode length: 75.89 +/- 10.00
New best mean reward!
Eval num_timesteps=10000, episode_reward=-534.39 +/- 39.12
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=59.00 +/- 103.40
Episode length: 751.60 +/- 151.14
New best mean reward!
Eval num_timesteps=20000, episode_reward=-56.25 +/- 100.94
Episode length: 889.70 +/- 126.19
Eval num_timesteps=25000, episode_reward=-46.14 +/- 123.63
Episode length: 694.84 +/- 147.33
Eval num_timesteps=30000, episode_reward=-94.99 +/- 68.80
Episode length: 875.50 +/- 182.63
Eval num_timesteps=35000, episode_reward=55.81 +/- 101.95
Episode length: 722.12 +/- 191.76
Eval num_timesteps=40000, episode_reward=-80.78 +/- 30.27
Episode length: 998.92 +/- 10.75
Eval num_timesteps=45000, episode_reward=-102.36 +/- 40.24
Episode length: 952.76 +/- 133.85
Eval num_timesteps=50000, episode_reward=-69.10 +/- 106.62
Episode length: 615.92 +/- 249.58
Eval num_timesteps=55000, episode_reward=-124.88 +/- 48.06
Episode length: 725.81 +/- 287.00
Eval num_timesteps=60000, episode_reward=-3.79 +/- 124.01
Episode length: 413.19 +/- 172.85
Eval num_timesteps=65000, episode_reward=-68.37 +/- 91.25
Episode length: 433.03 +/- 231.54
Eval num_timesteps=70000, episode_reward=-108.41 +/- 53.77
Episode length: 437.56 +/- 296.64
Eval num_timesteps=75000, episode_reward=-134.02 +/- 41.59
Episode length: 557.91 +/- 326.78
Eval num_timesteps=80000, episode_reward=-99.54 +/- 46.70
Episode length: 723.24 +/- 349.12
Eval num_timesteps=85000, episode_reward=-112.50 +/- 53.08
Episode length: 400.15 +/- 292.48
Eval num_timesteps=90000, episode_reward=-105.57 +/- 38.43
Episode length: 449.49 +/- 338.01
Eval num_timesteps=95000, episode_reward=-160.00 +/- 40.54
Episode length: 351.15 +/- 231.79
Eval num_timesteps=100000, episode_reward=-73.26 +/- 61.50
Episode length: 642.39 +/- 363.46
Eval num_timesteps=105000, episode_reward=-87.68 +/- 23.81
Episode length: 814.68 +/- 331.38
Eval num_timesteps=110000, episode_reward=-75.39 +/- 27.22
Episode length: 726.48 +/- 376.25
Eval num_timesteps=115000, episode_reward=-108.61 +/- 58.10
Episode length: 521.91 +/- 341.83
Eval num_timesteps=120000, episode_reward=-146.27 +/- 46.18
Episode length: 429.19 +/- 299.77
Eval num_timesteps=125000, episode_reward=-138.82 +/- 48.35
Episode length: 496.32 +/- 333.37
Eval num_timesteps=130000, episode_reward=-129.52 +/- 28.72
Episode length: 390.32 +/- 291.98
Eval num_timesteps=135000, episode_reward=-114.28 +/- 57.33
Episode length: 468.31 +/- 324.27
Eval num_timesteps=140000, episode_reward=-134.11 +/- 35.54
Episode length: 366.14 +/- 291.13
Eval num_timesteps=145000, episode_reward=-145.02 +/- 45.35
Episode length: 419.76 +/- 287.33
Eval num_timesteps=150000, episode_reward=-138.03 +/- 32.92
Episode length: 450.31 +/- 320.07
Eval num_timesteps=155000, episode_reward=-156.18 +/- 40.49
Episode length: 359.37 +/- 277.65
Eval num_timesteps=160000, episode_reward=-132.95 +/- 39.83
Episode length: 427.80 +/- 338.90
Eval num_timesteps=165000, episode_reward=-120.31 +/- 35.98
Episode length: 570.86 +/- 382.72
Eval num_timesteps=170000, episode_reward=-157.99 +/- 37.79
Episode length: 410.07 +/- 295.87
Eval num_timesteps=175000, episode_reward=-150.19 +/- 39.27
Episode length: 398.86 +/- 266.84
Eval num_timesteps=180000, episode_reward=-140.82 +/- 28.75
Episode length: 330.51 +/- 249.47
Eval num_timesteps=185000, episode_reward=-140.03 +/- 26.80
Episode length: 329.84 +/- 238.81
Eval num_timesteps=190000, episode_reward=-114.66 +/- 46.72
Episode length: 318.50 +/- 257.62
Eval num_timesteps=195000, episode_reward=-137.52 +/- 35.29
Episode length: 310.19 +/- 251.33
Eval num_timesteps=200000, episode_reward=-145.61 +/- 43.72
Episode length: 347.88 +/- 265.23
Eval num_timesteps=205000, episode_reward=-132.38 +/- 49.41
Episode length: 401.69 +/- 292.91
Eval num_timesteps=210000, episode_reward=-119.67 +/- 33.52
Episode length: 408.25 +/- 317.91
Eval num_timesteps=215000, episode_reward=-134.14 +/- 36.03
Episode length: 416.76 +/- 294.62
Eval num_timesteps=220000, episode_reward=-134.55 +/- 42.79
Episode length: 336.04 +/- 249.99
Eval num_timesteps=225000, episode_reward=-133.59 +/- 41.40
Episode length: 452.84 +/- 325.41
Eval num_timesteps=230000, episode_reward=-130.08 +/- 37.21
Episode length: 358.36 +/- 258.67
Eval num_timesteps=235000, episode_reward=-137.50 +/- 40.56
Episode length: 366.72 +/- 286.96
Eval num_timesteps=240000, episode_reward=-133.46 +/- 54.93
Episode length: 427.52 +/- 306.23
Eval num_timesteps=245000, episode_reward=-133.15 +/- 39.23
Episode length: 381.85 +/- 289.97
Eval num_timesteps=250000, episode_reward=-131.91 +/- 46.56
Episode length: 418.42 +/- 320.16
FINISHED IN 2795.3747141769854 s


starting seed  2919 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-356.59 +/- 135.67
Episode length: 373.91 +/- 133.78
New best mean reward!
Eval num_timesteps=10000, episode_reward=-238.45 +/- 118.91
Episode length: 759.94 +/- 168.08
New best mean reward!
Eval num_timesteps=15000, episode_reward=-93.35 +/- 21.41
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-65.86 +/- 35.09
Episode length: 987.16 +/- 71.14
New best mean reward!
Eval num_timesteps=25000, episode_reward=-106.09 +/- 94.24
Episode length: 586.28 +/- 162.61
Eval num_timesteps=30000, episode_reward=-189.19 +/- 62.98
Episode length: 992.85 +/- 36.43
Eval num_timesteps=35000, episode_reward=-22.56 +/- 61.97
Episode length: 952.03 +/- 116.26
New best mean reward!
Eval num_timesteps=40000, episode_reward=68.86 +/- 109.52
Episode length: 677.26 +/- 212.43
New best mean reward!
Eval num_timesteps=45000, episode_reward=23.42 +/- 125.51
Episode length: 489.46 +/- 161.18
Eval num_timesteps=50000, episode_reward=29.58 +/- 115.79
Episode length: 458.12 +/- 193.96
Eval num_timesteps=55000, episode_reward=-13.29 +/- 109.37
Episode length: 548.04 +/- 211.64
Eval num_timesteps=60000, episode_reward=-73.28 +/- 56.87
Episode length: 905.77 +/- 177.88
Eval num_timesteps=65000, episode_reward=-102.89 +/- 36.77
Episode length: 985.59 +/- 80.47
Eval num_timesteps=70000, episode_reward=-113.24 +/- 37.84
Episode length: 910.87 +/- 186.72
Eval num_timesteps=75000, episode_reward=-153.89 +/- 45.50
Episode length: 682.68 +/- 344.65
Eval num_timesteps=80000, episode_reward=-145.18 +/- 50.50
Episode length: 645.91 +/- 342.95
Eval num_timesteps=85000, episode_reward=-110.36 +/- 35.46
Episode length: 431.67 +/- 299.60
Eval num_timesteps=90000, episode_reward=-131.48 +/- 36.59
Episode length: 581.86 +/- 384.39
Eval num_timesteps=95000, episode_reward=-102.71 +/- 37.03
Episode length: 546.02 +/- 380.86
Eval num_timesteps=100000, episode_reward=-126.00 +/- 42.03
Episode length: 468.56 +/- 354.14
Eval num_timesteps=105000, episode_reward=-135.26 +/- 33.68
Episode length: 466.75 +/- 351.12
Eval num_timesteps=110000, episode_reward=-126.47 +/- 33.50
Episode length: 452.18 +/- 341.39
Eval num_timesteps=115000, episode_reward=-132.04 +/- 33.72
Episode length: 492.80 +/- 362.36
Eval num_timesteps=120000, episode_reward=-67.23 +/- 69.15
Episode length: 658.70 +/- 371.79
Eval num_timesteps=125000, episode_reward=-112.50 +/- 40.01
Episode length: 537.36 +/- 335.07
Eval num_timesteps=130000, episode_reward=-100.20 +/- 24.74
Episode length: 652.70 +/- 370.41
Eval num_timesteps=135000, episode_reward=-73.04 +/- 45.72
Episode length: 668.33 +/- 382.08
Eval num_timesteps=140000, episode_reward=-98.81 +/- 60.15
Episode length: 401.69 +/- 295.13
Eval num_timesteps=145000, episode_reward=-123.67 +/- 43.16
Episode length: 456.73 +/- 311.51
Eval num_timesteps=150000, episode_reward=-88.99 +/- 39.95
Episode length: 492.63 +/- 363.26
Eval num_timesteps=155000, episode_reward=-83.93 +/- 29.32
Episode length: 617.74 +/- 401.56
Eval num_timesteps=160000, episode_reward=-127.60 +/- 35.75
Episode length: 528.60 +/- 372.03
Eval num_timesteps=165000, episode_reward=-82.16 +/- 39.17
Episode length: 490.31 +/- 361.23
Eval num_timesteps=170000, episode_reward=-87.23 +/- 27.01
Episode length: 556.37 +/- 389.23
Eval num_timesteps=175000, episode_reward=-88.56 +/- 26.81
Episode length: 672.23 +/- 389.98
Eval num_timesteps=180000, episode_reward=-101.93 +/- 32.67
Episode length: 488.31 +/- 367.54
Eval num_timesteps=185000, episode_reward=-103.66 +/- 25.65
Episode length: 547.49 +/- 365.41
Eval num_timesteps=190000, episode_reward=-115.53 +/- 37.73
Episode length: 407.53 +/- 315.67
Eval num_timesteps=195000, episode_reward=-99.93 +/- 42.60
Episode length: 558.42 +/- 370.18
Eval num_timesteps=200000, episode_reward=-80.45 +/- 64.44
Episode length: 507.89 +/- 351.41
Eval num_timesteps=205000, episode_reward=-91.19 +/- 42.17
Episode length: 579.28 +/- 385.38
Eval num_timesteps=210000, episode_reward=-81.39 +/- 37.89
Episode length: 576.53 +/- 393.56
Eval num_timesteps=215000, episode_reward=-88.07 +/- 32.05
Episode length: 568.69 +/- 383.97
Eval num_timesteps=220000, episode_reward=-93.90 +/- 31.48
Episode length: 543.24 +/- 367.71
Eval num_timesteps=225000, episode_reward=-74.50 +/- 28.75
Episode length: 618.44 +/- 386.39
Eval num_timesteps=230000, episode_reward=-85.64 +/- 30.72
Episode length: 586.90 +/- 380.54
Eval num_timesteps=235000, episode_reward=-79.23 +/- 35.40
Episode length: 547.74 +/- 386.08
Eval num_timesteps=240000, episode_reward=-71.73 +/- 36.81
Episode length: 603.60 +/- 380.02
Eval num_timesteps=245000, episode_reward=-73.71 +/- 37.82
Episode length: 609.04 +/- 380.74
Eval num_timesteps=250000, episode_reward=-73.69 +/- 36.49
Episode length: 528.92 +/- 379.80
FINISHED IN 3260.9991317859967 s


starting seed  2920 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-853.14 +/- 645.25
Episode length: 122.14 +/- 58.73
New best mean reward!
Eval num_timesteps=10000, episode_reward=-845.67 +/- 572.40
Episode length: 120.82 +/- 57.85
New best mean reward!
Eval num_timesteps=15000, episode_reward=-508.77 +/- 166.94
Episode length: 134.77 +/- 67.94
New best mean reward!
Eval num_timesteps=20000, episode_reward=-472.45 +/- 67.98
Episode length: 485.76 +/- 37.78
New best mean reward!
Eval num_timesteps=25000, episode_reward=-107.53 +/- 31.13
Episode length: 316.50 +/- 83.88
New best mean reward!
Eval num_timesteps=30000, episode_reward=-147.64 +/- 24.64
Episode length: 993.29 +/- 52.42
Eval num_timesteps=35000, episode_reward=-137.35 +/- 66.42
Episode length: 869.80 +/- 173.28
Eval num_timesteps=40000, episode_reward=-170.56 +/- 52.92
Episode length: 749.11 +/- 219.06
Eval num_timesteps=45000, episode_reward=-206.57 +/- 52.06
Episode length: 921.92 +/- 139.58
Eval num_timesteps=50000, episode_reward=-83.56 +/- 21.29
Episode length: 994.66 +/- 49.00
New best mean reward!
Eval num_timesteps=55000, episode_reward=-145.92 +/- 26.92
Episode length: 999.68 +/- 2.99
Eval num_timesteps=60000, episode_reward=-115.25 +/- 27.80
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=65000, episode_reward=-111.30 +/- 23.60
Episode length: 991.00 +/- 89.55
Eval num_timesteps=70000, episode_reward=-55.15 +/- 17.98
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=75000, episode_reward=-81.77 +/- 24.44
Episode length: 976.87 +/- 109.12
Eval num_timesteps=80000, episode_reward=-165.21 +/- 60.60
Episode length: 914.05 +/- 124.13
Eval num_timesteps=85000, episode_reward=-142.74 +/- 49.22
Episode length: 953.36 +/- 105.29
Eval num_timesteps=90000, episode_reward=-38.01 +/- 21.32
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=95000, episode_reward=-104.76 +/- 64.21
Episode length: 910.81 +/- 150.70
Eval num_timesteps=100000, episode_reward=19.99 +/- 62.31
Episode length: 969.38 +/- 74.21
New best mean reward!
Eval num_timesteps=105000, episode_reward=91.40 +/- 124.14
Episode length: 413.40 +/- 106.27
New best mean reward!
Eval num_timesteps=110000, episode_reward=-26.69 +/- 78.97
Episode length: 217.37 +/- 50.08
Eval num_timesteps=115000, episode_reward=66.46 +/- 135.08
Episode length: 243.23 +/- 75.59
Eval num_timesteps=120000, episode_reward=105.01 +/- 126.33
Episode length: 461.65 +/- 133.95
New best mean reward!
Eval num_timesteps=125000, episode_reward=92.02 +/- 125.69
Episode length: 415.34 +/- 112.37
Eval num_timesteps=130000, episode_reward=83.59 +/- 116.15
Episode length: 633.66 +/- 127.59
Eval num_timesteps=135000, episode_reward=-50.20 +/- 45.03
Episode length: 999.51 +/- 4.40
Eval num_timesteps=140000, episode_reward=-148.39 +/- 61.31
Episode length: 838.21 +/- 196.13
Eval num_timesteps=145000, episode_reward=-95.12 +/- 56.30
Episode length: 898.36 +/- 178.19
Eval num_timesteps=150000, episode_reward=-67.55 +/- 39.83
Episode length: 981.32 +/- 91.07
Eval num_timesteps=155000, episode_reward=-114.64 +/- 22.50
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=160000, episode_reward=-61.65 +/- 24.16
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=165000, episode_reward=-77.56 +/- 50.41
Episode length: 856.37 +/- 247.86
Eval num_timesteps=170000, episode_reward=-56.46 +/- 25.19
Episode length: 996.65 +/- 33.33
Eval num_timesteps=175000, episode_reward=-81.03 +/- 37.72
Episode length: 906.01 +/- 217.80
Eval num_timesteps=180000, episode_reward=-81.49 +/- 24.28
Episode length: 943.37 +/- 177.97
Eval num_timesteps=185000, episode_reward=-116.37 +/- 65.65
Episode length: 753.16 +/- 292.94
Eval num_timesteps=190000, episode_reward=-95.85 +/- 39.85
Episode length: 826.52 +/- 277.98
Eval num_timesteps=195000, episode_reward=-89.48 +/- 52.68
Episode length: 717.00 +/- 302.36
Eval num_timesteps=200000, episode_reward=-86.71 +/- 49.69
Episode length: 760.33 +/- 321.72
Eval num_timesteps=205000, episode_reward=-80.28 +/- 42.41
Episode length: 709.15 +/- 339.79
Eval num_timesteps=210000, episode_reward=-73.38 +/- 43.61
Episode length: 767.18 +/- 329.91
Eval num_timesteps=215000, episode_reward=-97.39 +/- 44.78
Episode length: 642.51 +/- 338.14
Eval num_timesteps=220000, episode_reward=-96.12 +/- 62.83
Episode length: 521.21 +/- 335.93
Eval num_timesteps=225000, episode_reward=-75.54 +/- 69.75
Episode length: 626.85 +/- 329.74
Eval num_timesteps=230000, episode_reward=-98.16 +/- 60.23
Episode length: 512.20 +/- 309.98
Eval num_timesteps=235000, episode_reward=-106.91 +/- 44.75
Episode length: 548.65 +/- 329.25
Eval num_timesteps=240000, episode_reward=-99.88 +/- 57.47
Episode length: 568.20 +/- 331.97
Eval num_timesteps=245000, episode_reward=-105.02 +/- 44.32
Episode length: 523.62 +/- 329.16
Eval num_timesteps=250000, episode_reward=-103.70 +/- 49.18
Episode length: 476.96 +/- 331.89
FINISHED IN 3394.6556365169818 s


starting seed  2921 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-125.33 +/- 23.77
Episode length: 214.29 +/- 38.76
New best mean reward!
Eval num_timesteps=10000, episode_reward=-136.41 +/- 22.59
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=15000, episode_reward=-20.96 +/- 35.12
Episode length: 998.44 +/- 10.65
New best mean reward!
Eval num_timesteps=20000, episode_reward=-48.44 +/- 38.72
Episode length: 989.70 +/- 51.92
Eval num_timesteps=25000, episode_reward=-30.75 +/- 104.92
Episode length: 808.03 +/- 183.82
Eval num_timesteps=30000, episode_reward=-49.19 +/- 66.22
Episode length: 924.24 +/- 140.09
Eval num_timesteps=35000, episode_reward=-71.87 +/- 104.09
Episode length: 688.32 +/- 230.17
Eval num_timesteps=40000, episode_reward=-84.16 +/- 96.96
Episode length: 713.79 +/- 233.36
Eval num_timesteps=45000, episode_reward=-55.51 +/- 39.88
Episode length: 946.41 +/- 146.45
Eval num_timesteps=50000, episode_reward=-127.80 +/- 40.54
Episode length: 428.22 +/- 229.94
Eval num_timesteps=55000, episode_reward=-113.08 +/- 54.87
Episode length: 660.24 +/- 294.76
Eval num_timesteps=60000, episode_reward=-122.71 +/- 42.61
Episode length: 544.95 +/- 317.66
Eval num_timesteps=65000, episode_reward=-163.35 +/- 34.46
Episode length: 468.57 +/- 271.99
Eval num_timesteps=70000, episode_reward=-90.65 +/- 41.05
Episode length: 524.31 +/- 354.80
Eval num_timesteps=75000, episode_reward=-111.41 +/- 50.65
Episode length: 476.84 +/- 338.07
Eval num_timesteps=80000, episode_reward=-114.62 +/- 34.95
Episode length: 667.37 +/- 364.91
Eval num_timesteps=85000, episode_reward=-126.03 +/- 37.97
Episode length: 516.15 +/- 357.91
Eval num_timesteps=90000, episode_reward=-95.09 +/- 36.15
Episode length: 567.42 +/- 371.45
Eval num_timesteps=95000, episode_reward=-135.33 +/- 29.29
Episode length: 384.53 +/- 291.88
Eval num_timesteps=100000, episode_reward=-142.36 +/- 32.10
Episode length: 374.94 +/- 295.97
Eval num_timesteps=105000, episode_reward=-154.81 +/- 47.53
Episode length: 457.35 +/- 333.74
Eval num_timesteps=110000, episode_reward=-153.85 +/- 35.58
Episode length: 394.65 +/- 316.77
Eval num_timesteps=115000, episode_reward=-137.71 +/- 29.62
Episode length: 431.81 +/- 321.94
Eval num_timesteps=120000, episode_reward=-128.35 +/- 25.75
Episode length: 619.90 +/- 399.02
Eval num_timesteps=125000, episode_reward=-151.06 +/- 51.29
Episode length: 446.76 +/- 299.78
Eval num_timesteps=130000, episode_reward=-129.51 +/- 38.49
Episode length: 475.04 +/- 328.07
Eval num_timesteps=135000, episode_reward=-128.98 +/- 38.08
Episode length: 527.03 +/- 362.73
Eval num_timesteps=140000, episode_reward=-150.74 +/- 40.31
Episode length: 470.62 +/- 333.79
Eval num_timesteps=145000, episode_reward=-149.40 +/- 37.31
Episode length: 388.02 +/- 296.54
Eval num_timesteps=150000, episode_reward=-147.77 +/- 36.59
Episode length: 395.55 +/- 301.97
Eval num_timesteps=155000, episode_reward=-143.84 +/- 39.75
Episode length: 421.25 +/- 309.67
Eval num_timesteps=160000, episode_reward=-118.25 +/- 32.67
Episode length: 483.82 +/- 353.10
Eval num_timesteps=165000, episode_reward=-135.37 +/- 32.26
Episode length: 701.12 +/- 364.25
Eval num_timesteps=170000, episode_reward=-140.42 +/- 44.83
Episode length: 519.11 +/- 331.14
Eval num_timesteps=175000, episode_reward=-137.81 +/- 35.94
Episode length: 433.63 +/- 312.86
Eval num_timesteps=180000, episode_reward=-122.55 +/- 32.47
Episode length: 374.34 +/- 278.71
Eval num_timesteps=185000, episode_reward=-124.93 +/- 32.64
Episode length: 364.70 +/- 288.93
Eval num_timesteps=190000, episode_reward=-143.36 +/- 34.22
Episode length: 357.61 +/- 274.45
Eval num_timesteps=195000, episode_reward=-122.68 +/- 34.46
Episode length: 419.76 +/- 315.59
Eval num_timesteps=200000, episode_reward=-132.28 +/- 30.25
Episode length: 409.64 +/- 321.19
Eval num_timesteps=205000, episode_reward=-157.10 +/- 40.65
Episode length: 411.22 +/- 310.19
Eval num_timesteps=210000, episode_reward=-146.39 +/- 42.68
Episode length: 474.04 +/- 340.29
Eval num_timesteps=215000, episode_reward=-145.55 +/- 36.98
Episode length: 446.39 +/- 319.61
Eval num_timesteps=220000, episode_reward=-146.83 +/- 34.82
Episode length: 474.07 +/- 349.59
Eval num_timesteps=225000, episode_reward=-153.91 +/- 37.39
Episode length: 448.36 +/- 347.96
Eval num_timesteps=230000, episode_reward=-156.96 +/- 35.28
Episode length: 425.86 +/- 321.92
Eval num_timesteps=235000, episode_reward=-157.65 +/- 43.76
Episode length: 460.64 +/- 327.92
Eval num_timesteps=240000, episode_reward=-151.80 +/- 38.47
Episode length: 432.87 +/- 314.51
Eval num_timesteps=245000, episode_reward=-153.35 +/- 38.24
Episode length: 426.19 +/- 323.70
Eval num_timesteps=250000, episode_reward=-147.18 +/- 33.13
Episode length: 460.73 +/- 334.79
FINISHED IN 2691.6506351819844 s


starting seed  2922 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-200.78 +/- 90.07
Episode length: 73.23 +/- 11.90
New best mean reward!
Eval num_timesteps=10000, episode_reward=-330.83 +/- 62.19
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=15000, episode_reward=16.36 +/- 99.70
Episode length: 809.81 +/- 137.27
New best mean reward!
Eval num_timesteps=20000, episode_reward=77.66 +/- 93.00
Episode length: 852.65 +/- 131.68
New best mean reward!
Eval num_timesteps=25000, episode_reward=130.21 +/- 126.43
Episode length: 456.27 +/- 139.90
New best mean reward!
Eval num_timesteps=30000, episode_reward=-23.84 +/- 69.77
Episode length: 947.10 +/- 146.97
Eval num_timesteps=35000, episode_reward=126.09 +/- 89.75
Episode length: 718.99 +/- 201.08
Eval num_timesteps=40000, episode_reward=-7.40 +/- 116.45
Episode length: 766.88 +/- 238.55
Eval num_timesteps=45000, episode_reward=-74.31 +/- 105.13
Episode length: 207.30 +/- 58.74
Eval num_timesteps=50000, episode_reward=41.05 +/- 103.85
Episode length: 817.48 +/- 152.50
Eval num_timesteps=55000, episode_reward=-8.67 +/- 108.85
Episode length: 604.72 +/- 236.42
Eval num_timesteps=60000, episode_reward=-83.94 +/- 39.74
Episode length: 783.23 +/- 313.93
Eval num_timesteps=65000, episode_reward=-117.97 +/- 42.71
Episode length: 550.36 +/- 377.21
Eval num_timesteps=70000, episode_reward=-103.71 +/- 53.20
Episode length: 674.12 +/- 342.19
Eval num_timesteps=75000, episode_reward=-182.73 +/- 56.56
Episode length: 593.94 +/- 316.94
Eval num_timesteps=80000, episode_reward=-102.44 +/- 44.72
Episode length: 822.74 +/- 291.29
Eval num_timesteps=85000, episode_reward=-121.59 +/- 36.51
Episode length: 441.16 +/- 316.14
Eval num_timesteps=90000, episode_reward=-134.92 +/- 38.58
Episode length: 516.45 +/- 355.72
Eval num_timesteps=95000, episode_reward=-108.13 +/- 29.06
Episode length: 526.28 +/- 371.61
Eval num_timesteps=100000, episode_reward=-135.03 +/- 46.35
Episode length: 668.65 +/- 356.92
Eval num_timesteps=105000, episode_reward=-113.35 +/- 37.11
Episode length: 513.28 +/- 363.36
Eval num_timesteps=110000, episode_reward=-185.44 +/- 64.43
Episode length: 391.38 +/- 284.22
Eval num_timesteps=115000, episode_reward=-176.59 +/- 57.37
Episode length: 434.39 +/- 304.02
Eval num_timesteps=120000, episode_reward=-147.14 +/- 63.85
Episode length: 426.95 +/- 310.98
Eval num_timesteps=125000, episode_reward=-143.59 +/- 46.60
Episode length: 379.08 +/- 269.47
Eval num_timesteps=130000, episode_reward=-133.08 +/- 76.79
Episode length: 433.20 +/- 297.39
Eval num_timesteps=135000, episode_reward=-108.26 +/- 62.72
Episode length: 308.33 +/- 201.80
Eval num_timesteps=140000, episode_reward=-114.63 +/- 71.11
Episode length: 404.43 +/- 285.94
Eval num_timesteps=145000, episode_reward=-128.08 +/- 52.23
Episode length: 337.71 +/- 232.75
Eval num_timesteps=150000, episode_reward=-116.88 +/- 70.72
Episode length: 433.17 +/- 303.15
Eval num_timesteps=155000, episode_reward=-103.14 +/- 64.82
Episode length: 484.26 +/- 322.59
Eval num_timesteps=160000, episode_reward=-109.53 +/- 70.12
Episode length: 447.39 +/- 294.33
Eval num_timesteps=165000, episode_reward=-98.33 +/- 52.06
Episode length: 537.80 +/- 353.32
Eval num_timesteps=170000, episode_reward=-119.21 +/- 52.62
Episode length: 531.51 +/- 367.28
Eval num_timesteps=175000, episode_reward=-105.87 +/- 41.37
Episode length: 551.25 +/- 370.74
Eval num_timesteps=180000, episode_reward=-125.49 +/- 41.40
Episode length: 434.39 +/- 316.66
Eval num_timesteps=185000, episode_reward=-117.65 +/- 39.66
Episode length: 398.93 +/- 316.36
Eval num_timesteps=190000, episode_reward=-115.91 +/- 35.85
Episode length: 451.57 +/- 337.12
Eval num_timesteps=195000, episode_reward=-100.27 +/- 70.72
Episode length: 456.78 +/- 312.93
Eval num_timesteps=200000, episode_reward=-82.86 +/- 68.33
Episode length: 384.03 +/- 288.78
Eval num_timesteps=205000, episode_reward=-42.87 +/- 94.95
Episode length: 392.82 +/- 295.95
Eval num_timesteps=210000, episode_reward=-45.24 +/- 87.21
Episode length: 490.89 +/- 326.04
Eval num_timesteps=215000, episode_reward=-38.83 +/- 98.06
Episode length: 486.51 +/- 317.99
Eval num_timesteps=220000, episode_reward=-37.01 +/- 92.05
Episode length: 445.98 +/- 308.56
Eval num_timesteps=225000, episode_reward=-73.72 +/- 68.75
Episode length: 418.81 +/- 310.32
Eval num_timesteps=230000, episode_reward=-76.05 +/- 71.47
Episode length: 422.66 +/- 312.36
Eval num_timesteps=235000, episode_reward=-54.34 +/- 87.07
Episode length: 420.95 +/- 291.51
Eval num_timesteps=240000, episode_reward=-70.92 +/- 76.69
Episode length: 471.53 +/- 321.70
Eval num_timesteps=245000, episode_reward=-74.61 +/- 71.04
Episode length: 384.59 +/- 274.28
Eval num_timesteps=250000, episode_reward=-81.69 +/- 75.20
Episode length: 418.95 +/- 292.90
FINISHED IN 2192.8810234580305 s


starting seed  2923 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-4033.19 +/- 1968.72
Episode length: 484.41 +/- 76.98
New best mean reward!
Eval num_timesteps=10000, episode_reward=-839.13 +/- 364.33
Episode length: 145.15 +/- 46.65
New best mean reward!
Eval num_timesteps=15000, episode_reward=-212.94 +/- 50.28
Episode length: 964.30 +/- 79.84
New best mean reward!
Eval num_timesteps=20000, episode_reward=-168.56 +/- 69.55
Episode length: 742.84 +/- 234.23
New best mean reward!
Eval num_timesteps=25000, episode_reward=56.26 +/- 122.42
Episode length: 563.96 +/- 176.50
New best mean reward!
Eval num_timesteps=30000, episode_reward=41.55 +/- 111.65
Episode length: 630.04 +/- 251.47
Eval num_timesteps=35000, episode_reward=-55.05 +/- 115.73
Episode length: 516.82 +/- 198.39
Eval num_timesteps=40000, episode_reward=-128.79 +/- 54.85
Episode length: 777.85 +/- 255.90
Eval num_timesteps=45000, episode_reward=-74.55 +/- 63.22
Episode length: 947.56 +/- 103.30
Eval num_timesteps=50000, episode_reward=-13.96 +/- 110.33
Episode length: 578.82 +/- 281.12
Eval num_timesteps=55000, episode_reward=-11.19 +/- 115.51
Episode length: 437.09 +/- 186.77
Eval num_timesteps=60000, episode_reward=-52.13 +/- 103.81
Episode length: 604.89 +/- 282.46
Eval num_timesteps=65000, episode_reward=-111.58 +/- 50.18
Episode length: 433.39 +/- 257.29
Eval num_timesteps=70000, episode_reward=-132.67 +/- 45.09
Episode length: 325.56 +/- 215.72
Eval num_timesteps=75000, episode_reward=-111.35 +/- 36.13
Episode length: 362.24 +/- 254.11
Eval num_timesteps=80000, episode_reward=-147.94 +/- 44.04
Episode length: 402.43 +/- 287.38
Eval num_timesteps=85000, episode_reward=-142.80 +/- 43.61
Episode length: 405.84 +/- 285.93
Eval num_timesteps=90000, episode_reward=-116.92 +/- 36.94
Episode length: 492.13 +/- 343.95
Eval num_timesteps=95000, episode_reward=-95.45 +/- 44.18
Episode length: 701.46 +/- 358.37
Eval num_timesteps=100000, episode_reward=-122.41 +/- 38.07
Episode length: 452.62 +/- 291.89
Eval num_timesteps=105000, episode_reward=-103.79 +/- 57.00
Episode length: 559.94 +/- 328.28
Eval num_timesteps=110000, episode_reward=-133.66 +/- 52.81
Episode length: 563.64 +/- 321.30
Eval num_timesteps=115000, episode_reward=-125.66 +/- 46.06
Episode length: 520.09 +/- 288.75
Eval num_timesteps=120000, episode_reward=-67.55 +/- 79.56
Episode length: 510.80 +/- 308.76
Eval num_timesteps=125000, episode_reward=-97.47 +/- 57.84
Episode length: 499.96 +/- 314.76
Eval num_timesteps=130000, episode_reward=-126.45 +/- 40.09
Episode length: 424.91 +/- 299.96
Eval num_timesteps=135000, episode_reward=-143.69 +/- 46.16
Episode length: 427.09 +/- 305.29
Eval num_timesteps=140000, episode_reward=-117.24 +/- 43.02
Episode length: 452.18 +/- 344.48
Eval num_timesteps=145000, episode_reward=-125.60 +/- 40.92
Episode length: 409.39 +/- 288.42
Eval num_timesteps=150000, episode_reward=-152.79 +/- 56.09
Episode length: 420.10 +/- 304.80
Eval num_timesteps=155000, episode_reward=-145.47 +/- 49.41
Episode length: 401.29 +/- 299.74
Eval num_timesteps=160000, episode_reward=-129.62 +/- 50.56
Episode length: 524.72 +/- 354.85
Eval num_timesteps=165000, episode_reward=-108.70 +/- 38.18
Episode length: 556.27 +/- 359.68
Eval num_timesteps=170000, episode_reward=-127.01 +/- 45.23
Episode length: 518.54 +/- 335.87
Eval num_timesteps=175000, episode_reward=-128.99 +/- 41.95
Episode length: 437.84 +/- 287.44
Eval num_timesteps=180000, episode_reward=-132.78 +/- 36.62
Episode length: 377.06 +/- 271.56
Eval num_timesteps=185000, episode_reward=-105.64 +/- 41.51
Episode length: 424.13 +/- 302.94
Eval num_timesteps=190000, episode_reward=-111.44 +/- 38.08
Episode length: 468.73 +/- 347.63
Eval num_timesteps=195000, episode_reward=-121.22 +/- 46.87
Episode length: 470.14 +/- 329.77
Eval num_timesteps=200000, episode_reward=-129.95 +/- 58.33
Episode length: 535.01 +/- 334.71
Eval num_timesteps=205000, episode_reward=-98.53 +/- 47.86
Episode length: 582.80 +/- 362.08
Eval num_timesteps=210000, episode_reward=-91.99 +/- 39.97
Episode length: 566.95 +/- 382.39
Eval num_timesteps=215000, episode_reward=-102.26 +/- 40.07
Episode length: 476.67 +/- 338.42
Eval num_timesteps=220000, episode_reward=-82.13 +/- 61.68
Episode length: 493.91 +/- 346.60
Eval num_timesteps=225000, episode_reward=-92.18 +/- 41.56
Episode length: 512.22 +/- 360.04
Eval num_timesteps=230000, episode_reward=-92.95 +/- 29.97
Episode length: 512.77 +/- 367.36
Eval num_timesteps=235000, episode_reward=-96.66 +/- 32.68
Episode length: 564.03 +/- 363.27
Eval num_timesteps=240000, episode_reward=-102.51 +/- 37.31
Episode length: 514.08 +/- 347.23
Eval num_timesteps=245000, episode_reward=-94.77 +/- 32.95
Episode length: 531.79 +/- 364.19
Eval num_timesteps=250000, episode_reward=-100.16 +/- 33.86
Episode length: 516.10 +/- 371.11
FINISHED IN 1990.3006027520169 s


starting seed  2924 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-961.75 +/- 669.58
Episode length: 133.37 +/- 65.52
New best mean reward!
Eval num_timesteps=10000, episode_reward=-904.00 +/- 767.98
Episode length: 125.85 +/- 67.45
New best mean reward!
Eval num_timesteps=15000, episode_reward=-932.73 +/- 740.89
Episode length: 128.47 +/- 67.88
Eval num_timesteps=20000, episode_reward=-836.05 +/- 395.61
Episode length: 121.96 +/- 45.02
New best mean reward!
Eval num_timesteps=25000, episode_reward=-125.96 +/- 42.21
Episode length: 69.06 +/- 11.64
New best mean reward!
Eval num_timesteps=30000, episode_reward=-112.98 +/- 77.63
Episode length: 99.88 +/- 31.64
New best mean reward!
Eval num_timesteps=35000, episode_reward=-198.06 +/- 81.72
Episode length: 118.28 +/- 57.97
Eval num_timesteps=40000, episode_reward=-571.03 +/- 241.62
Episode length: 883.05 +/- 107.70
Eval num_timesteps=45000, episode_reward=-313.56 +/- 93.71
Episode length: 972.91 +/- 78.73
Eval num_timesteps=50000, episode_reward=-41.71 +/- 47.66
Episode length: 995.60 +/- 25.34
New best mean reward!
Eval num_timesteps=55000, episode_reward=-39.69 +/- 27.13
Episode length: 999.97 +/- 0.30
New best mean reward!
Eval num_timesteps=60000, episode_reward=63.53 +/- 122.35
Episode length: 733.50 +/- 132.01
New best mean reward!
Eval num_timesteps=65000, episode_reward=-22.01 +/- 32.53
Episode length: 998.93 +/- 6.22
Eval num_timesteps=70000, episode_reward=120.73 +/- 97.22
Episode length: 677.05 +/- 104.52
New best mean reward!
Eval num_timesteps=75000, episode_reward=161.54 +/- 90.29
Episode length: 538.88 +/- 223.71
New best mean reward!
Eval num_timesteps=80000, episode_reward=148.73 +/- 111.85
Episode length: 420.07 +/- 126.94
Eval num_timesteps=85000, episode_reward=133.18 +/- 111.70
Episode length: 446.41 +/- 160.93
Eval num_timesteps=90000, episode_reward=37.56 +/- 120.80
Episode length: 875.62 +/- 107.68
Eval num_timesteps=95000, episode_reward=-5.29 +/- 98.38
Episode length: 923.61 +/- 116.96
Eval num_timesteps=100000, episode_reward=38.16 +/- 145.46
Episode length: 735.56 +/- 228.40
Eval num_timesteps=105000, episode_reward=-26.43 +/- 114.40
Episode length: 915.02 +/- 166.78
Eval num_timesteps=110000, episode_reward=-67.60 +/- 40.52
Episode length: 951.36 +/- 149.62
Eval num_timesteps=115000, episode_reward=-62.36 +/- 27.40
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=-53.93 +/- 25.76
Episode length: 999.30 +/- 6.96
Eval num_timesteps=125000, episode_reward=81.40 +/- 101.02
Episode length: 777.32 +/- 154.54
Eval num_timesteps=130000, episode_reward=-116.53 +/- 56.29
Episode length: 934.71 +/- 125.85
Eval num_timesteps=135000, episode_reward=97.56 +/- 122.99
Episode length: 500.83 +/- 199.61
Eval num_timesteps=140000, episode_reward=72.79 +/- 113.99
Episode length: 650.66 +/- 167.10
Eval num_timesteps=145000, episode_reward=131.33 +/- 111.13
Episode length: 398.14 +/- 173.40
Eval num_timesteps=150000, episode_reward=48.34 +/- 121.96
Episode length: 422.28 +/- 215.80
Eval num_timesteps=155000, episode_reward=-17.63 +/- 110.60
Episode length: 682.01 +/- 290.69
Eval num_timesteps=160000, episode_reward=-21.06 +/- 100.51
Episode length: 690.19 +/- 271.47
Eval num_timesteps=165000, episode_reward=-77.52 +/- 53.99
Episode length: 742.20 +/- 311.76
Eval num_timesteps=170000, episode_reward=-105.54 +/- 67.20
Episode length: 670.25 +/- 332.75
Eval num_timesteps=175000, episode_reward=-23.42 +/- 100.78
Episode length: 623.87 +/- 259.29
Eval num_timesteps=180000, episode_reward=17.74 +/- 115.36
Episode length: 661.51 +/- 244.24
Eval num_timesteps=185000, episode_reward=19.92 +/- 105.08
Episode length: 426.94 +/- 227.45
Eval num_timesteps=190000, episode_reward=38.52 +/- 121.04
Episode length: 341.90 +/- 190.27
Eval num_timesteps=195000, episode_reward=2.91 +/- 102.11
Episode length: 314.79 +/- 152.14
Eval num_timesteps=200000, episode_reward=25.76 +/- 111.82
Episode length: 287.38 +/- 157.18
Eval num_timesteps=205000, episode_reward=-3.26 +/- 108.23
Episode length: 441.51 +/- 237.55
Eval num_timesteps=210000, episode_reward=-114.72 +/- 45.44
Episode length: 603.61 +/- 313.24
Eval num_timesteps=215000, episode_reward=-98.35 +/- 47.31
Episode length: 472.66 +/- 291.13
Eval num_timesteps=220000, episode_reward=-115.83 +/- 47.30
Episode length: 473.65 +/- 276.23
Eval num_timesteps=225000, episode_reward=-132.07 +/- 54.92
Episode length: 468.94 +/- 258.93
Eval num_timesteps=230000, episode_reward=-116.35 +/- 49.14
Episode length: 531.83 +/- 307.61
Eval num_timesteps=235000, episode_reward=-106.47 +/- 46.60
Episode length: 514.56 +/- 324.27
Eval num_timesteps=240000, episode_reward=-114.90 +/- 49.34
Episode length: 547.38 +/- 335.95
Eval num_timesteps=245000, episode_reward=-117.18 +/- 57.75
Episode length: 640.44 +/- 338.60
Eval num_timesteps=250000, episode_reward=-127.60 +/- 65.81
Episode length: 586.28 +/- 344.67
FINISHED IN 3257.3312647890416 s


starting seed  2925 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-239.20 +/- 123.59
Episode length: 690.13 +/- 193.81
New best mean reward!
Eval num_timesteps=10000, episode_reward=-520.51 +/- 202.47
Episode length: 579.62 +/- 109.65
Eval num_timesteps=15000, episode_reward=69.79 +/- 121.11
Episode length: 696.28 +/- 113.40
New best mean reward!
Eval num_timesteps=20000, episode_reward=-7.31 +/- 76.59
Episode length: 950.52 +/- 100.69
Eval num_timesteps=25000, episode_reward=29.05 +/- 111.13
Episode length: 732.48 +/- 129.62
Eval num_timesteps=30000, episode_reward=68.62 +/- 122.86
Episode length: 754.62 +/- 194.66
Eval num_timesteps=35000, episode_reward=-52.16 +/- 25.21
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=-13.60 +/- 157.70
Episode length: 756.43 +/- 148.28
Eval num_timesteps=45000, episode_reward=26.23 +/- 137.49
Episode length: 608.51 +/- 152.13
Eval num_timesteps=50000, episode_reward=99.05 +/- 112.13
Episode length: 590.76 +/- 168.89
New best mean reward!
Eval num_timesteps=55000, episode_reward=47.12 +/- 123.26
Episode length: 805.31 +/- 162.95
Eval num_timesteps=60000, episode_reward=-117.74 +/- 66.33
Episode length: 466.87 +/- 287.64
Eval num_timesteps=65000, episode_reward=4.29 +/- 118.58
Episode length: 408.20 +/- 191.96
Eval num_timesteps=70000, episode_reward=-33.57 +/- 105.07
Episode length: 394.74 +/- 227.38
Eval num_timesteps=75000, episode_reward=-75.81 +/- 45.13
Episode length: 688.28 +/- 375.68
Eval num_timesteps=80000, episode_reward=-70.48 +/- 29.93
Episode length: 779.38 +/- 355.06
Eval num_timesteps=85000, episode_reward=-125.41 +/- 49.44
Episode length: 416.50 +/- 317.07
Eval num_timesteps=90000, episode_reward=-101.11 +/- 57.36
Episode length: 472.21 +/- 341.43
Eval num_timesteps=95000, episode_reward=-105.70 +/- 35.37
Episode length: 517.03 +/- 360.04
Eval num_timesteps=100000, episode_reward=-154.16 +/- 35.57
Episode length: 397.25 +/- 235.97
Eval num_timesteps=105000, episode_reward=-91.60 +/- 56.70
Episode length: 517.85 +/- 375.73
Eval num_timesteps=110000, episode_reward=-117.26 +/- 30.23
Episode length: 468.30 +/- 359.62
Eval num_timesteps=115000, episode_reward=-108.45 +/- 29.62
Episode length: 479.10 +/- 356.31
Eval num_timesteps=120000, episode_reward=-96.51 +/- 27.75
Episode length: 663.40 +/- 388.22
Eval num_timesteps=125000, episode_reward=-95.99 +/- 39.71
Episode length: 588.72 +/- 382.24
Eval num_timesteps=130000, episode_reward=-146.29 +/- 48.66
Episode length: 344.29 +/- 243.26
Eval num_timesteps=135000, episode_reward=-112.93 +/- 47.69
Episode length: 417.33 +/- 298.71
Eval num_timesteps=140000, episode_reward=-68.20 +/- 93.98
Episode length: 415.67 +/- 269.99
Eval num_timesteps=145000, episode_reward=-101.78 +/- 62.24
Episode length: 460.68 +/- 329.36
Eval num_timesteps=150000, episode_reward=-59.93 +/- 102.09
Episode length: 428.10 +/- 263.56
Eval num_timesteps=155000, episode_reward=-21.57 +/- 109.73
Episode length: 391.74 +/- 238.73
Eval num_timesteps=160000, episode_reward=-40.36 +/- 96.00
Episode length: 418.96 +/- 268.78
Eval num_timesteps=165000, episode_reward=-70.53 +/- 107.38
Episode length: 407.21 +/- 257.22
Eval num_timesteps=170000, episode_reward=-42.05 +/- 78.11
Episode length: 727.53 +/- 338.53
Eval num_timesteps=175000, episode_reward=-77.21 +/- 35.42
Episode length: 562.20 +/- 377.69
Eval num_timesteps=180000, episode_reward=-76.73 +/- 55.67
Episode length: 487.06 +/- 344.24
Eval num_timesteps=185000, episode_reward=-45.74 +/- 98.77
Episode length: 397.01 +/- 258.18
Eval num_timesteps=190000, episode_reward=-43.21 +/- 99.44
Episode length: 387.01 +/- 256.59
Eval num_timesteps=195000, episode_reward=-31.41 +/- 100.64
Episode length: 383.19 +/- 262.35
Eval num_timesteps=200000, episode_reward=-12.85 +/- 109.10
Episode length: 402.10 +/- 251.56
Eval num_timesteps=205000, episode_reward=-38.50 +/- 101.21
Episode length: 366.24 +/- 233.02
Eval num_timesteps=210000, episode_reward=-65.67 +/- 62.27
Episode length: 521.18 +/- 361.01
Eval num_timesteps=215000, episode_reward=-66.04 +/- 80.95
Episode length: 451.17 +/- 324.31
Eval num_timesteps=220000, episode_reward=-89.99 +/- 52.96
Episode length: 461.59 +/- 328.04
Eval num_timesteps=225000, episode_reward=-53.51 +/- 94.42
Episode length: 485.98 +/- 317.74
Eval num_timesteps=230000, episode_reward=-50.36 +/- 91.25
Episode length: 474.99 +/- 306.27
Eval num_timesteps=235000, episode_reward=-59.41 +/- 70.65
Episode length: 474.91 +/- 347.36
Eval num_timesteps=240000, episode_reward=-69.11 +/- 67.64
Episode length: 451.46 +/- 316.52
Eval num_timesteps=245000, episode_reward=-73.46 +/- 67.64
Episode length: 477.70 +/- 337.88
Eval num_timesteps=250000, episode_reward=-63.66 +/- 68.04
Episode length: 494.23 +/- 355.78
FINISHED IN 2970.1950487919967 s


starting seed  2926 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-581.98 +/- 92.98
Episode length: 552.29 +/- 66.07
New best mean reward!
Eval num_timesteps=10000, episode_reward=-455.43 +/- 48.92
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=15000, episode_reward=-81.75 +/- 35.40
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-120.92 +/- 24.80
Episode length: 992.56 +/- 48.40
Eval num_timesteps=25000, episode_reward=-76.20 +/- 20.00
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=25.63 +/- 113.60
Episode length: 664.71 +/- 173.94
New best mean reward!
Eval num_timesteps=35000, episode_reward=-49.99 +/- 50.82
Episode length: 956.53 +/- 110.64
Eval num_timesteps=40000, episode_reward=-86.37 +/- 42.19
Episode length: 969.48 +/- 92.04
Eval num_timesteps=45000, episode_reward=-102.43 +/- 36.40
Episode length: 997.22 +/- 19.57
Eval num_timesteps=50000, episode_reward=-69.45 +/- 69.11
Episode length: 787.43 +/- 255.81
Eval num_timesteps=55000, episode_reward=18.64 +/- 116.36
Episode length: 621.81 +/- 208.65
Eval num_timesteps=60000, episode_reward=-122.74 +/- 56.28
Episode length: 524.07 +/- 278.16
Eval num_timesteps=65000, episode_reward=-119.70 +/- 54.65
Episode length: 569.07 +/- 315.40
Eval num_timesteps=70000, episode_reward=-155.98 +/- 50.33
Episode length: 500.44 +/- 301.12
Eval num_timesteps=75000, episode_reward=-102.31 +/- 48.04
Episode length: 594.94 +/- 354.67
Eval num_timesteps=80000, episode_reward=-97.94 +/- 39.14
Episode length: 645.09 +/- 368.26
Eval num_timesteps=85000, episode_reward=-160.08 +/- 36.16
Episode length: 445.13 +/- 281.77
Eval num_timesteps=90000, episode_reward=-82.35 +/- 20.73
Episode length: 849.46 +/- 312.15
Eval num_timesteps=95000, episode_reward=-130.19 +/- 49.52
Episode length: 582.87 +/- 366.44
Eval num_timesteps=100000, episode_reward=-139.91 +/- 22.25
Episode length: 597.91 +/- 395.02
Eval num_timesteps=105000, episode_reward=-155.86 +/- 46.42
Episode length: 511.90 +/- 348.07
Eval num_timesteps=110000, episode_reward=-133.37 +/- 28.95
Episode length: 387.18 +/- 293.12
Eval num_timesteps=115000, episode_reward=-144.93 +/- 42.97
Episode length: 378.00 +/- 273.85
Eval num_timesteps=120000, episode_reward=-92.02 +/- 42.65
Episode length: 666.24 +/- 380.81
Eval num_timesteps=125000, episode_reward=-138.46 +/- 44.98
Episode length: 608.75 +/- 380.04
Eval num_timesteps=130000, episode_reward=-127.17 +/- 42.86
Episode length: 506.15 +/- 354.48
Eval num_timesteps=135000, episode_reward=-118.54 +/- 42.67
Episode length: 472.44 +/- 335.38
Eval num_timesteps=140000, episode_reward=-115.23 +/- 43.89
Episode length: 520.49 +/- 343.91
Eval num_timesteps=145000, episode_reward=-112.19 +/- 42.79
Episode length: 531.31 +/- 350.96
Eval num_timesteps=150000, episode_reward=-119.34 +/- 35.61
Episode length: 481.06 +/- 355.19
Eval num_timesteps=155000, episode_reward=-110.57 +/- 48.03
Episode length: 426.74 +/- 300.36
Eval num_timesteps=160000, episode_reward=-129.98 +/- 33.94
Episode length: 472.67 +/- 326.41
Eval num_timesteps=165000, episode_reward=-130.15 +/- 36.52
Episode length: 403.10 +/- 293.93
Eval num_timesteps=170000, episode_reward=-125.04 +/- 32.23
Episode length: 512.42 +/- 355.09
Eval num_timesteps=175000, episode_reward=-122.97 +/- 29.49
Episode length: 509.96 +/- 374.37
Eval num_timesteps=180000, episode_reward=-105.45 +/- 42.26
Episode length: 485.41 +/- 342.61
Eval num_timesteps=185000, episode_reward=-109.06 +/- 44.47
Episode length: 505.06 +/- 346.79
Eval num_timesteps=190000, episode_reward=-97.66 +/- 41.83
Episode length: 529.90 +/- 349.46
Eval num_timesteps=195000, episode_reward=-125.35 +/- 37.19
Episode length: 488.24 +/- 321.39
Eval num_timesteps=200000, episode_reward=-117.44 +/- 35.20
Episode length: 477.50 +/- 334.46
Eval num_timesteps=205000, episode_reward=-117.94 +/- 36.18
Episode length: 484.96 +/- 353.04
Eval num_timesteps=210000, episode_reward=-123.76 +/- 35.02
Episode length: 471.48 +/- 355.45
Eval num_timesteps=215000, episode_reward=-102.93 +/- 34.29
Episode length: 469.70 +/- 347.42
Eval num_timesteps=220000, episode_reward=-115.66 +/- 32.98
Episode length: 427.14 +/- 317.66
Eval num_timesteps=225000, episode_reward=-120.56 +/- 37.69
Episode length: 567.61 +/- 358.83
Eval num_timesteps=230000, episode_reward=-113.86 +/- 31.44
Episode length: 471.15 +/- 351.11
Eval num_timesteps=235000, episode_reward=-111.23 +/- 31.88
Episode length: 464.16 +/- 342.06
Eval num_timesteps=240000, episode_reward=-118.96 +/- 37.13
Episode length: 473.65 +/- 340.29
Eval num_timesteps=245000, episode_reward=-112.75 +/- 36.21
Episode length: 451.22 +/- 327.93
Eval num_timesteps=250000, episode_reward=-111.62 +/- 31.99
Episode length: 425.84 +/- 338.50
FINISHED IN 4126.957564887009 s


starting seed  2927 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-245.01 +/- 89.03
Episode length: 195.84 +/- 110.91
New best mean reward!
Eval num_timesteps=10000, episode_reward=-436.82 +/- 113.13
Episode length: 383.55 +/- 81.01
Eval num_timesteps=15000, episode_reward=-290.11 +/- 61.32
Episode length: 953.30 +/- 72.72
Eval num_timesteps=20000, episode_reward=-143.83 +/- 23.68
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=25000, episode_reward=-86.07 +/- 22.42
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=30000, episode_reward=-39.39 +/- 25.36
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=35000, episode_reward=-83.87 +/- 27.60
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=40000, episode_reward=29.87 +/- 103.00
Episode length: 815.47 +/- 155.54
New best mean reward!
Eval num_timesteps=45000, episode_reward=-18.42 +/- 86.45
Episode length: 859.56 +/- 197.87
Eval num_timesteps=50000, episode_reward=-101.47 +/- 48.66
Episode length: 804.90 +/- 280.03
Eval num_timesteps=55000, episode_reward=-82.04 +/- 62.45
Episode length: 761.20 +/- 325.48
Eval num_timesteps=60000, episode_reward=-71.02 +/- 77.51
Episode length: 374.23 +/- 235.57
Eval num_timesteps=65000, episode_reward=-9.78 +/- 122.54
Episode length: 510.93 +/- 251.47
Eval num_timesteps=70000, episode_reward=-84.17 +/- 65.61
Episode length: 701.99 +/- 364.66
Eval num_timesteps=75000, episode_reward=22.23 +/- 91.41
Episode length: 809.15 +/- 252.55
Eval num_timesteps=80000, episode_reward=-75.90 +/- 92.55
Episode length: 475.98 +/- 279.23
Eval num_timesteps=85000, episode_reward=-95.23 +/- 60.85
Episode length: 520.37 +/- 318.91
Eval num_timesteps=90000, episode_reward=-79.30 +/- 46.89
Episode length: 680.92 +/- 358.94
Eval num_timesteps=95000, episode_reward=-108.48 +/- 54.62
Episode length: 588.11 +/- 333.34
Eval num_timesteps=100000, episode_reward=-37.90 +/- 111.82
Episode length: 479.79 +/- 248.13
Eval num_timesteps=105000, episode_reward=-55.57 +/- 110.64
Episode length: 489.23 +/- 278.41
Eval num_timesteps=110000, episode_reward=-17.23 +/- 99.42
Episode length: 515.26 +/- 286.56
Eval num_timesteps=115000, episode_reward=15.15 +/- 108.21
Episode length: 534.92 +/- 292.79
Eval num_timesteps=120000, episode_reward=-92.89 +/- 60.83
Episode length: 729.22 +/- 364.66
Eval num_timesteps=125000, episode_reward=-95.31 +/- 66.56
Episode length: 597.49 +/- 311.84
Eval num_timesteps=130000, episode_reward=-105.37 +/- 72.39
Episode length: 531.15 +/- 326.20
Eval num_timesteps=135000, episode_reward=-99.73 +/- 43.29
Episode length: 758.18 +/- 353.15
Eval num_timesteps=140000, episode_reward=-109.43 +/- 46.65
Episode length: 557.87 +/- 359.48
Eval num_timesteps=145000, episode_reward=-63.71 +/- 59.18
Episode length: 680.12 +/- 355.16
Eval num_timesteps=150000, episode_reward=-91.91 +/- 43.37
Episode length: 543.32 +/- 379.60
Eval num_timesteps=155000, episode_reward=-105.40 +/- 32.64
Episode length: 494.71 +/- 362.22
Eval num_timesteps=160000, episode_reward=-56.25 +/- 73.83
Episode length: 582.21 +/- 349.32
Eval num_timesteps=165000, episode_reward=-99.89 +/- 33.15
Episode length: 618.08 +/- 381.14
Eval num_timesteps=170000, episode_reward=-104.55 +/- 42.37
Episode length: 564.02 +/- 383.88
Eval num_timesteps=175000, episode_reward=-101.42 +/- 50.67
Episode length: 574.94 +/- 356.74
Eval num_timesteps=180000, episode_reward=-104.62 +/- 41.87
Episode length: 538.77 +/- 340.74
Eval num_timesteps=185000, episode_reward=-91.82 +/- 49.89
Episode length: 549.01 +/- 362.09
Eval num_timesteps=190000, episode_reward=-127.06 +/- 45.30
Episode length: 479.86 +/- 322.97
Eval num_timesteps=195000, episode_reward=-117.45 +/- 37.46
Episode length: 465.31 +/- 319.05
Eval num_timesteps=200000, episode_reward=-106.70 +/- 58.39
Episode length: 592.79 +/- 361.60
Eval num_timesteps=205000, episode_reward=-110.93 +/- 47.86
Episode length: 516.46 +/- 342.37
Eval num_timesteps=210000, episode_reward=-128.29 +/- 44.91
Episode length: 421.02 +/- 296.99
Eval num_timesteps=215000, episode_reward=-123.21 +/- 42.03
Episode length: 505.87 +/- 347.19
Eval num_timesteps=220000, episode_reward=-107.87 +/- 43.26
Episode length: 490.77 +/- 350.77
Eval num_timesteps=225000, episode_reward=-112.21 +/- 36.42
Episode length: 461.45 +/- 337.22
Eval num_timesteps=230000, episode_reward=-109.78 +/- 38.36
Episode length: 479.10 +/- 355.44
Eval num_timesteps=235000, episode_reward=-122.83 +/- 41.21
Episode length: 525.82 +/- 329.40
Eval num_timesteps=240000, episode_reward=-113.26 +/- 33.00
Episode length: 512.95 +/- 355.17
Eval num_timesteps=245000, episode_reward=-114.09 +/- 50.72
Episode length: 528.62 +/- 364.72
Eval num_timesteps=250000, episode_reward=-114.80 +/- 42.02
Episode length: 518.27 +/- 350.91
FINISHED IN 3532.737721620011 s


starting seed  2928 


<class 'torch.nn.modules.activation.ReLU'>
running on  cuda
Eval num_timesteps=5000, episode_reward=-2022.91 +/- 475.17
Episode length: 602.97 +/- 78.83
New best mean reward!
Eval num_timesteps=10000, episode_reward=-308.52 +/- 84.46
Episode length: 566.48 +/- 166.37
New best mean reward!
Eval num_timesteps=15000, episode_reward=-205.97 +/- 33.57
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=20000, episode_reward=-153.59 +/- 55.27
Episode length: 904.61 +/- 119.45
New best mean reward!
Eval num_timesteps=25000, episode_reward=-129.67 +/- 28.84
Episode length: 1000.00 +/- 0.00
New best mean reward!
Traceback (most recent call last):
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/sb.py", line 167, in <module>
    args = parser.parse_args()
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/sb.py", line 158, in main
    random.seed(args.seed + i)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/sb.py", line 138, in drl
    
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/a2c/a2c.py", line 217, in learn
    return super().learn(
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/on_policy_algorithm.py", line 251, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/on_policy_algorithm.py", line 185, in collect_rollouts
    if callback.on_step() is False:
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/callbacks.py", line 88, in on_step
    return self._on_step()
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/callbacks.py", line 435, in _on_step
    episode_rewards, episode_lengths = evaluate_policy(
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/evaluation.py", line 86, in evaluate_policy
    actions, states = model.predict(observations, state=states, episode_start=episode_starts, deterministic=deterministic)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/base_class.py", line 589, in predict
    return self.policy.predict(observation, state, episode_start, deterministic)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/policies.py", line 341, in predict
    actions = self._predict(observation, deterministic=deterministic)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/policies.py", line 647, in _predict
    return self.get_distribution(observation).get_actions(deterministic=deterministic)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/policies.py", line 684, in get_distribution
    latent_pi = self.mlp_extractor.forward_actor(features)
  File "/home/haani/snap/snapd-desktop-integration/83/Documents/thesis/stable_baselines3_thesis/common/torch_layers.py", line 259, in forward_actor
    return self.policy_net(self.shared_net(features))
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1581, in _call_impl
    hook_result = hook(self, args, result)
  Fi